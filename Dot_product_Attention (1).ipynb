{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91892c6-90fa-48e6-9a7b-2e173e4b0a5c",
   "metadata": {},
   "source": [
    "The objective of this project is to: \n",
    "* Create positional encodings to capture sequential relationships in data\n",
    "* Calculate scaled dot-product self-attention with word embeddings\n",
    "* Implement masked multi-head attention\n",
    "* Build and train a Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bf32da35-c73d-4fd9-ac13-b9611a826739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required packages: \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import  reshape, shape, transpose\n",
    "\n",
    "from transformers import DistilBertTokenizerFast #, TFDistilBertModel\n",
    "from transformers import TFDistilBertForTokenClassification\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af948524-a3c0-40c4-a3b5-11a0d767ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the angles for positional embeddings: \n",
    "def get_angles(pos, k, d):\n",
    "    \"\"\"\n",
    "    Get the angles for the positional encoding\n",
    "    \n",
    "    Arguments:\n",
    "        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]\n",
    "        k --   Row vector containing the dimension span [[0, 1, 2, ..., d-1]]\n",
    "        d(integer) -- Encoding size\n",
    "    \n",
    "    Returns:\n",
    "        angles -- (pos, d) numpy array \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get i from dimension span k\n",
    "    i = k//2\n",
    "    # Calculate the angles using pos, i and d\n",
    "    angles = pos/ (10000)**(2*i/d)\n",
    "\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7163b5-180d-4d4c-80ac-b6db715c49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write down your own positional embedding: \n",
    "#what do we need? we need to first calculate the angles and then pass those to cal cosine and sine and save into the pos embs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e4e749-80e0-4962-853e-feb69b1dc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so how to calculate the angles? for the angles we require position i, and d. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390d1d6a-6a04-4ee1-ab15-e11c24e8a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_emb(len_seq, len_emb): \n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates the positional embeddings for all the words in the sequence based on: \n",
    "    \n",
    "    Input: \n",
    "    len_seq (int) : The length of the sequences inputed into the model. \n",
    "    len_emb (int) : The length of the word embeddings for every word in the sequence. \n",
    "\n",
    "    Note: the size of the positional encoding and the word embeddings must match in order to add them in the next step. \n",
    "\n",
    "    Output: \n",
    "    res (np.array(len_seq, len_emb)) : ith row of this matrix represents the positional encodings for the ith position in the sequence. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    len_i = int(len_emb/2)\n",
    "\n",
    "    # Initialize the matrix to save positional encodings: \n",
    "    res = np.zeros((len_seq,len_emb))\n",
    "    angles = np.zeros((len_seq,len_emb))\n",
    "    \n",
    "    #for each position in the sequence \n",
    "    for pos in range(len_seq): \n",
    "        \n",
    "        #calculate the angles: \n",
    "        for i in range(len_i): \n",
    "            angles[pos,2*i] = pos/(10000**(2*i/len_emb))\n",
    "            angles[pos, 2*i +1] = pos/(10000**(2*i/len_emb)) \n",
    "        \n",
    "        # Calculate the entries corresponding to each position \n",
    "        #for j in range(len_i): \n",
    "        res[pos, 0::2] = np.sin(angles[pos,0::2])\n",
    "        res[pos,1::2] = np.cos(angles[pos,0::2])\n",
    "            \n",
    "    return(tf.cast(res.reshape(1,len_seq,len_emb), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e75702-9536-4867-8023-e9fda3c2c388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
       "array([[[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "          0.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
       "        [ 8.4147096e-01,  5.4030228e-01,  9.9833414e-02,  9.9500418e-01,\n",
       "          9.9998331e-03,  9.9994999e-01,  9.9999981e-04,  9.9999952e-01],\n",
       "        [ 9.0929741e-01, -4.1614684e-01,  1.9866933e-01,  9.8006660e-01,\n",
       "          1.9998666e-02,  9.9980003e-01,  1.9999987e-03,  9.9999797e-01],\n",
       "        [ 1.4112000e-01, -9.8999250e-01,  2.9552022e-01,  9.5533651e-01,\n",
       "          2.9995501e-02,  9.9955004e-01,  2.9999956e-03,  9.9999553e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb(4,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9cb92-9293-4a30-b4cc-7c98a557daf1",
   "metadata": {},
   "source": [
    "We want the Softmax function that assigns the attention scores to avoid assigning any attention score to the padded parts of the sequence. So, instead we can either define a function that replaces vectors of all zeros with negative infinity (-1e-9) or when creating the padded embeddings for each input, we can assign -1e-9 to every padded token. But if we add the padding before going through the dot product attention (before the softmax), it is possible that through multiplication with matrices q,k, and v the padded vectors grow larger and then when we run the resultant matrix through softmax, it might again not assign 0 attention scores to the padded sequences. Therefore, the padded mask must be added after the dot product. Then apply Softmax, then multiply with the V matrix. Where to normalize? we will normalize the attention scores after the dot product before masking is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f8a5e5-f0f7-4da4-ae82-cd410ee5b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the input with Glove Word Embeddings: \n",
    "def gvec_input(x,m,e): \n",
    "    \"\"\"\n",
    "    \n",
    "    This function takes any input, x, and returns a glove vector based on the \n",
    "    words introduced in the vocabulary (400,000 words). This function returns k vectors where k is the number of words in the \n",
    "    sentence. Every vector corresponds to a word in the dictionary and each entry will describe a feature of the word. \n",
    "    \n",
    "    inputs: \n",
    "    \n",
    "    x (string) : a statement from customers. \n",
    "    m (int)    : size of the sequence \n",
    "    e (int)    : size of the embeddings \n",
    "    outputs: \n",
    "    v (m,n)    : where m is the number of words in the sentence and n = 50 is the number of total features describing a word. \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    gv = np.zeros((n,m, e))\n",
    "    \n",
    "    for i in range(0, n): #looping over each comment \n",
    "        txt = x[i] #select the ith comment  \n",
    "        txt = (txt[:m] if len(txt) > m else txt + ['<pad>'] * (m - len(txt))) #shorten or add extra padding\n",
    "        for l in range(m): #looping over each word \n",
    "            \n",
    "            # add the embedding of all ones for pads\n",
    "            if txt[l] == \"<pad>\": \n",
    "                gv[i,l,:] = np.ones(e) \n",
    "                \n",
    "            # if a word is not is the list of Glove embeddings, then assign an array which is the average of all embeddings:    \n",
    "            elif txt[l] not in words: \n",
    "                gv[i,l,:] = np.mean(vectors, axis = 0)\n",
    "            # add the word embeddings: \n",
    "            else: \n",
    "                gv[i,l,:] = embeddings_dict[txt[l]]\n",
    "    return(gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0640e104-b96c-4491-b450-dab4782f2c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               reviewId            userName  \\\n",
      "0     gp:AOqpTOFxf3fttcT5DSvFIn9KPp5FErgH9yC533Fmoxv...      Donna Caritero   \n",
      "1     gp:AOqpTOEq6rNIWLnPV4KFTctWvm0mpGEQljtD6mvy1H-...  Soumi Mukhopadhyay   \n",
      "2     gp:AOqpTOE86hSyPRHZgYt28Uk5zGe4FZGb1hkmtFDiYJ2...   Theknown _unknown   \n",
      "3     gp:AOqpTOHSuKkVTcM3QgCCKysHQlxEnk2ocOKsUMiMIJy...        Anthony Dean   \n",
      "4     gp:AOqpTOEOrZt5H6jXPiplJyffCd5ZBnVXACTWgwNsF1R...   Neha Diana Wesley   \n",
      "...                                                 ...                 ...   \n",
      "1495  gp:AOqpTOHhnXMpylU3f-1V1KbR2hwWArOilxPlKI6K4xY...            Reen Ali   \n",
      "1496  gp:AOqpTOEcz62DHS-amqTB5xGMhM4_R0UJpcv_HDNny9i...     Shaurya Chilwal   \n",
      "1497  gp:AOqpTOFMqEqa_kpp29Q8wjcBmKUCAvOQGQx4KZQ8b83...           GK Gaming   \n",
      "1498  gp:AOqpTOGY4z3pUxeiqGzn2ad3Noxqlbm-9DZ3ksHqD1_...    1203_Vani Sharma   \n",
      "1499  gp:AOqpTOFVGZ0MXyR-Gv_d2cYf2KD709Hwple_u7OZE4y...           MeLLy EcK   \n",
      "\n",
      "                                              userImage  \\\n",
      "0     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "2     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "3     https://play-lh.googleusercontent.com/a/AATXAJ...   \n",
      "4     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "...                                                 ...   \n",
      "1495  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1496  https://play-lh.googleusercontent.com/a/AATXAJ...   \n",
      "1497  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1498  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1499  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "\n",
      "                                                 review  score  thumbsUpCount  \\\n",
      "0     Overall it's really an amazing app. I've been ...      4            528   \n",
      "1     Hey! Yes I gave a 5 star rating... coz I belie...      5            351   \n",
      "2     Canva used to be a good app! But recently I've...      1            160   \n",
      "3     It's a brilliant app, but I have just one prob...      5            145   \n",
      "4     This was such a great app. I used to make BTS ...      4            142   \n",
      "...                                                 ...    ...            ...   \n",
      "1495   Absolutely amazing and a lifesaver for teachers.      5              0   \n",
      "1496  Very nice but many a times shows error opening...      3              0   \n",
      "1497  Too much lag. Always stuck on starting page. W...      1              0   \n",
      "1498  Nice app for all college work. So many feature...      5              0   \n",
      "1499  I am a teacher and this was so much for this s...      5              0   \n",
      "\n",
      "     reviewCreatedVersion                  at  \\\n",
      "0                 2.116.0 2021-06-17 07:18:54   \n",
      "1                 2.116.0 2021-06-17 19:18:28   \n",
      "2                 2.116.0 2021-06-23 19:13:28   \n",
      "3                 2.116.0 2021-06-19 23:36:07   \n",
      "4                 2.116.0 2021-06-21 00:29:27   \n",
      "...                   ...                 ...   \n",
      "1495              2.127.0 2021-09-07 02:45:51   \n",
      "1496              2.123.0 2021-08-14 07:36:50   \n",
      "1497              2.118.0 2021-07-06 03:34:38   \n",
      "1498              2.123.0 2021-08-07 18:47:15   \n",
      "1499              2.117.0 2021-06-28 03:40:57   \n",
      "\n",
      "                                           replyContent           repliedAt  \\\n",
      "0     Hi Donna. We are sorry that your text or desig... 2021-06-19 21:24:32   \n",
      "1                                                   NaN                 NaT   \n",
      "2     Hi there. We're sorry to hear that you are hav... 2021-06-26 20:20:56   \n",
      "3                                                   NaN                 NaT   \n",
      "4     Hi Neha. Sorry to hear that you are unable to ... 2021-06-24 20:46:28   \n",
      "...                                                 ...                 ...   \n",
      "1495                                                NaN                 NaT   \n",
      "1496  Hi Shaurya, we're sorry if the app shows error... 2021-08-22 00:07:12   \n",
      "1497  Hello there, sorry if it is frustrating and ju... 2021-07-19 01:19:18   \n",
      "1498                                                NaN                 NaT   \n",
      "1499                                                NaN                 NaT   \n",
      "\n",
      "     Sentiment              Sub Category    Sub Category_test  \n",
      "0     Negative                       NaN  bug_picture_quality  \n",
      "1     Positive           extremely_happy                  NaN  \n",
      "2     Negative  saving_downloading_issue     bug_saving_files  \n",
      "3     Negative                    others        bug_app_crash  \n",
      "4     Negative                    others            bug_other  \n",
      "...        ...                       ...                  ...  \n",
      "1495  Positive           extremely_happy                  NaN  \n",
      "1496  Negative                    others                  NaN  \n",
      "1497  Negative                    others                  NaN  \n",
      "1498  Positive           extremely_happy                  NaN  \n",
      "1499  Positive           extremely_happy                  NaN  \n",
      "\n",
      "[1500 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading the data: \n",
    "CustomerFeed = 'Canva_reviews.xlsx'\n",
    "df = pd.read_excel(CustomerFeed)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2c13f4-64e6-461e-ba0a-f47a02d1f2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall it's really an amazing app. I've been ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey! Yes I gave a 5 star rating... coz I belie...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canva used to be a good app! But recently I've...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a brilliant app, but I have just one prob...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This was such a great app. I used to make BTS ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review Sentiment\n",
       "0  Overall it's really an amazing app. I've been ...  Negative\n",
       "1  Hey! Yes I gave a 5 star rating... coz I belie...  Positive\n",
       "2  Canva used to be a good app! But recently I've...  Negative\n",
       "3  It's a brilliant app, but I have just one prob...  Negative\n",
       "4  This was such a great app. I used to make BTS ...  Negative"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"review\", \"Sentiment\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efee0dca-791d-4461-87cc-a72c931a04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_txt(review):\n",
    "    \"\"\"\n",
    "    This function receives a text and returns it edited as follows: \n",
    "    1, all words converted to lower case \n",
    "    2, integers removed\n",
    "    3, tokenize the words \n",
    "    4, punctuation removed \n",
    "    5, common words that are unnecessary are removed. \n",
    "    \"\"\"\n",
    "    \n",
    "    review_edited = []\n",
    "\n",
    "    #Converting to lower case: \n",
    "    review_edited = review.lower() \n",
    "    \n",
    "    #Removing integers: \n",
    "    pattern = r'[0-9]'\n",
    "    # Match all digits in the string and replace them with an empty string\n",
    "    review_edited = re.sub(pattern, '', review_edited) \n",
    "\n",
    "    #Tokenize the comment: \n",
    "    review_edited = word_tokenize(review_edited) \n",
    "\n",
    "    #Removing punctuation \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    review_edited = [''.join(tokenizer.tokenize(word)) for word in review_edited if len(tokenizer.tokenize(word))>0]\n",
    "\n",
    "    #Removing common words: \n",
    "    remove_list = stopwords.words('english') \n",
    "    to_remove = [ \"not\",'don',\"don't\",'should',\"should've\", 'ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven',\"haven't\",'isn',\"isn't\",'mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn', \"wouldn't\"]\n",
    " \n",
    "    review_edited = [word for word in review_edited if not word in remove_list]\n",
    "    return(review_edited) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc11020d-af99-4e71-98cd-1a53acc9df36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unable', 'save', 'work', 'nothing', 'works']\n",
      "Unable to save my work. Nothing works :(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Negative', 'Positive']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the reviews: \n",
    "x = df[\"review\"] \n",
    "\n",
    "#Modify the text to test the function reviews_edited: \n",
    "reviews_edited = [edit_txt(review) for review in x]\n",
    "print(reviews_edited[13])\n",
    "print(x[13])\n",
    "\n",
    "# Define the target dataset and extract the unique rankings: \n",
    "y = df[\"Sentiment\"].tolist()\n",
    "ranking = np.unique(y)\n",
    "ranking = ranking.tolist()\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659e7b7-d82a-465b-be12-cb4e9a83f09d",
   "metadata": {},
   "source": [
    "### <font color = \"red\"> Do we need the following? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d06fea0-e4bd-42f0-b9f0-724cbf2ee4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aap',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'acc',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessibilities']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dictionary: \n",
    "Split = [] \n",
    "Dic = []\n",
    "dictionary = np.unique([word for review in reviews_edited for word in review]).tolist()\n",
    "\n",
    "# Add extra padding to limit the length of the input: \n",
    "dictionary = dictionary + [\"<pad>\"]\n",
    "dictionary[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d9e8f8-7b69-44e9-adac-e687dd985a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing datasets: \n",
    "#x = x.to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ca92e7d-f6b9-4af3-99a0-c97369effba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the edit_txt function to both text corpus: \n",
    "X_train = [edit_txt(comment) for comment in X_train]\n",
    "X_test = [edit_txt(comment) for comment in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ce1576-ee25-4447-b1fd-bd3abe0ea73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word embeddings (Glove word embeddings) \n",
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.50d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "\n",
    "words =  list(embeddings_dict.keys())\n",
    "vectors = [embeddings_dict[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e84cded1-8bc4-4eec-9f9b-cccb5b98983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the length of the sequence: \n",
    "m = 30 \n",
    "# The length of the embeddings: \n",
    "e = 50\n",
    "X_trainmod = gvec_input(X_train,m,e) \n",
    "X_testmod = gvec_input(X_test,m,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "058fc745-0c8b-456d-8c03-f48b4cee67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79238999  0.21864     0.68711001 ... -0.066753   -0.39660001\n",
      "   0.74818999]\n",
      " [ 0.36998999  0.082841    0.16883001 ...  0.0053184  -0.50853002\n",
      "   0.24986   ]\n",
      " [ 0.02648     0.33737001  0.065667   ... -0.3398     -0.23043001\n",
      "   0.19069   ]\n",
      " ...\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1125, 30, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_trainmod[0])\n",
    "X_trainmod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2610eef7-b508-4824-986e-26fa7a3a42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_mask(tensor): \n",
    "    \"\"\"\n",
    "    this function will encode the padded sequences as -1e-9 so that when they are run through a Softmax, the value will be equal to zero. \n",
    "    \"\"\"\n",
    "    # Identify rows where all elements are zero\n",
    "    is_zero_row = tf.reduce_all(tf.equal(tensor, 0), axis=1)\n",
    "\n",
    "    # Expand is_zero_row to match the shape of tensor\n",
    "    is_zero_row_expanded = tf.expand_dims(is_zero_row, axis=-1)\n",
    "\n",
    "    # Replace zeros with -1e-9 where the row is all zeros\n",
    "    result_tensor = tf.where(is_zero_row_expanded, tf.constant(-1e-9, dtype=tf.float64), tensor)\n",
    "    return(result_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276cf1ef-cb5f-4700-a9cf-3c5bcb130d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now time to define the self_attention: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d6376dbc-8cdc-4021-864d-00d204ab466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(q,k,v, masking):\n",
    "    \"\"\"\n",
    "    this function calculates a self_attention mechanism \n",
    "    res are the final attention scores. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Perform matrix multiplication on the last two dimensions\n",
    "    dotqk = tf.matmul(q, k, transpose_b = True)\n",
    "\n",
    "    dim_k = tf.cast(k.shape[-1],tf.float32)\n",
    "    normalized_dotqk = dotqk/tf.math.sqrt(dim_k)\n",
    "    \n",
    "    #then add the masking if masking if given\" \n",
    "    if masking is not None: \n",
    "        normalized_dotqk += (1 - masking)* (-1e9)\n",
    "    \n",
    "    attention_scores =  tf.nn.softmax(tf.cast(normalized_dotqk, dtype=tf.float32),axis = -1)\n",
    "    res = tf.matmul(attention_scores,v) \n",
    "    \n",
    "    return(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e32d7c66-8e34-40be-be57-749847459aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 30, 20)\n",
      "(1125, 30, 30)\n",
      "(1125, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "print(dense_q.shape)\n",
    "print(dense_k.shape)\n",
    "print(dense_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d658dee0-13c1-4a74-8123-a1ddecdee97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 2, 10, 30)\n",
      "(1125, 2, 15, 30)\n",
      "(1125, 2, 15, 30)\n"
     ]
    }
   ],
   "source": [
    "#reshape the q, k, v matrices: \n",
    "reshaped_q = reshape_tensor(dense_q, 2, pre_attention = True)\n",
    "reshaped_k = reshape_tensor(dense_k, 2, pre_attention = True) \n",
    "reshaped_v =  reshape_tensor(dense_v, 2 ,pre_attention  = True) \n",
    "\n",
    "print(reshaped_q.shape)\n",
    "print(reshaped_k.shape)\n",
    "print(reshaped_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2e54a302-30bd-4791-bbd5-9c1160b10f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 30, 10, 2)\n",
      "(1125, 30, 2, 15)\n"
     ]
    }
   ],
   "source": [
    "q_transposed = tf.transpose(reshaped_q, perm=[0, 2, 3, 1])  # shape: (#sample, #head, 30, 10)\n",
    "k_transposed = tf.transpose(reshaped_k, perm=[0, 2, 1, 3])\n",
    "print(q_transposed.shape)\n",
    "print(k_transposed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "11c3cada-a0d8-4a1c-95f8-9bd3a37aa481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1125, 2, 10, 30])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the attention scores: \n",
    "attention_scores = self_attention(reshaped_q, reshaped_k, reshaped_v, None)\n",
    "attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b854b-4baa-4b39-990a-22f7675947ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_tensor(attention_scores, heads, pre_attention = False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47e973-6b52-4261-ac14-c877622f21e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f50c7c-0562-4c2a-ac00-a5c954f75b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1db727d-28ce-4222-93ce-3d0add3c5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([[[1, 1, 0, 1], [1, 1, 0, 1], [1, 1, 0, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "390f092f-2c00-41ec-b8e8-e4971c9473ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0.2589478 , 0.42693272, 0.15705977, 0.15705977],\n",
       "       [0.2772748 , 0.2772748 , 0.2772748 , 0.16817567],\n",
       "       [0.33620113, 0.33620113, 0.12368149, 0.2039163 ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention(q,k,v,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c6dfc37-d963-47b1-b080-54855b16080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.3071959 , 0.5064804 , 0.        , 0.18632373],\n",
       "        [0.38365173, 0.38365173, 0.        , 0.23269655],\n",
       "        [0.38365173, 0.38365173, 0.        , 0.23269655]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention(q,k,v,mask)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d24857a1-8baa-43b3-88ba-bf4af7b97f9c",
   "metadata": {},
   "source": [
    "def padding_mask(tensor): \n",
    "    \"\"\"\n",
    "    This function encodes the padded sequences as -1e-9 so that when they are run through a Softmax, the value will be equal to zero. \n",
    "    This version is adapted for a 2D tensor input.\n",
    "    \"\"\"\n",
    "    # Ensure the tensor has at least 2 dimensions\n",
    "    if tf.rank(tensor) != 2:\n",
    "        raise ValueError(\"Input tensor must be 2D with shape [sequence_length, embedding_size].\")\n",
    "    \n",
    "    # Identify rows where all elements are zero\n",
    "    is_zero_row = tf.reduce_all(tf.equal(tensor, 0), axis=1)\n",
    "\n",
    "    # Expand is_zero_row to match the shape of tensor\n",
    "    is_zero_row_expanded = tf.expand_dims(is_zero_row, axis=-1)\n",
    "\n",
    "    # Replace zeros with -1e-9 where the row is all zeros\n",
    "    result_tensor = tf.where(is_zero_row_expanded, tf.constant(-1e-9, dtype=tensor.dtype), tensor)\n",
    "    \n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbadeff-f5df-457a-8c51-2b22fba90fe7",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> Review masked functions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c10984-8a5d-4d05-9301-0fee3991b7f8",
   "metadata": {},
   "source": [
    "Preferably, we want the input of the Encoder structure to already have the word embeddings and the positional encodings. In the Encoder structure, we will have the multi-head attention (think of it as running the self-attention multiple times) and a fully connected neural network which will be called FullFeedForward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "645c8842-8c75-4d7d-84f6-7cc6dc1a2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullFeedForward(n_1, emb_size):#the model must return vectors of the same size as the embeddings of the input so can be combined with decoder\n",
    "    model = Sequential([\n",
    "    Dense(n_1, activation='tanh', name=\"dense1\"), #relu? (#samples, len_seq, n_1)\n",
    "    Dense(emb_size, activation='tanh', name=\"dense2\")# linear? (#samples, len_seq, emb_size)\n",
    "])\n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e1408-13cd-4dec-a8dd-5b3a1aa5f512",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Why is the embedding size also taken as an argument in MHA? we get matrices q, k, and v. The product of qTk will give a dim_k or dim_q by emb_size. The final product in the attention mechanism must yield a matrix of the same length of seq and emb_size. \n",
    "\n",
    "* look into the command of MHA.\n",
    "* LayerNormalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba488292-2fd2-4f80-9eaa-962064cb7ca3",
   "metadata": {},
   "source": [
    "### Multi-head attention? \n",
    "We will input 3 xs (possibly they could be different?) then the inputs are mapped linearly to give us the matrices Query, Key and Value. \n",
    "* dimension x (#batches, len_seq, len_emb)\n",
    "* dim of k:$K^T x$ if k is (len_seq,dim_k), then its transpose is (dim_k, len_seq), the resultant matrix is going to have dim (dim_k, len_emb)\n",
    "* dim of q: $Q^T x $; if q is (len_seq,dim_q), then its transpose is of dim (dim_q, len_emb) and the resultant dot product gives (dim_q,len_emb)\n",
    "* Similarly, for the multiplication of $V^T x$, we have the value being of dimension (dim_v, len_emb).\n",
    "  * if it is a self-attention (attention with only one head), then $qk^T$ has dim (dim_q, dim_k), scale, add the mask and dropout if given.\n",
    "  * if it has n heads, then we will produce query and key matrices of dimensions dim_q/n, dim_k/n. After the dot product, the result is of dim (dim_q/n, dim_k/n). We then concatenate these results to get the desired dim of (dim_q,dim_k). $ \\bold{make sure you understand the concatenation} $\n",
    "* dot prodcut v (dim_v, len_emb) qTk (dim_q, dim_k) --> $ qTk .v $ Note that here dim_k must be the same as the dimension of v for this dot product to occur.\n",
    "* just like magic, you have the attention scores now and the result is a matrix of (dim_k, len_emb).\n",
    "* so then we add our initial x and normalize too. in order to add x to the attention scores, the attention scores need to have the same dim as x. meaning that dim_k needs to be the same as the len of the sequence.\n",
    "\n",
    "### Fully Connected Neural Network: \n",
    "\n",
    "We feed the matrix out of the attention mechanism into the fully connected neural network. how many neurons? what matters is that the output layer must have len_emb neurons in order to match the dim of x. why do we need them to match? becoz we again add the input seq x to the result (after another layer of normalization). \n",
    "\n",
    "Then copy the result, pass as key and value to the decoder network. \n",
    "\n",
    "# Question isn't the dot product we are talking here actually a cross product?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc1c8d12-2822-4f45-b2ff-0ffa7fa5e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(q_matrix, heads, pre_attention): \n",
    "    \n",
    "    #pre_attention, we'll need to reform into 4d \n",
    "    if pre_attention:\n",
    "\n",
    "        dense_qre = reshape(q_matrix, (shape(q_matrix)[0], shape(q_matrix)[1], heads, -1))\n",
    "        dense_qre = transpose(dense_qre, ([0, 2, 3, 1]))\n",
    "        \n",
    "        \n",
    "    #post_attention, we'll need to revert back to 3d: \n",
    "    else: \n",
    "        q_matrix_transpose = transpose(q_matrix, ([0,3,1,2]))\n",
    "        dense_qre = reshape(q_matrix_transpose, (shape(q_matrix_transpose)[0], shape(q_matrix_transpose)[1], -1)) \n",
    "        \n",
    "        \n",
    "    return(dense_qre)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a1380463-0062-4718-b56c-dd21b0823aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class MultiHeadAttention(Layer):  # Ensure this name matches in `super()`\n",
    "    def __init__(self, dim_kv, dim_q, len_emb, heads, masking, **kwargs):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)  # Ensure the class name here is correct\n",
    "        self.dim_k = self.dim_v = dim_kv\n",
    "        self.dim_q = dim_q\n",
    "        self.heads = heads\n",
    "        self.masking = masking\n",
    "        self.d_model = len_emb\n",
    "\n",
    "    \n",
    "    def call(self,x,**kwargs): #by passing self, you passed all the attributes you've defined above. \n",
    "        dense_q = Dense(units = self.dim_q)(x) # shape = (#samples, len_seq, dim_q)\n",
    "        dense_k = Dense(units = self.dim_k)(x) # shape = (#samples, len_seq, dim_k) \n",
    "        dense_v = Dense(units = self.dim_v)(x) # shape = (#samples, len_seq, dim_v) \n",
    "        \n",
    "        # Reshape: \n",
    "        dense_qre = reshape_tensor(dense_q, heads, pre_attention = True) #shape = (#samples, #heads, dim_q/heads, len_seq)\n",
    "        dense_kre = reshape_tensor(dense_k, heads, pre_attention = True) #shape = (#samples, #heads, dim_k/heads, len_seq)\n",
    "        dense_vre = reshape_tensor(dense_v, heads, pre_attention = True) #shape = (#samples, #heads, dim_v/heads, len_seq) \n",
    "        \n",
    "        # Calculate the attention scores: \n",
    "        attention_scores = self_attention(dense_qre, dense_kre,dense_vre, masking) #shape = (#samples, #heads, dim_q/heads, len_seq)\n",
    "        \n",
    "        # Revert the shape:\n",
    "        attention_with_v = reshape_tensor(attention_scores, heads, pre_attention = False) #shape = (#samples, len_seq, dim_q)\n",
    "        \n",
    "        # Run through another dense and add to the initial x: \n",
    "        res = Dense(units = self.d_model)(attention_with_v) + x  # shape = (#samples, len_seq, d_model) \n",
    "        #how to add the dropout and the normalization layers? \n",
    "        return(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0ce61987-9ca6-4042-ae9d-846c54c1199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1125, 30, 50])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_kv = 30 \n",
    "dim_q = 20 \n",
    "len_emb = 50\n",
    "heads = 2 \n",
    "\n",
    "masking = None \n",
    "\n",
    "function = MultiHeadAttention(dim_kv, dim_q, len_emb, heads, None)\n",
    "function(X_trainmod).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c89b0f-fd06-4f4b-ace0-b7d86134303b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92f969-6166-496c-898b-da33f567ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer (tf.keras.layers.Layer): #what does this mean? this means that the class we are defining is child to the \n",
    "                                            #parent environment keras.layers.Layer. so when Layer is loaded this will be also loaded? no this \n",
    "                                            #will be defined in this environment. \n",
    "    #initialize the attributes? what are the attributes of the encoder layer? \n",
    "    #how do we initialize the q, k, and v matrices? \n",
    "    #how is this model trained? \n",
    "    \n",
    "    #is the x being fed here with the embeddings and positional encodings? \n",
    "    def __init__(self, num_head, emb_size, n_1, var_norm = , var_drop) #n_1 is the number of neurons in the ffn. \n",
    "    #don't know what the integer var_norm does. \n",
    "\n",
    "    #then define the multi head attribute of this class so when called this will be a function: #read about the MHA command in python\n",
    "    self.mha = MultiHeadAttention(num_head = num_head, emb_size = emb_size, var_drop)#, #what else do we need\n",
    "    #define the fully forward neural network \n",
    "    self.ffn = FullFeedForward(n_1, emb_size) #why do we need the emb_size? #the output when gone through must have \n",
    "                                              #the same dims as the input. so if n by emb_size is given, then n by emb_size must \n",
    "                                              #be outputted. therefore, both for the mha and the ffn, the last layer needs to take care         \n",
    "                                             #of the dim of the output and therefore needs the emb_dim. \n",
    "    #define the layer normalizations. what happens if we only define one layer and apply it twice? \n",
    "    #get to know the command layer normalization. \n",
    "    self.NormalizedLayer1 = LayerNormalization(var_norm) #don't know other inputs required. \n",
    "    self.NormalizedLayer2 = LayerNormalization(var_norm) #don't know other inputs required. \n",
    "    #we also define a dropout function here. what is its role? \n",
    "    #where do we define the dropout and why where is it automatic and where should we define it? does it really make a differnce? \n",
    "    #dropout will be applied to both layers one to the attention layer and one to the ffn. multi-head already has the command built-in. \n",
    "    self.dropout = Dropout(var_drop) #don't know other inputs reuqired. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe40d6-1c74-471e-bd0e-914365959944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21020813-3ebe-4b40-be49-9c48f9f6fe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddfd23-3ba1-4267-99b5-79f9a3d0e047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ecd096-90a3-4431-911d-6d184e58037c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75cbb94-77cc-4907-a737-fd8d5d907a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1a681-d589-4c5a-af70-70b821da0fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a127b8-7c92-423c-ad0d-68ea6ee5775d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceffbfc-f314-42ae-af33-9a76f37e9d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ec1c1-3e8f-4ac4-bda1-b0627002e3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05c982-2eb9-4a6b-8b84-49b7321ecc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb7119-f21d-4d72-adc7-8fbaeb1abe10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd27a212-c483-4c34-bf7e-437f2e5d3064",
   "metadata": {},
   "source": [
    "My intuition is that when the output is not normalized, the algo will be caught in many local minima or maxima and cannot easily and quickly converge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2562cd5-4af8-4ed6-b838-fe0d530ad92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer): #here the brackets mean that this class will be part of the layers in keras and can be used like \n",
    "                                        #any other layer like Dense or multi-head. \n",
    "\n",
    "    #specifies some attributes in brackets: \n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6): \n",
    "        super(EncoderLayer, self).__init__() #this specifies that EncoderLayer will have all the attributes of layer.\n",
    "    #now define the multi-head: \n",
    "    self.mha = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FullyConnected(embedding_dim=embedding_dim,\n",
    "                                fully_connected_dim=fully_connected_dim)\n",
    "\n",
    "    self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "    self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "    self.dropout_ffn = Dropout(dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21790d2e-aee3-4d60-9fbf-4f9d27684db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9e895-e86d-407e-8c8c-ea7c85d83e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9678cc-2b85-4654-9aa5-4fe96993e28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8488cf-25ac-4a3a-9a81-21f60ef83a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5602fc-fea1-4eb4-a771-d44f0120c2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

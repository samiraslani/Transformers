{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91892c6-90fa-48e6-9a7b-2e173e4b0a5c",
   "metadata": {},
   "source": [
    "The objective of this project is to: \n",
    "* Create positional encodings to capture sequential relationships in data\n",
    "* Calculate scaled dot-product self-attention with word embeddings\n",
    "* Implement masked multi-head attention\n",
    "* Build and train a Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf32da35-c73d-4fd9-ac13-b9611a826739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required packages: \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization, Layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import  reshape, shape, transpose, ones, linalg\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336901d7-5379-461c-a943-ee19e2929ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(y): \n",
    "    '''\n",
    "    This function maps the probabilities outputed by the model back to the rankings list \n",
    "    and outputs the ranking with the highest probability. \n",
    "    \n",
    "    inputs: \n",
    "    y  (1,m)     : Probability output of the RNN model \n",
    "    \n",
    "    outputs: \n",
    "    res (string) : The ranking corresponding to the most probable outcome. \n",
    "    \n",
    "    '''\n",
    "    y = y.tolist()\n",
    "    #ranking = ['Below Average' , 'Average' , 'Above Average']\n",
    "    res = ranking[y.index(max(y))]\n",
    "    return(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93292b78-55cb-415e-b26f-537ab511c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to write another function that maps the correct output of the function to the rankings. \n",
    "def vec_output(y): \n",
    "    m = len(ranking)\n",
    "    txt = y\n",
    "    v = np.zeros(m) \n",
    "    j = ranking.index(txt)\n",
    "    v[j] = 1\n",
    "    return v \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45966623-2e5e-49d6-bcd4-7d301a610f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               reviewId            userName  \\\n",
      "0     gp:AOqpTOFxf3fttcT5DSvFIn9KPp5FErgH9yC533Fmoxv...      Donna Caritero   \n",
      "1     gp:AOqpTOEq6rNIWLnPV4KFTctWvm0mpGEQljtD6mvy1H-...  Soumi Mukhopadhyay   \n",
      "2     gp:AOqpTOE86hSyPRHZgYt28Uk5zGe4FZGb1hkmtFDiYJ2...   Theknown _unknown   \n",
      "3     gp:AOqpTOHSuKkVTcM3QgCCKysHQlxEnk2ocOKsUMiMIJy...        Anthony Dean   \n",
      "4     gp:AOqpTOEOrZt5H6jXPiplJyffCd5ZBnVXACTWgwNsF1R...   Neha Diana Wesley   \n",
      "...                                                 ...                 ...   \n",
      "1495  gp:AOqpTOHhnXMpylU3f-1V1KbR2hwWArOilxPlKI6K4xY...            Reen Ali   \n",
      "1496  gp:AOqpTOEcz62DHS-amqTB5xGMhM4_R0UJpcv_HDNny9i...     Shaurya Chilwal   \n",
      "1497  gp:AOqpTOFMqEqa_kpp29Q8wjcBmKUCAvOQGQx4KZQ8b83...           GK Gaming   \n",
      "1498  gp:AOqpTOGY4z3pUxeiqGzn2ad3Noxqlbm-9DZ3ksHqD1_...    1203_Vani Sharma   \n",
      "1499  gp:AOqpTOFVGZ0MXyR-Gv_d2cYf2KD709Hwple_u7OZE4y...           MeLLy EcK   \n",
      "\n",
      "                                              userImage  \\\n",
      "0     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "2     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "3     https://play-lh.googleusercontent.com/a/AATXAJ...   \n",
      "4     https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "...                                                 ...   \n",
      "1495  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1496  https://play-lh.googleusercontent.com/a/AATXAJ...   \n",
      "1497  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1498  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "1499  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
      "\n",
      "                                                 review  score  thumbsUpCount  \\\n",
      "0     Overall it's really an amazing app. I've been ...      4            528   \n",
      "1     Hey! Yes I gave a 5 star rating... coz I belie...      5            351   \n",
      "2     Canva used to be a good app! But recently I've...      1            160   \n",
      "3     It's a brilliant app, but I have just one prob...      5            145   \n",
      "4     This was such a great app. I used to make BTS ...      4            142   \n",
      "...                                                 ...    ...            ...   \n",
      "1495   Absolutely amazing and a lifesaver for teachers.      5              0   \n",
      "1496  Very nice but many a times shows error opening...      3              0   \n",
      "1497  Too much lag. Always stuck on starting page. W...      1              0   \n",
      "1498  Nice app for all college work. So many feature...      5              0   \n",
      "1499  I am a teacher and this was so much for this s...      5              0   \n",
      "\n",
      "     reviewCreatedVersion                  at  \\\n",
      "0                 2.116.0 2021-06-17 07:18:54   \n",
      "1                 2.116.0 2021-06-17 19:18:28   \n",
      "2                 2.116.0 2021-06-23 19:13:28   \n",
      "3                 2.116.0 2021-06-19 23:36:07   \n",
      "4                 2.116.0 2021-06-21 00:29:27   \n",
      "...                   ...                 ...   \n",
      "1495              2.127.0 2021-09-07 02:45:51   \n",
      "1496              2.123.0 2021-08-14 07:36:50   \n",
      "1497              2.118.0 2021-07-06 03:34:38   \n",
      "1498              2.123.0 2021-08-07 18:47:15   \n",
      "1499              2.117.0 2021-06-28 03:40:57   \n",
      "\n",
      "                                           replyContent           repliedAt  \\\n",
      "0     Hi Donna. We are sorry that your text or desig... 2021-06-19 21:24:32   \n",
      "1                                                   NaN                 NaT   \n",
      "2     Hi there. We're sorry to hear that you are hav... 2021-06-26 20:20:56   \n",
      "3                                                   NaN                 NaT   \n",
      "4     Hi Neha. Sorry to hear that you are unable to ... 2021-06-24 20:46:28   \n",
      "...                                                 ...                 ...   \n",
      "1495                                                NaN                 NaT   \n",
      "1496  Hi Shaurya, we're sorry if the app shows error... 2021-08-22 00:07:12   \n",
      "1497  Hello there, sorry if it is frustrating and ju... 2021-07-19 01:19:18   \n",
      "1498                                                NaN                 NaT   \n",
      "1499                                                NaN                 NaT   \n",
      "\n",
      "     Sentiment              Sub Category    Sub Category_test  \n",
      "0     Negative                       NaN  bug_picture_quality  \n",
      "1     Positive           extremely_happy                  NaN  \n",
      "2     Negative  saving_downloading_issue     bug_saving_files  \n",
      "3     Negative                    others        bug_app_crash  \n",
      "4     Negative                    others            bug_other  \n",
      "...        ...                       ...                  ...  \n",
      "1495  Positive           extremely_happy                  NaN  \n",
      "1496  Negative                    others                  NaN  \n",
      "1497  Negative                    others                  NaN  \n",
      "1498  Positive           extremely_happy                  NaN  \n",
      "1499  Positive           extremely_happy                  NaN  \n",
      "\n",
      "[1500 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading the data: \n",
    "CustomerFeed = 'Canva_reviews.xlsx'\n",
    "df = pd.read_excel(CustomerFeed)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed01bd6-e55b-40da-b78c-dacc052aa824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall it's really an amazing app. I've been ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey! Yes I gave a 5 star rating... coz I belie...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canva used to be a good app! But recently I've...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a brilliant app, but I have just one prob...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This was such a great app. I used to make BTS ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review Sentiment\n",
       "0  Overall it's really an amazing app. I've been ...  Negative\n",
       "1  Hey! Yes I gave a 5 star rating... coz I belie...  Positive\n",
       "2  Canva used to be a good app! But recently I've...  Negative\n",
       "3  It's a brilliant app, but I have just one prob...  Negative\n",
       "4  This was such a great app. I used to make BTS ...  Negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"review\", \"Sentiment\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517047a2-9096-4a74-9e01-05676b9bd5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_txt(review):\n",
    "    \"\"\"\n",
    "    This function receives a text and returns it edited as follows: \n",
    "    1, all words converted to lower case \n",
    "    2, integers removed\n",
    "    3, tokenize the words \n",
    "    4, punctuation removed \n",
    "    5, common words that are unnecessary are removed. \n",
    "    \"\"\"\n",
    "    \n",
    "    review_edited = []\n",
    "\n",
    "    #Converting to lower case: \n",
    "    review_edited = review.lower() \n",
    "    \n",
    "    #Removing integers: \n",
    "    pattern = r'[0-9]'\n",
    "    # Match all digits in the string and replace them with an empty string\n",
    "    review_edited = re.sub(pattern, '', review_edited) \n",
    "\n",
    "    #Tokenize the comment: \n",
    "    review_edited = word_tokenize(review_edited) \n",
    "\n",
    "    #Removing punctuation \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    review_edited = [''.join(tokenizer.tokenize(word)) for word in review_edited if len(tokenizer.tokenize(word))>0]\n",
    "\n",
    "    #Removing common words: \n",
    "    #remove_list = stopwords.words('english') \n",
    "    #to_remove = [ \"not\",'don',\"don't\",'should',\"should've\", 'ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven',\"haven't\",'isn',\"isn't\",'mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn', \"wouldn't\"]\n",
    " \n",
    "    #review_edited = [word for word in review_edited if not word in remove_list]\n",
    "    return(review_edited) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd96cb6-6ee5-4019-ac4d-a0fcfe27b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Really great editing app, its all around which makes it great. Has everything I need for basic editing. It makes editing easier because of premade tools and stickers, designs, etc. I gave it four stars only because of how slow it loads, especially at starting the app. It is pretty stressful, so you really gotta have patience at waiting for stuff to load.\n",
      "\n",
      "Corresponding ranking: Positive\n",
      "\n",
      "Rankigns include ['Negative', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "# Defining the review dataset as x: \n",
    "x = df[\"review\"] \n",
    "dfrank = df.iloc[:,1]\n",
    "\n",
    "print(x[10])\n",
    "\n",
    "y = df[\"Sentiment\"].tolist()\n",
    "ranking = np.unique(y)\n",
    "ranking = ranking.tolist()\n",
    "print(f\"\\nCorresponding ranking: {y[10]}\\n\")\n",
    "print(f\"Rankigns include {ranking}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b5b06c-8007-44e0-927c-43470a4c7b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment before editting: Unable to save my work. Nothing works :(\n",
      "Comment after editting: ['unable', 'to', 'save', 'my', 'work', 'nothing', 'works']\n",
      "['_', 'a', 'aa', 'aap', 'ability', 'able', 'about', 'above', 'absolutely', 'acc', 'accepted', 'access', 'accessibilities', 'accessible', 'accidentally', 'accoding', 'according', 'account', 'across', 'action', 'activity', 'actual', 'actually', 'ad', 'adaptable', 'add', 'added', 'adding', 'addition', 'address']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2317"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dictionary: \n",
    "reviews_edited = [edit_txt(review) for review in x]\n",
    "print(f\"Comment before editting: {x[13]}\")\n",
    "print(f\"Comment after editting: {reviews_edited[13]}\")\n",
    "\n",
    "Split = [] \n",
    "Dic = []\n",
    "dictionary = np.unique([word for review in reviews_edited for word in review]).tolist()\n",
    "print(dictionary[0:30])\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7081a45c-6f89-4650-a7db-25ef012a7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word embeddigns:\n",
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.50d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "\n",
    "words =  list(embeddings_dict.keys())\n",
    "vectors = [embeddings_dict[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "441f1982-69c4-4728-a6bf-22a173deabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the dataset into 75% training set and 25% test set: \n",
    "x = x.to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd8bb1f-c770-4e01-b7be-55d2fd03daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the text in the training and texting datasets: \n",
    "X_train = [edit_txt(comment) for comment in X_train]\n",
    "X_test = [edit_txt(comment) for comment in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ccb410-cf01-42cb-856e-36bce73fa80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'spend',\n",
       " 'so',\n",
       " 'much',\n",
       " 'time',\n",
       " 'in',\n",
       " 'working',\n",
       " 'a',\n",
       " 'poster',\n",
       " 'and',\n",
       " 'the',\n",
       " 'app',\n",
       " 'is',\n",
       " 'not',\n",
       " 'allowing',\n",
       " 'to',\n",
       " 'download',\n",
       " 'simply',\n",
       " 'wasted',\n",
       " 'my',\n",
       " 'hard',\n",
       " 'work']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24993869-fed5-49e8-bbb3-7c2974df863c",
   "metadata": {},
   "source": [
    "## Creating the word embeddings based on GloVe embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72957b17-242f-42a0-bdff-f77ef8329a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the input with Glove Word Embeddings: \n",
    "def gvec_input(x,m,e): \n",
    "    \"\"\"\n",
    "    \n",
    "    This function takes any input, x, and returns a glove vector based on the \n",
    "    words introduced in the vocabulary (400,000 words). This function returns k vectors where k is the number of words in the \n",
    "    sentence. Every vector corresponds to a word in the dictionary and each entry will describe a feature of the word. \n",
    "    \n",
    "    inputs: \n",
    "    \n",
    "    x (string) : a statement from customers. \n",
    "    m (int)    : size of the sequence \n",
    "    e (int)    : size of the embeddings \n",
    "    outputs: \n",
    "    v (m,n)    : where m is the number of words in the sentence and n = 50 is the number of total features describing a word. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "    gv = np.zeros((n,m, e))\n",
    "    \n",
    "    for i in range(0, n): #looping over each comment \n",
    "        txt = x[i] #select the ith comment  \n",
    "        txt = (txt[:m] if len(txt) > m else txt + ['<pad>'] * (m - len(txt))) #shorten or add extra padding\n",
    "        for l in range(m): #looping over each word \n",
    "            \n",
    "            # add the embedding of all ones for pads\n",
    "            if txt[l] == \"<pad>\": \n",
    "                gv[i,l,:] = np.zeros(e) \n",
    "                \n",
    "            # if a word is not is the list of Glove embeddings, then assign an array which is the average of all embeddings:    \n",
    "            elif txt[l] not in words: \n",
    "                gv[i,l,:] = np.mean(vectors, axis = 0)\n",
    "            # add the word embeddings: \n",
    "            else: \n",
    "                gv[i,l,:] = embeddings_dict[txt[l]]\n",
    "    return(gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e84cded1-8bc4-4eec-9f9b-cccb5b98983b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit the length of the sequence: \n",
    "m = 30 \n",
    "# The length of the embeddings: \n",
    "e = 50\n",
    "X_trainmod = gvec_input(X_train,m,e) #X_train is training dataset modified (edited and tokenized);\n",
    "                                     # shape of X_trainmod (#samples, len_seq, len_emb) \n",
    "\n",
    "X_testmod = gvec_input(X_test,m,e)   #X_test will be the testing dataset modified (edited and tokenized) \n",
    "                                     # shape of X_testmod (#samples, len_seq, len_emb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3be0f25-1775-4187-ba5c-a061b13ba539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11891     0.15255    -0.082073   ... -0.57511997 -0.26671001\n",
      "   0.92120999]\n",
      " [ 0.79238999  0.21864     0.68711001 ... -0.066753   -0.39660001\n",
      "   0.74818999]\n",
      " [ 0.60307997 -0.32023999  0.088857   ... -0.25187001 -0.26879001\n",
      "   0.36657   ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "(1125, 30, 50)\n",
      "(375, 30, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_trainmod[0])\n",
    "print(X_trainmod.shape)\n",
    "print(X_testmod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb98c58-011d-43fb-b5f7-e93ae79e9107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map the y_training and y_testing datasets to Boolean 0, 1: \n",
    "y_trainmod = (np.array([vec_output(y) for y in y_train])).reshape(len(y_train), len(ranking))\n",
    "y_testmod = (np.array([vec_output(y) for y in y_test])).reshape(len(y_test),len(ranking))\n",
    "y_trainmod[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824583e-f0dd-499d-a464-3f5a424ba195",
   "metadata": {},
   "source": [
    "## Define the self attention: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d6376dbc-8cdc-4021-864d-00d204ab466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(q,k,v, masking):\n",
    "    \"\"\"\n",
    "    This function applied the self-attention mechanism to a given input. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform matrix multiplication on the last two dimensions\n",
    "    dotqk = tf.matmul(q, k, transpose_b = True) #must be of size (batch_size, seq_len, seq_len) \n",
    "\n",
    "    dim_k = tf.cast(k.shape[-1],tf.float32) \n",
    "    normalized_dotqk = dotqk/tf.math.sqrt(dim_k)\n",
    "    \n",
    "    #then add the masking if masking if given\" \n",
    "    if masking is not None: \n",
    "        normalized_dotqk += masking* -1e9\n",
    "    \n",
    "    attention_scores =  tf.nn.softmax(tf.cast(normalized_dotqk, dtype=tf.float32),axis = -1)\n",
    "    res = tf.matmul(attention_scores,v) \n",
    "    \n",
    "    return(attention_scores, res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d82d35-b01d-4f64-b60e-742859cd1516",
   "metadata": {},
   "source": [
    "## Define the Padding Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2610eef7-b508-4824-986e-26fa7a3a42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(matrix,num_heads):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        seq -- (n, m) matrix\n",
    "    \n",
    "    Returns:\n",
    "        mask -- (n, 1, 1, m) binary tensor\n",
    "    \"\"\"\n",
    "    # Check if each row is all zeros\n",
    "    zero_rows = np.all(matrix == 0, axis=2)\n",
    "    \n",
    "    # Convert boolean array to integer array (0s and 1s)\n",
    "    padded_mask = zero_rows.astype(int)\n",
    "    # Expand to make 4D: \n",
    "    expanded_padding_mask_init = tf.expand_dims(padded_mask, axis=1)\n",
    "    expanded_padding_mask_final = tf.expand_dims(expanded_padding_mask_init, axis=1)\n",
    "    # Repeat for each head: \n",
    "    final_mask = tf.cast(tf.tile(expanded_padding_mask_final, [1, num_heads, 1, 1]),tf.float32)  # (batch_size, num_heads, 1, seq_len)\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "54b397ff-7638-4482-bdbd-1d669b49f564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1125, 2, 1, 30])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the padding mask depending on the number of heads in the multi-head attention: \n",
    "padding_mask= create_padding_mask(X_trainmod,2) \n",
    "padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "94fd8f9f-995f-464c-871d-f97b15e0c0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "   1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "   1. 1. 1. 1. 1. 1. 1.]]], shape=(2, 1, 30), dtype=float32)\n",
      "\n",
      "Two matrices will be printed, each corresponding to the masking for a head. \n",
      "Note that the same padding mask will be applied to all heads sicne the source sample is the same.Indexes up to 21st are all zero meaning that no masking is required for these words but the rest must be masked\n"
     ]
    }
   ],
   "source": [
    "# Print the padding mask corresponding to the first sample in the dataset: \n",
    "print(padding_mask[0])\n",
    "print(f\"\\nTwo matrices will be printed, each corresponding to the masking for a head. \\n\"\n",
    "       \"Note that the same padding mask will be applied to all heads sicne the source sample is the same.\"\n",
    "        \"Indexes up to 21st are all zero meaning that no masking is required for these words but the rest must be masked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f306b59-a2ca-4df6-9b2c-b4db5480955d",
   "metadata": {},
   "source": [
    "#### Try how it works: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f9b5bd6a-5d6b-48a0-9e23-eb6083bf18e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11891     0.15255    -0.082073   ... -0.57511997 -0.26671001\n",
      "   0.92120999]\n",
      " [ 0.79238999  0.21864     0.68711001 ... -0.066753   -0.39660001\n",
      "   0.74818999]\n",
      " [ 0.60307997 -0.32023999  0.088857   ... -0.25187001 -0.26879001\n",
      "   0.36657   ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "\n",
      "Here is the 21st word of the first samlpe feedback: [ 5.13589978e-01  1.96950004e-01 -5.19439995e-01 -8.62179995e-01\n",
      "  1.54940002e-02  1.09729998e-01 -8.02929997e-01 -3.33609998e-01\n",
      " -1.61189993e-04  1.01889996e-02  4.67340015e-02  4.67510015e-01\n",
      " -4.74750012e-01  1.10380001e-01  3.93269986e-01 -4.36520010e-01\n",
      "  3.99839997e-01  2.71090001e-01  4.26499993e-01 -6.06400013e-01\n",
      "  8.11450005e-01  4.56299990e-01 -1.27260000e-01 -2.24739999e-01\n",
      "  6.40709996e-01 -1.27670002e+00 -7.22310007e-01 -6.95900023e-01\n",
      "  2.80450005e-02 -2.30719998e-01  3.79959989e+00 -1.26249999e-01\n",
      " -4.79669988e-01 -9.99719977e-01 -2.19760001e-01  5.05649984e-01\n",
      "  2.59530004e-02  8.05140018e-01  1.99290007e-01  2.87959993e-01\n",
      " -1.59150004e-01 -3.04380000e-01  1.60249993e-01 -1.82899997e-01\n",
      " -3.85629982e-02 -1.76190004e-01  2.70409994e-02  4.68420014e-02\n",
      " -6.28970027e-01  3.57259989e-01]\n",
      "\n",
      "Zero paddings start from position 22 in the sequence: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example: \n",
    "# Note that the first sample in the dataset has a length of \n",
    "print(X_trainmod[0])\n",
    "print(f\"\\nHere is the 21st word of the first samlpe feedback: {X_trainmod[0][21]}\\n\")\n",
    "print(f\"Zero paddings start from position 22 in the sequence: {X_trainmod[0][22]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "741f090a-8d83-4413-a148-9212695ff86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 30), dtype=float32, numpy=\n",
       "array([[[-0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00,\n",
       "         -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00,\n",
       "         -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00,\n",
       "         -0.e+00, -1.e+09, -1.e+09, -1.e+09, -1.e+09, -1.e+09, -1.e+09,\n",
       "         -1.e+09, -1.e+09]],\n",
       "\n",
       "       [[-0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00,\n",
       "         -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00,\n",
       "         -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00,\n",
       "         -0.e+00, -1.e+09, -1.e+09, -1.e+09, -1.e+09, -1.e+09, -1.e+09,\n",
       "         -1.e+09, -1.e+09]]], dtype=float32)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " padding_mask[0] * -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9c0ff967-fee9-4395-a3a0-8d0aa28b8a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Try the masking: \n",
    "\n",
    "# Define the query, key and, value matrices: \n",
    "dense_q = Dense(units = 20)(X_trainmod) # shape = (#samples, len_seq, dim_q)\n",
    "dense_k = Dense(units = 20)(X_trainmod) # shape = (#samples, len_seq, dim_k) \n",
    "dense_v = Dense(units = 30)(X_trainmod) # shape = (#samples, len_seq, dim_v) \n",
    "\n",
    "# Reshape the query, key, and value matrices: \n",
    "dense_qre = reshape_tensor(dense_q,2, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_q/heads)\n",
    "dense_kre = reshape_tensor(dense_k, 2, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_q/heads)\n",
    "dense_vre = reshape_tensor(dense_v, 2, pre_attention = True)\n",
    "\n",
    "attention_scores, res = self_attention(dense_qre,dense_kre,dense_vre, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "08dce66e-e733-4789-8f9b-13f7b728fd3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-2.4714701e+00 -1.6462295e+00 -2.0647089e+00 -2.1044219e+00\n",
      " -1.0884269e+00 -1.3197348e+00 -5.0339353e-01 -1.6755505e+00\n",
      " -1.3996890e+00 -1.2149099e+00 -1.1414751e+00  6.1669850e-01\n",
      " -1.9416343e+00 -1.2651926e+00  3.4386593e-01 -7.9303038e-01\n",
      "  1.0365025e+00 -8.2757193e-01  8.4825709e-02 -2.2144122e+00\n",
      " -1.3065406e+00 -5.2829480e-01 -1.0000000e+09 -1.0000000e+09\n",
      " -1.0000000e+09 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
      " -1.0000000e+09 -1.0000000e+09], shape=(30,), dtype=float32)\n",
      "\n",
      "If the normalized dot-product is passed through the Softmax this way, the amount of attention given to the padded vectors will not be zero.\n"
     ]
    }
   ],
   "source": [
    "print(normalized_dotqk[0][0][0])#this is the result of the dot-product for the first sample, first head, first word. \n",
    "print(f\"\\nIf the normalized dot-product is passed through the Softmax this way, the amount of attention given to the padded\"\n",
    "      \" vectors will not be zero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "431a305d-8632-41c5-a6ad-8df93cdaea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 2, 30, 30)\n",
      "tf.Tensor(\n",
      "[0.00690022 0.01574927 0.01036376 0.00996025 0.0275113  0.02183008\n",
      " 0.04938419 0.0152942  0.02015263 0.02424266 0.02608991 0.15136927\n",
      " 0.01172109 0.02305381 0.11522534 0.03696581 0.23033306 0.03571076\n",
      " 0.08893    0.00892282 0.02212003 0.04816965 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(attention_scores.shape) #(num_samples, #heads, len_seq,len_seq) \n",
    "print(attention_scores[0][0][0]) #this is the attention scores for the first sample, first head, for the first word:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149e1c3-e372-4c47-bf5a-515614302f04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Try the code more in detail: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fbb556e-1b75-43b1-86c2-cb36c00a3535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([ 9.854767 ,  8.496491 ,  7.7601767,  6.7471952,  4.0660534,\n",
       "        1.5270729,  1.5375006,  1.9661689,  0.4747281,  2.5537195,\n",
       "        0.4514052,  1.0212986,  1.6682776,  4.2590213,  3.5995393,\n",
       "        5.3422823,  5.162285 ,  5.785897 ,  5.343223 , 10.098306 ,\n",
       "        9.047625 ,  8.059312 ,  4.5651455,  4.44317  ,  4.018174 ,\n",
       "        3.7627876,  3.8784006,  4.133665 ,  4.086391 ,  3.4858587],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotqk = tf.matmul(dense_qre, dense_kre, transpose_b = True) #must be of size (batch_size, seq_len, seq_len) \n",
    "dotqk[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7cae658-3ebf-419c-b687-24ed823da299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.1622777, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[3.116351   2.6868265  2.4539833  2.1336505  1.2857989  0.48290285\n",
      " 0.4862004  0.6217572  0.15012221 0.807557   0.14274685 0.322963\n",
      " 0.5275557  1.3468207  1.1382742  1.689378   1.6324577  1.8296611\n",
      " 1.6896755  3.1933646  2.86111    2.5485783  1.4436257  1.4050537\n",
      " 1.2706583  1.1898979  1.226458   1.3071797  1.2922302  1.1023253 ], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Normalize: \n",
    "dim_k = tf.cast(dense_kre.shape[-1],tf.float32) \n",
    "normalized_dotqk = dotqk/tf.math.sqrt(dim_k)\n",
    "print(tf.math.sqrt(dim_k))\n",
    "print(normalized_dotqk[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eff46865-7084-4491-90c6-8e1e1455e222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([ 3.1163509e+00,  2.6868265e+00,  2.4539833e+00,  2.1336505e+00,\n",
       "        1.2857989e+00,  4.8290285e-01,  4.8620039e-01,  6.2175721e-01,\n",
       "        1.5012221e-01,  8.0755699e-01,  1.4274685e-01,  3.2296300e-01,\n",
       "        5.2755570e-01,  1.3468207e+00,  1.1382742e+00,  1.6893780e+00,\n",
       "        1.6324577e+00,  1.8296611e+00,  1.6896755e+00,  3.1933646e+00,\n",
       "        2.8611100e+00,  2.5485783e+00, -1.0000000e+09, -1.0000000e+09,\n",
       "       -1.0000000e+09, -1.0000000e+09, -1.0000000e+09, -1.0000000e+09,\n",
       "       -1.0000000e+09, -1.0000000e+09], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_dotqk += masking* -1e9\n",
    "normalized_dotqk[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "899566d9-ffbc-4619-a019-50f1c04bb7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([0.14328252, 0.09325092, 0.07388063, 0.0536305 , 0.02297178,\n",
       "       0.01029203, 0.01032603, 0.0118251 , 0.00737864, 0.01423957,\n",
       "       0.00732442, 0.00877082, 0.01076202, 0.02441721, 0.01982099,\n",
       "       0.03439274, 0.03248977, 0.03957227, 0.03440297, 0.15475327,\n",
       "       0.11100524, 0.0812106 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores =  tf.nn.softmax(tf.cast(normalized_dotqk, dtype=tf.float32),axis = -1)\n",
    "attention_scores[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa72c2b-4ef2-4dc2-939b-16a7d5db0694",
   "metadata": {},
   "source": [
    "# Look Ahead Mask: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0e6fa7d6-fbca-43b1-94dd-5c2256e932ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_ahead_mask(dim): \n",
    "    \n",
    "    \"\"\"\n",
    "    At each iteration of the decoder making predictions, pass the length of the input (dim) to this function to mask the proceeding words\n",
    "    \n",
    "    \"\"\"\n",
    "    # keeps the main diagonal and all sub-diagonals and sets all super-diagonals to zero: \n",
    "    mask = 1 - linalg.band_part(ones((dim, dim)), -1, 0) \n",
    "    expanded_mask_init = tf.expand_dims(mask, axis = 0) #(1,len_seq, len_seq) \n",
    "    expanded_mask_final = tf.expand_dims(expanded_mask_init, axis = 0)\n",
    " \n",
    "    return expanded_mask_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60783520-7cea-482d-b494-3a55f66352bf",
   "metadata": {},
   "source": [
    "#### Try the code to see how the look-ahead mask works: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "93006392-36a6-487c-a5a4-af54adf81c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "look_ahead_mask1 = look_ahead_mask(5)#try a smaller example than the dataset \n",
    "print(look_ahead_mask1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8ce0bb47-1ec7-4ffb-8327-9eca56604bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try the masking: \n",
    "\n",
    "# Define the query, key and, value matrices: \n",
    "dense_q = reshape(Dense(units = 20)(X_trainmod[0:2,0:5]), (2, 5, 20))# shape = (#samples, len_seq, dim_q)\n",
    "dense_k = reshape(Dense(units = 20)(X_trainmod[0:2,0:5]),(2,5,20)) # shape = (#samples, len_seq, dim_k) \n",
    "dense_v = reshape(Dense(units = 20)(X_trainmod[0:2,0:5]),(2,5,20)) # shape = (#samples, len_seq, dim_v) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bdeaf915-a69d-45ee-b6a6-d4d18e119b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2, 5, 10])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the query, key, and value matrices: \n",
    "dense_qre = reshape_tensor(dense_q,2, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_q/heads)\n",
    "dense_kre = reshape_tensor(dense_k, 2, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_k/heads)\n",
    "dense_vre = reshape_tensor(dense_v, 2, pre_attention = True)\n",
    "\n",
    "dense_qre.shape #2 samples, 2 heads, len_se = 10, 2*10 = 20 = dim_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6f5d0b9c-d4ac-4455-b34f-43108e6ac039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 5, 5), dtype=float32, numpy=\n",
       "array([[[[-8.43732730e-02, -7.93995082e-01, -4.75165278e-01,\n",
       "          -3.78226489e-01,  4.82216001e-01],\n",
       "         [ 1.42866743e+00,  2.02169847e+00,  1.53103852e+00,\n",
       "           1.46419132e+00,  1.43432593e+00],\n",
       "         [ 3.60690475e-01,  3.96175802e-01, -8.98327008e-02,\n",
       "          -1.11132786e-01,  6.80906415e-01],\n",
       "         [ 1.79796472e-01,  2.40602046e-01,  3.25290933e-02,\n",
       "          -8.80601332e-02,  3.28476518e-01],\n",
       "         [-2.47988656e-01, -7.86857754e-02, -2.97271460e-01,\n",
       "          -2.34151274e-01,  2.09704652e-01]],\n",
       "\n",
       "        [[-5.26181340e-01,  6.88323304e-02, -3.39775950e-01,\n",
       "          -1.80493101e-01,  3.51474524e-01],\n",
       "         [-7.38709748e-01, -3.05430740e-01, -9.91906375e-02,\n",
       "          -7.81071559e-02,  7.52550006e-01],\n",
       "         [-1.39334106e+00, -4.78385419e-01, -7.98267722e-01,\n",
       "          -7.59888589e-01, -6.86964672e-03],\n",
       "         [-1.05567908e+00, -4.79450911e-01, -6.87709332e-01,\n",
       "          -7.32642293e-01,  2.09290564e-01],\n",
       "         [-1.12096858e+00, -3.48198801e-01, -7.37987936e-01,\n",
       "          -5.80300331e-01,  1.66431710e-01]]],\n",
       "\n",
       "\n",
       "       [[[-1.03235555e+00, -9.22904074e-01, -5.40955186e-01,\n",
       "          -8.40837300e-01, -3.20715070e-01],\n",
       "         [ 2.59406090e-01, -1.92323118e-01,  2.04740688e-01,\n",
       "           1.54660329e-01, -1.82673290e-01],\n",
       "         [-8.04596543e-01, -7.25087345e-01, -1.93104940e-03,\n",
       "          -9.75911975e-01,  9.32655483e-02],\n",
       "         [-7.33151436e-01, -6.86907828e-01, -2.56771117e-01,\n",
       "          -1.07372177e+00,  5.55385053e-01],\n",
       "         [-3.38878065e-01, -4.09801245e-01, -2.40709707e-01,\n",
       "          -3.44171852e-01, -3.62074286e-01]],\n",
       "\n",
       "        [[-1.29013360e+00, -1.04164422e+00, -6.42724931e-01,\n",
       "          -6.60617530e-01, -2.14854926e-01],\n",
       "         [-8.60489249e-01, -9.18903768e-01, -4.19723511e-01,\n",
       "          -5.28194129e-01, -1.73014030e-01],\n",
       "         [-9.44797456e-01, -9.16112542e-01, -1.23003113e+00,\n",
       "          -9.52494323e-01, -8.74417126e-01],\n",
       "         [-3.70453775e-01, -4.98720050e-01,  1.15392637e-02,\n",
       "           5.24861552e-03,  2.18890905e-01],\n",
       "         [-6.44080400e-01, -1.03470778e+00, -1.17720878e+00,\n",
       "          -9.27429497e-01, -9.66055572e-01]]]], dtype=float32)>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotqk = tf.matmul(dense_qre, dense_kre, transpose_b = True) #must be of size (batch_size, seq_len, seq_len) \n",
    "dim_k = tf.cast(dense_kre.shape[-1],tf.float32) \n",
    "normalized_dotqk = dotqk/tf.math.sqrt(dim_k)\n",
    "normalized_dotqk #not yet masked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0c324a1d-0a1c-4aea-b53f-1fd03bc0955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores given to the 1st word relative to the rest of the words:\n",
      " [[1.         0.         0.         0.         0.        ]\n",
      " [0.3559397  0.6440603  0.         0.         0.        ]\n",
      " [0.37405312 0.38756484 0.23838204 0.         0.        ]\n",
      " [0.27094594 0.28793216 0.23384346 0.20727839 0.        ]\n",
      " [0.17449728 0.20668833 0.16610603 0.17692864 0.27577972]]\n"
     ]
    }
   ],
   "source": [
    "normalized_dotqk += look_ahead_mask1*-1e9\n",
    "attention_scores =  tf.nn.softmax(tf.cast(normalized_dotqk, dtype=tf.float32),axis = -1)\n",
    "print(f\"Attention scores given to the 1st word relative to the rest of the words:\\n {attention_scores[0][0]}\")#attention scores for the first and only sample, first head,first word \n",
    "\n",
    "#print(f\"\\n\\nAttention scores given for the 10th word relative to the rest of the words: {attention_scores[0][10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de794942-6c08-4374-b2a5-20896633470e",
   "metadata": {},
   "source": [
    "Assuming that the rows (words) are processed one at a time, we can see that the attentions are masked. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc2847-c7c2-43a5-8dfe-73865ee03fe2",
   "metadata": {},
   "source": [
    "## Creating the positional encodings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92969105-1d2a-4d69-8f93-6fc54cee9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the angles for positional embeddings: \n",
    "\n",
    "def get_angles(pos, k, d):\n",
    "    \"\"\"\n",
    "    Get the angles for the positional encoding\n",
    "    \n",
    "    Arguments:\n",
    "        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]\n",
    "        k --   Row vector containing the dimension span [[0, 1, 2, ..., d-1]]\n",
    "        d(integer) -- Encoding size\n",
    "    \n",
    "    Returns:\n",
    "        angles -- (pos, d) numpy array \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get i from dimension span k\n",
    "    i = k//2\n",
    "    # Calculate the angles using pos, i and d\n",
    "    angles = pos/ (10000)**(2*i/d)\n",
    "\n",
    "    \n",
    "    return angles\n",
    "    \n",
    "def pos_emb(len_seq,len_emb): \n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates the positional embeddings for all the words in the sequence based on: \n",
    "    \n",
    "    Input: \n",
    "    len_seq (int) : The length of the sequences inputed into the model. \n",
    "    len_emb (int) : The length of the word embeddings for every word in the sequence. \n",
    "\n",
    "    Note: the size of the positional encoding and the word embeddings must match in order to add them in the next step. \n",
    "\n",
    "    Output: \n",
    "    res (np.array(len_seq, len_emb)) : ith row of this matrix represents the positional encodings for the ith position in the sequence. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    len_i = int(len_emb/2)\n",
    "\n",
    "    # Initialize the matrix to save positional encodings: \n",
    "    res = np.zeros((len_seq,len_emb))\n",
    "    angles = np.zeros((len_seq,len_emb))\n",
    "    \n",
    "    #for each position in the sequence \n",
    "    for pos in range(len_seq): #there are 30 words so position ranges between 0-29\n",
    "        \n",
    "        #calculate the angles: \n",
    "        for i in range(len_i): #ranges between 0 - 24\n",
    "            angles[pos,2*i] = pos/(10000**(2*i/len_emb))\n",
    "            angles[pos, 2*i +1] = pos/(10000**(2*i/len_emb)) \n",
    "        \n",
    "        # Calculate the entries corresponding to each position \n",
    "        #for j in range(len_i): \n",
    "        res[pos, 0::2] = np.sin(angles[pos,0::2])\n",
    "        res[pos,1::2] = np.cos(angles[pos,0::2])\n",
    "            \n",
    "    return(tf.cast(res.reshape(1,len_seq,len_emb), dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5690200e-c70b-4e95-8582-f2f386fa2528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 30, 50])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the positional embeddings: \n",
    "position_enc = pos_emb(X_trainmod.shape[1],X_trainmod.shape[2])\n",
    "position_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa27d01c-567d-4b68-a541-5b52444a278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125, 30, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([375, 30, 50])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the positional encoding to the word embeddings: \n",
    "X_trainmod = X_trainmod + position_enc \n",
    "print(X_trainmod.shape)\n",
    "\n",
    "X_testmod = X_testmod + position_enc \n",
    "X_testmod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc50a9-15bc-4a67-8f91-67165834ea85",
   "metadata": {},
   "source": [
    "## Defining the feed forward neural network: \n",
    "This will be used as a part of the encoder and decoder structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "645c8842-8c75-4d7d-84f6-7cc6dc1a2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullFeedForward(n_1, emb_size):#the model must return vectors of the same size as the embeddings of the input so can be combined with decoder\n",
    "    model = Sequential([\n",
    "    Dense(n_1, activation='tanh', name=\"dense1\"), #relu? (#samples, len_seq, n_1)\n",
    "    Dense(emb_size, activation='tanh', name=\"dense2\")# linear? (#samples, len_seq, emb_size)\n",
    "])\n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc1c8d12-2822-4f45-b2ff-0ffa7fa5e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reshape_tensor which will be later on used for the Multi-head attention: \n",
    "\n",
    "def reshape_tensor(q_matrix, heads, pre_attention): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    #pre_attention, we'll need to reform into 4d \n",
    "    if pre_attention:\n",
    "\n",
    "        dense_qre = reshape(q_matrix, (shape(q_matrix)[0], shape(q_matrix)[1], heads, -1))\n",
    "        dense_qre = transpose(dense_qre, ([0, 2, 1, 3]))\n",
    "        \n",
    "        \n",
    "    #post_attention, we'll need to revert back to 3d: 1125, 2, 30, 15]\n",
    "    else: \n",
    "        q_matrix_transpose = transpose(q_matrix, ([0,2,1,3]))\n",
    "        dense_qre = reshape(q_matrix_transpose, (shape(q_matrix_transpose)[0], shape(q_matrix_transpose)[1], -1)) \n",
    "        \n",
    "        \n",
    "    return(dense_qre)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8258207-265a-4ebe-a61c-b4de933b4ae4",
   "metadata": {},
   "source": [
    "## Define the class for multi-head attention: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a1380463-0062-4718-b56c-dd21b0823aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer): \n",
    "\n",
    "    def __init__(self, dim_kv, dim_q, len_emb, heads, **kwargs):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__(**kwargs) \n",
    "        self.heads = heads\n",
    "        self.denseq = Dense(units = dim_q)\n",
    "        self.densek = Dense(units = dim_kv)\n",
    "        self.densev = Dense(units = dim_kv) \n",
    "        self.dense = Dense(units = len_emb)\n",
    "    \n",
    "    def call(self,q,k,v, masking, **kwargs): #by passing self, you passed all the attributes you've defined above. \n",
    "       \n",
    "        # Define the query, key, and value matrices: \n",
    "        dense_q = self.denseq(q) # shape = (#samples, len_seq, dim_q)\n",
    "        dense_k = self.densek(k) # shape = (#samples, len_seq, dim_k) \n",
    "        dense_v = self.densev(v) # shape = (#samples, len_seq, dim_v) \n",
    "        \n",
    "        # Reshape: \n",
    "        dense_qre = reshape_tensor(dense_q, self.heads, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_q/heads)\n",
    "        dense_kre = reshape_tensor(dense_k, self.heads, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_k/heads)\n",
    "        dense_vre = reshape_tensor(dense_v, self.heads, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_v/heads)\n",
    "        \n",
    "        # Calculate the attention scores: \n",
    "        attention_scores, res = self_attention(dense_qre, dense_kre,dense_vre,masking) #shape = (#samples, #heads, dim_q/heads, len_seq)\n",
    "        \n",
    "        # Revert the shape:\n",
    "        attention_with_v = reshape_tensor(res, self.heads, pre_attention = False) #shape = (#samples, len_seq, dim_q)\n",
    "        \n",
    "        # Run through another dense and add to the initial x: \n",
    "        res = self.dense(attention_with_v)  # shape = (#samples, len_seq, d_model) \n",
    "        \n",
    "        return(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0ce61987-9ca6-4042-ae9d-846c54c1199b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1125, 30, 50])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it works: \n",
    "dim_kv = 30 #we keep the dimension of k and q the same for the dot product to work. and then the dim of v the same so that mult happens\n",
    "dim_q = 30 \n",
    "len_emb = 50\n",
    "heads = 2 \n",
    "\n",
    "\n",
    "function = MultiHeadAttention(dim_kv, dim_q, len_emb, heads)\n",
    "function(X_trainmod, X_trainmod,X_trainmod, masking).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d98f9a-346a-4605-9fbd-32df11e4da5a",
   "metadata": {},
   "source": [
    "## Define the Encoder layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "40656c8b-23c9-403e-9bc8-566f49c50af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    \n",
    "    def __init__(self, dim_kv, dim_q, heads, fnn_neurons, len_emb, iter, drop_rate):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        self.mha     = MultiHeadAttention(dim_kv, dim_q, len_emb, heads)\n",
    "        self.norm1    = LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm2    = LayerNormalization(epsilon = 1e-6)\n",
    "        self.drop    = Dropout(rate = drop_rate)\n",
    "        self.fnn     = FullFeedForward(fnn_neurons, len_emb)\n",
    "        self.iter    = iter\n",
    "\n",
    "        \n",
    "    def call(self,x,training, masking): \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        for _ in range(self.iter): \n",
    "\n",
    "            # Add dropout layer: \n",
    "            drop_x = self.drop(x, training = training) \n",
    "            \n",
    "            # Calculate the attention scores: \n",
    "            mha_scores = self.mha(drop_x, drop_x, drop_x, masking = masking)\n",
    "        \n",
    "            # Add dropout and normalize: \n",
    "            dropout_1 = self.drop(mha_scores, training = training)\n",
    "            norm_1  = self.norm1(dropout_1 + x )\n",
    "        \n",
    "            #Run through a fully connected neural network: \n",
    "            fnn_output = self.fnn(norm_1) \n",
    "            \n",
    "            # Add dropout: \n",
    "            dropout_2 = self.drop(fnn_output, training = training)\n",
    "        \n",
    "            # Normalize: \n",
    "            x = self.norm2(dropout_2 + norm_1)\n",
    "            \n",
    "        return x\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "289dfe62-5023-400c-9778-08acedc534a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1125, 30, 50])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it works: \n",
    "dim_kv = 40 \n",
    "dim_q = 40 \n",
    "len_emb = 50\n",
    "heads = 4 \n",
    "masking = masking\n",
    "fnn_neurons = 20\n",
    "drop_rate = 0.1\n",
    "function = Encoder(dim_kv, dim_q, heads, fnn_neurons, len_emb, iter = 10, drop_rate = 0.1)\n",
    "output_encoder = function(X_trainmod, training = True, masking = None)\n",
    "output_encoder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e5f21-f3b1-4018-849d-8288983c6a87",
   "metadata": {},
   "source": [
    "## Define the Decoder layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c75cbb94-77cc-4907-a737-fd8d5d907a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer): \n",
    "\n",
    "    def __init__(self, len_emb, dim_kv, dim_q, heads, \n",
    "                dd_model, iter, \n",
    "                drop_rate = 0.1, epsilon = 1e-6):  #dd_model is the number of neurons in the last layer of decoder (dense with softmax) \n",
    "        super(Decoder, self).__init__()\n",
    "        self.len_emb = len_emb\n",
    "        self.mha1 = MultiHeadAttention(dim_kv, dim_q, len_emb, heads) #remove the masking from the attributes and add it to the call argument) \n",
    "        self.mha2 = MultiHeadAttention(dim_kv, dim_q, len_emb, heads) #same for here \n",
    "        self.drop = Dropout(rate = drop_rate)\n",
    "        self.layernorm1 = LayerNormalization(epsilon = epsilon)\n",
    "        self.layernorm2 = LayerNormalization(epsilon = epsilon)\n",
    "        self.layernorm3 = LayerNormalization(epsilon = epsilon)\n",
    "        self.dense =  FullFeedForward(dd_model, len_emb) \n",
    "        self.iter = iter\n",
    "\n",
    "\n",
    "#question! how does the built-in mha receive the number of q, k, v dims to map and create the q, k, v matrices? are the default. \n",
    "#question! during training will the layer normaliation parameters also train> if so, we need to define deperate layer norms to each. \n",
    "#question! there are some dense models in mha how are the number of neurons in them defined here? \n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, training, dec_pad_mask): \n",
    "        \"\"\"\n",
    "        The look-ahead mask will be defined within the model when training == True; otherwise, look-ahead-mask = None\n",
    "        \"\"\"\n",
    "        \n",
    "        len_seq = x.shape[1]\n",
    "        \n",
    "        # Create the look-ahead mask: \n",
    "        if training == True:\n",
    "            \n",
    "            look_ahead_mask1 = look_ahead_mask(len_seq)\n",
    "            \n",
    "        else \n",
    "            look_ahead_mask1 = None \n",
    "            \n",
    "    \n",
    "        for _ in range(iter):\n",
    "            \n",
    "            # Add positional Encoding: #remove the pos embeddings and have it in hte transformer. \n",
    "            #x += pos_emb(x.shape[1], self.len_emb)\n",
    "        \n",
    "            # Add a dropout layer: \n",
    "            x = self.drop(x, training = training) \n",
    "           \n",
    "            # Run through a MHA with the look-forward mask: \n",
    "            attn_mat1 = self.mha1(x, x, x, masking = look_ahead_mask1)\n",
    "            \n",
    "            # Add dropout here during training:  \n",
    "            attn_mat1 = self.drop(attn_mat, training = training)\n",
    "            \n",
    "            # Add and Normalize: \n",
    "            attn_mat1_x = self.layernorm1(attn_mat1 + x)\n",
    "            \n",
    "            # Run through the next MHA: \n",
    "            attn_mat2 = self.mha2(x , enc_output, enc_output, masking = dec_pad_mask)\n",
    "            \n",
    "            # Add dropout during training: \n",
    "            attn_mat2 = self.drop(attn_mat2, training = training) \n",
    "            \n",
    "            # Add and Normalize: \n",
    "            attn_mat2_x = self.layernorm2(attn_mat2 +  attn_mat1_x) \n",
    "            \n",
    "            # Run through a dense layer: \n",
    "            dense_output = self.dense(attn_mat2_x)\n",
    "            \n",
    "            # Add Dropout: \n",
    "            dense_drop = self.drop(dense_output, training = training)\n",
    "            \n",
    "            # Add and Normalize: \n",
    "            x = self.layernorm3(dense_drop + attn_mat2_x) #x is the res but remember that since it's in a loop we still call it x. \n",
    "            \n",
    "        return(x) \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2c66f01-2ae5-4ecb-99f0-9f4a7b885ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if it works after you've defined your output sequence (decoder input):  \n",
    "len_emb = 50 \n",
    "dim_kv = 30 \n",
    "dim_q = 50 \n",
    "heads = 3 \n",
    "dd_model = 20 \n",
    "iter = 3 \n",
    "drop_rate = 0.1\n",
    "function_decoder = Decoder(len_emb, dim_kv, dim_q, heads, \n",
    "                           dd_model, iter, drop_rate = 0.1, epsilon = 1e-6)\n",
    "\n",
    "function_decoder(y, output_encoder, training = True, dec_pad_mask = None).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2ac83-37ed-4dc2-8b76-48a34de41922",
   "metadata": {},
   "source": [
    "## Define the Transformer architecture: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53a127b8-7c92-423c-ad0d-68ea6ee5775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.layers.Layer): \n",
    "\n",
    "    def __init__(self, len_emb, dim_kv, dim_q, heads, d_model,\n",
    "                dd_model, iterEnc, iterDec, df_model, len_seq_out,\n",
    "                drop_rate = 0.1, epsilon = 1e-6):\n",
    "        \n",
    "        super(Transformer, self).__init__()\n",
    "        self.len_emb = len_emb\n",
    "        self.len_seq_out = len_seq_out\n",
    "        \n",
    "        self.encoder = Encoder(dim_kv, dim_q, heads, d_model, len_emb, iterEnc, drop_rate = 0.1)\n",
    "        \n",
    "        self.decoder = Decoder(len_emb, dim_kv, dim_q, heads, dd_model, iterDec, drop_rate = 0.1, epsilon = 1e-6)\n",
    "        \n",
    "        self.dense =  Dense(units = df_model,activation = 'softmax') \n",
    "        \n",
    "    def call(self, input_seqs, output_seqs, training, enc_pad_mask, dec_pad_mask, look_ahead_mask):\n",
    "    \n",
    "        \"\"\"\n",
    "        the output sequence and the input sequence must already be in the form of word embeddings added. we need two more paddings. <sos> and <eos> \n",
    "        len_seq in and out might be different \n",
    "        \"\"\"\n",
    "        \n",
    "        #first pass the input embeddings to add the positional encodings no dropouts necessary as the encoder already has it: \n",
    "        len_seq = input_seqs.shape[1]\n",
    "        input_seqs += pos_enc(len_seq_in, self.len_emb) \n",
    "        \n",
    "        #multiply by a constant for numerical stability #look into it! \n",
    "        input_seqs *= tf.math.sqrt(tf.cast(self.len_emb,tf.float32))\n",
    "        \n",
    "        # Run through the encoder part: \n",
    "        enc_output = self.encoder(input_seqs, training = training, masking = enc_pad_mask)\n",
    "        \n",
    "        # Add positional encoding for the output sequence: \n",
    "        output_seqs += pos_enc(self.len_seq_out, self.len_emb)\n",
    "        output_seqs *= tf.math.sqrt(tf.cast(self.len_emb,tf.float32))\n",
    "        \n",
    "        #Run through the decoder part: \n",
    "        dec_output = self.decoder(output_seqs, enc_output, training = training, dec_pad_mask = dec_pad_mask)\n",
    "        \n",
    "        # Run through a linear layer with activation function softmax \n",
    "        res = self.dense(dec_output) \n",
    "        return(res) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad6aed-290a-4b89-82f9-38c31f8f8e8b",
   "metadata": {},
   "source": [
    "before running through the final linear layer, do we add drop out to the model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b3bc0-05c5-4c0a-8cf5-d934d3325778",
   "metadata": {},
   "source": [
    "For the word embeddings and if we are to use the decoder structure, we need to modify the word embeddings to also include two tokens : $<sos> $ start of the sentence and $<eos>$ end of the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49675bc1-db99-42df-953c-07b889b3bebe",
   "metadata": {},
   "source": [
    "We want the Softmax function that assigns the attention scores to avoid assigning any attention score to the padded parts of the sequence. So, instead we can either define a function that replaces vectors of all zeros with negative infinity (-1e-9) or when creating the padded embeddings for each input, we can assign -1e-9 to every padded token. But if we add the padding before going through the dot product attention (before the softmax), it is possible that through multiplication with matrices q,k, and v the padded vectors grow larger and then when we run the resultant matrix through softmax, it might again not assign 0 attention scores to the padded sequences. Therefore, the padded mask must be added after the dot product. Then apply Softhen multiply with the V matrix. Where to normalize? we will normalize the attention scores after the dot product before masking is applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff9997-82bd-4708-911a-fde51140d031",
   "metadata": {},
   "source": [
    "mPreferably, we want the input of the Encoder structure to already have the word embeddings and the positional encodings. In the Encoder structure, we will have the multi-head attention (think of it as running the self-attention multiple times) and a fully connected neural network which will be called FullFeedForward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27a212-c483-4c34-bf7e-437f2e5d3064",
   "metadata": {},
   "source": [
    "My intuition is that when the output is not normalized, the algo will be caught in many local minima or maxima and cannot easily and quickly converge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa067037-ec77-4047-ab47-cafa963125d6",
   "metadata": {},
   "source": [
    "change the layer norms as they are also trainable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5d26e-7464-4efe-8070-8d352f510595",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Why is the embedding size also taken as an argument in MHA? we get matrices q, k, and v. The product of qTk will give a dim_k or dim_q by emb_size. The final product in the attention mechanism must yield a matrix of the same length of seq and emb_size. \n",
    "\n",
    "* look into the command of MHA.\n",
    "* LayerNormalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d3e37-1b9f-4d23-8aae-309e9146b3f6",
   "metadata": {},
   "source": [
    "### Multi-head attention? \n",
    "We will input 3 xs (possibly they could be different?) then the inputs are mapped linearly to give us the matrices Query, Key and Value. \n",
    "* dimension x (#batches, len_seq, len_emb)\n",
    "* dim of k:$K^T x$ if k is (len_seq,dim_k), then its transpose is (dim_k, len_seq), the resultant matrix is going to have dim (dim_k, len_emb)\n",
    "* dim of q: $Q^T x $; if q is (len_seq,dim_q), then its transpose is of dim (dim_q, len_emb) and the resultant dot product gives (dim_q,len_emb)\n",
    "* Similarly, for the multiplication of $V^T x$, we have the value being of dimension (dim_v, len_emb).\n",
    "  * if it is a self-attention (attention with only one head), then $qk^T$ has dim (dim_q, dim_k), scale, add the mask and dropout if given.\n",
    "  * if it has n heads, then we will produce query and key matrices of dimensions dim_q/n, dim_k/n. After the dot product, the result is of dim (dim_q/n, dim_k/n). We then concatenate these results to get the desired dim of (dim_q,dim_k). $ \\bold{make sure you understand the concatenation} $\n",
    "* dot prodcut v (dim_v, len_emb) qTk (dim_q, dim_k) --> $ qTk .v $ Note that here dim_k must be the same as the dimension of v for this dot product to occur.\n",
    "* just like magic, you have the attention scores now and the result is a matrix of (dim_k, len_emb).\n",
    "* so then we add our initial x and normalize too. in order to add x to the attention scores, the attention scores need to have the same dim as x. meaning that dim_k needs to be the same as the len of the sequence.\n",
    "\n",
    "### Fully Connected Neural Network: \n",
    "\n",
    "We feed the matrix out of the attention mechanism into the fully connected neural network. how many neurons? what matters is that the output layer must have len_emb neurons in order to match the dim of x. why do we need them to match? becoz we again add the input seq x to the result (after another layer of normalization). \n",
    "\n",
    "Then copy the result, pass as key and value to the decoder network. \n",
    "\n",
    "# Question isn't the dot product we are talking here actually a cross product?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2663a32-dd95-4d8a-aaf7-bd23f2a93b3c",
   "metadata": {},
   "source": [
    "Do you wanna define another function that takes the dims you'd like and deliver you the query, key and value matrices? \n",
    "because now we no longer need to have as inputs, the dim_kv and dim_q. would we need the masking? yes in self_attention. \n",
    "we need the mha to take 3 arguments as q,k,v. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375c990e-9d1a-4269-9113-7bcc4e5d03d2",
   "metadata": {},
   "source": [
    "* How do we initialize the q, k, and v matrices?\n",
    "\n",
    "    A multi-head attention class is defined where based on the training x, created the q,k, and v matrices by applying a dense layer to the input sequence each time. \n",
    "\n",
    "\n",
    "* How is this model trained?\n",
    "  Still a question.\n",
    "\n",
    "* For the encoder layer, what attributes do we need?\n",
    "   * Better question to ask is what do we want the Encoder layer do?\n",
    "     When running the encoder layer, we want to input the input sequence; then this input sequence will go through to add word embeddings, then positional encodings. We then run the attention model on this to get the attention scores added to the structure. we then normalize and add dropout. Then run through a fully connected neural network, add x, normalize and add another dropout layer.\n",
    "\n",
    "* What is the purpose of the Dropout function and what are its arguments?\n",
    " \n",
    "  let's assume the dropout rate is 0.1. During training, the dropout layer randomly selects 10% of the input and replace it with zeros. This prevents the model to overfit the parameters based on the training set and also prevents the model to become too reliant on certain parameters. During the call function, make sure you set the training argument to 'True' so that the model will apply dropout only during training and does nothing during the inference mode (making predictions). \n",
    "\n",
    "* As an alternative to defining our own Multi-Head attention, we could use the one built-in Tensorflow package. Check out if the calculations are all the same and what the arguments to this layer are. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eff716-87b5-4621-a661-7732206e6c9b",
   "metadata": {},
   "source": [
    "the next task is to have an encoder layer. you then have a decoder and then the transformer. to the transformer, we would like to only input the x and not modify to add embeddings or positional embeddings. but for the encoder part, we would like to repeat the encoder part multiple times. so essentially, we want to add a loop to the encoder section. how to do that? \n",
    "what is going to be on repeat? the full encoder layer.\n",
    "so what would be the input to the encoder? x \n",
    "at first, the x will be the training set but for the next iterations on the loop, we will take the output of the encoder and input for the next time. so, this in that sense it sequential but the length of the senquence is actually much less. I would like to see how would repeating the loop actually benefit training. \n",
    "* try adding multiple iterations of the encoder and then try with only one layer of encoder and see if there is a difference in the model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d158f6f-fd4f-41f8-84b9-e89680434191",
   "metadata": {},
   "source": [
    "cool thing to know, you can use the underscore for any variable that is not gonna be used later. so for example, if you know a function will output 3 vars and you only need the first two, you can have the third variable saved as an underscore. or during a for loop, you can write for _ in range() this means that the place holder for the iterations will actually not be used inside the loop so you don't bother defining it. \n",
    "\n",
    "* Note that we must make sure in the attention paper bahdanua, we defined the correct variables to be saved and disregarded in the post-attention LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a001a10-6e74-4b6b-ac2b-dc82a70d6086",
   "metadata": {},
   "source": [
    "So what does the decoder do? \n",
    "it seems that the decoder but for the decoder to start we need the encoder code in coursera to be complete we then can move to it? not right now I am primed to work to have at least an understanding of the decoder before going through it we do not necessarily start the code right away. \n",
    "\n",
    "so what does a decoder do? the decoder, has also an input that is prob encoded with embeddings and the pos encodings. then the decoder must go through yet another mha. to this mha that takes 3 inputs, we input the query as the input of the decoder and we input the output of the encoding as the key and value. why? query is where the model is at prediction. so essentially, the query has info about what has already been predicted. then you pass on all the info about the input as the key so the model learns what part of the input to focus on most when making prediction at the next step. you then multiply the attention scores with the value matrix which is again the input encoded. so essentially, the decoder takes the info on what has already been predicted and the full key matrix (input encoded) decides which parts of the input to pay attention to the most and once the attention scores are calculated, then the attention scores are weigh the encoded input. this is beautiful! then the mha might repeat for several iterations and then the output is added and normalized to the initial input of the decoder. \n",
    "\n",
    "* the input of the decoder will go through a masked multi-head attention. might repeat multiple times. then you add the initial input embeddings and encoding to the output of the multi-head loop (after you add the dropout layer to it). then this is inputed into another mha as the query. the key and the value are taken as the output of the encoder. another mha in a loop. then you add the dropout layer and then add to the query of this mha. then normalize and then run through a ffn. then again add dropout and add the input of ffn to the output.\n",
    "\n",
    "there might be another linear map and the run through the softmax. and voila! \n",
    "\n",
    "ok so the first step is to modify our mha function. how? this model should take the query, key and values as inputs. previously, we would take the the input, and equal to the size of the input, we would calculate the query, key and value inside the mha. now take this calculation out. so the key, query and value will be defined outside the mha and inputed to reshape and cal attn scores. but note that this process must take place after the loop in the encoder is introduced. \n",
    "\n",
    "might also need to define a masked mha. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620a428-a4a4-4ac8-b6ec-13f9ffd5c0cc",
   "metadata": {},
   "source": [
    "in case it was needed, we can run our x matrix in the jupyter notebook of coursera and check if the outputs and inputs are the same and if one model performs differently than the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed74b0-11b1-4f1f-99e2-c24334b9fdbc",
   "metadata": {},
   "source": [
    "# ? would this be helpful for the task of sentiment analysis? I believe it should be. \n",
    "\n",
    "in case it was needed, we can run our x matrix in the jupyter notebook of coursera and check if the outputs and inputs are the same and if one model performs differently than the other. \n",
    "#change the padding of all 1s to a padding of all zeros and see how the performance of the model might change. \n",
    "# you might also be interested in applying a padding to the model to examine the improvment in the performance. \n",
    "#need to add training = training for all the dropouts applied so this will only occur during the training mode. not that right now, the model is \n",
    "#always in the training mode. no inference so the dropout layer is also applied during inference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1876d1-eb16-4451-b7d9-d2d5f4ebd6cb",
   "metadata": {},
   "source": [
    "There are multiple tasks that must be followed: \n",
    "1, build the decoder network from scratch. (today) \n",
    "2, build the transform's architecture (tom)\n",
    "3, learn about the dropouts (tom)\n",
    "4, learn about the masks (tom) \n",
    "5, apply the transformer to a task (2days each) 2 tasks (friday start this - sat done with one task) (sat - mon) finish the other task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517348fb-de0a-46dc-bc10-3bcedcf892ce",
   "metadata": {},
   "source": [
    "transformer: \n",
    "embeddings of the encoder and decoder should occur here but pos enc inside the encoder and decoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d5965-d0d9-4477-abfb-db1cd39e430b",
   "metadata": {},
   "source": [
    "check the performance of the model both with and without editting the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf52f79-5f9b-404f-aed4-a4a6238a6485",
   "metadata": {},
   "source": [
    "try other datasets to train and see if it outperforms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a925818-148a-434a-80d5-ce3e48379c4a",
   "metadata": {},
   "source": [
    "question: we have masking to be applied and before that we have positional encoding that changes the inputs the padded rows are no longer all zeros and will affect the dot-product. but then once the dot product is calculated, we mask them so that no attention is given to those words. couldn't it be even more informative for the model if the positional encoding just prints out zeros for the padded tokens? because no matter how small the pe are, they still do affect the dot product. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae7db9-726c-40a7-b366-66c5887ecfd6",
   "metadata": {},
   "source": [
    "write down why the model performance did not improve with the glove word embeddings compared to one-hot vectors once the additive attention model is applied. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc186aa-d5ec-4088-9539-b3ef0521eb2e",
   "metadata": {},
   "source": [
    "explore why the divide by the constant dim_k in the dot product attention and that why would it possibily become problematic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d22f0-6d44-4ab8-b177-f6a104a5416c",
   "metadata": {},
   "source": [
    "#****the question is when would the decoder be stopped? would we run it through a cretain number of iterations? no we will generate tokens until the \n",
    "#token end of the sentence is generated. so till then we will generate tokens. but right now for a simplification, we will only run a loop for w\n",
    "#which the decoder makes predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef771ab-2b50-42ba-b985-5d6826ee07dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c5b7d-8016-494c-b227-aeaa23ff67ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5b2dd-8131-417c-8f07-217b3ca0b212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0997a180-7b2f-4072-83ea-0f11589cb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the packages required: \n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, Softmax, Embedding\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow import  reshape, shape, transpose, ones, linalg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Dropout, LayerNormalization, Layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import  reshape, shape, transpose, ones, linalg\n",
    "from sklearn.model_selection import train_test_split \n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5589c27-bdcf-4a59-937d-454dd209a2ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 122450.35it/s]\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset \n",
    "m = 10000 #number of training samples \n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a68b564-b54c-414f-8663-850b13ebbabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('29 oct 1992', '1992-10-29'),\n",
       " ('23.07.70', '1970-07-23'),\n",
       " ('3/19/15', '2015-03-19'),\n",
       " ('tuesday may 13 1986', '1986-05-13'),\n",
       " ('friday march 9 1990', '1990-03-09'),\n",
       " ('monday august 11 1980', '1980-08-11'),\n",
       " ('thursday january 4 2001', '2001-01-04'),\n",
       " ('10 nov 1978', '1978-11-10'),\n",
       " ('22 oct 1976', '1976-10-22'),\n",
       " ('monday september 20 1993', '1993-09-20')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c27c636-3c60-4e73-82e4-7155845dfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,Y, human_vocab, machine_vocab, Ty, Tx):\n",
    "\n",
    "    #Convert each date into a vector of integers corresponding to its index in human_vocab (for X) or machine-vocab (for Y): \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "    \n",
    "    # Add the <sos> and <end> tokens to Y: \n",
    "    Y = [[11] + i + [12] for i in Y]\n",
    "\n",
    "    #Create the one-hot vectors (will be used as input) \n",
    "    #Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X))) #one-hot vector of each X element\n",
    "    #Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, np.array(Y)#, Xoh, Yoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc06d89f-f262-4486-9d8d-6a17ef8dadc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10,\n",
       " '<sos>': 11,\n",
       " '<end>': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab = machine_vocab | {'<sos>':11, '<end>':12}\n",
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0018ebd4-86aa-4905-b56a-b4091cf4b93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " ' ': 1,\n",
       " '.': 2,\n",
       " '/': 3,\n",
       " '0': 4,\n",
       " '1': 5,\n",
       " '2': 6,\n",
       " '3': 7,\n",
       " '4': 8,\n",
       " '5': 9,\n",
       " '6': 10,\n",
       " '7': 11,\n",
       " '8': 12,\n",
       " '9': 13,\n",
       " 'a': 14,\n",
       " 'b': 15,\n",
       " 'c': 16,\n",
       " 'd': 17,\n",
       " 'e': 18,\n",
       " 'f': 19,\n",
       " 'g': 20,\n",
       " 'h': 21,\n",
       " 'i': 22,\n",
       " 'j': 23,\n",
       " 'l': 24,\n",
       " 'm': 25,\n",
       " 'n': 26,\n",
       " 'o': 27,\n",
       " 'p': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'y': 35,\n",
       " '<unk>': 36,\n",
       " 'arb': 37}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del human_vocab['<pad>']\n",
    "human_vocab = {key: value + 1 for key, value in human_vocab.items()}\n",
    "human_vocab = {'<pad>':0} | human_vocab | {'arb': 37} # adding this since for the positional embeddings we need even values \n",
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3cdd48-383f-4d6a-b204-8eff0ca9132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlist the tuples; seperate and save the human-readable and machine-readable dates into X and Y respectively. \n",
    "X, Y = zip(*dataset)\n",
    "Tx = len(max(X, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2110270-1ce2-4793-b83a-148377c6071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '-', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9', 11: '<sos>', 12: '<end>'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_vocabulary = {index: word for word, index in machine_vocab.items()}\n",
    "print(reverse_vocabulary)\n",
    "def reverse_lookup(indices):\n",
    "    return [reverse_vocabulary[index] for index in indices if index in reverse_vocabulary]\n",
    "reverse_lookup([10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af3ac9-d49a-4275-ae7e-8cacb6061258",
   "metadata": {},
   "source": [
    "### Split the dataset to training and testing sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9d857b-3aab-45df-b41a-6c14d9ff7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the dataset into 75% training set and 25% test set: \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32704c4-22c6-4346-990e-170616debf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23 april 2006'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2820cd-cf07-400c-b11c-47f0e16e81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2006-04-23', '1980-02-16', '1997-12-08']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea24103-ead1-4b91-9a1a-c3805f2129e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ty = 10 \n",
    "X_trainmod, y_trainmod = preprocess_data(X_train,y_train, human_vocab, machine_vocab, Ty, 27)\n",
    "X_testmod, y_testmod = preprocess_data(X_test, y_test, human_vocab, machine_vocab, Ty, 27) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10fbf09-653d-4328-9608-82e094e6e34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  1, 14, 28, 29, 22, 24,  1,  6,  4,  4, 10,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainmod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77da993-eaae-46ca-b913-e8887046b0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  3,  1,  1,  7,  0,  1,  5,  0,  3,  4, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainmod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cfc43d2-2371-4489-961d-49af6034d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (7500, 27)\n",
      "Y.shape: (7500, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape:\", X_trainmod.shape)\n",
    "print(\"Y.shape:\", y_trainmod.shape)\n",
    "#print(\"Xoh.shape:\", Xoh.shape)\n",
    "#print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5d53f8-c219-4622-a0e1-20e1ca726df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element of X_train is :\n",
      "23 april 2006\n",
      "First element of y_train is :\n",
      "2006-04-23\n",
      "First encoding element of y_trainmod is :\n",
      "[11  3  1  1  7  0  1  5  0  3  4 12]\n",
      "Second encoding element of y_trainmod: \n",
      "[11  2 10  9  1  0  1  3  0  2  7 12]\n",
      "First integer encoding of X_train: \n",
      "[ 6  7  1 14 28 29 22 24  1  6  4  4 10  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"First element of X_train is :\\n{X_train[0]}\")\n",
    "print(f\"First element of y_train is :\\n{y_train[0]}\")\n",
    "print(f\"First encoding element of y_trainmod is :\\n{y_trainmod[0]}\")\n",
    "print(f\"Second encoding element of y_trainmod: \\n{y_trainmod[1]}\")\n",
    "print(f\"First integer encoding of X_train: \\n{X_trainmod[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "192a4924-7425-44fd-bc63-1548f3d7a9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainmod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32553e99-2b4d-4de5-9c76-a880b67ac2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7500, 27, 20])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST/ Define the embedding layer for the input of the encoder (human-readible dates)\n",
    "len_human_vocab_ = len(human_vocab)  # Example vocabulary size\n",
    "embedding_dim = 20  # Embedding dimension\n",
    "\n",
    "# Define an embedding layer\n",
    "Encoding_embedding = tf.keras.layers.Embedding(input_dim=len_human_vocab_, output_dim=embedding_dim)\n",
    "\n",
    "# Example usage\n",
    "input_indices = X_trainmod\n",
    "input_encoder = Encoding_embedding(input_indices)\n",
    "input_encoder.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e94af66-8b33-4213-84fe-0cd91aac4bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([-0.00577899,  0.01323602,  0.04087318, -0.02204746,  0.04948512,\n",
       "        0.00802944, -0.00022287,  0.03216836,  0.01461811, -0.03330668,\n",
       "       -0.01023803,  0.00774448,  0.00988574, -0.02216876,  0.02318745,\n",
       "       -0.01249168,  0.04581759,  0.04978187,  0.04951015, -0.00880697],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoder[0][-1] # this is the encoding for the last string of the first sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb1f49f4-bd78-49c1-bb1c-a663843a5143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 12, 20)\n",
      "tf.Tensor(\n",
      "[ 0.00802339  0.03491603 -0.03945272  0.01754576 -0.00411788 -0.02898422\n",
      "  0.03989638  0.04164628 -0.02419833 -0.00774594 -0.02297484  0.02806025\n",
      " -0.01405926  0.0110396  -0.01564211 -0.02295054  0.01978591  0.02532512\n",
      "  0.02784434  0.01005604], shape=(20,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([ 0.00802339,  0.03491603, -0.03945272,  0.01754576, -0.00411788,\n",
       "       -0.02898422,  0.03989638,  0.04164628, -0.02419833, -0.00774594,\n",
       "       -0.02297484,  0.02806025, -0.01405926,  0.0110396 , -0.01564211,\n",
       "       -0.02295054,  0.01978591,  0.02532512,  0.02784434,  0.01005604],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST/ Define the embedding layer for the input of the encoder (human-readible dates)\n",
    "len_machine_vocab = len(machine_vocab)  # Example vocabulary size\n",
    "embedding_dim = 20  # Embedding dimension\n",
    "\n",
    "# Define an embedding layer\n",
    "Encoding_embedding = tf.keras.layers.Embedding(input_dim=len_machine_vocab, output_dim=embedding_dim)\n",
    "\n",
    "# Example usage\n",
    "input_indices = y_trainmod\n",
    "input_decoder = Encoding_embedding(input_indices)\n",
    "print(input_decoder.shape)\n",
    "print(input_decoder[0][0])\n",
    "input_decoder[1][0] #same embedding for the start token in all samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25561d4c-daaa-45de-bd72-27a4696eaf5c",
   "metadata": {},
   "source": [
    "- To the machine vocabulary, we have added two tokens $<sos>$ and $<end>$. The decoder is now able to predict the end of the sequence.  \n",
    "- The length is no longer chosen but set as the length of the longest string among the inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e91eb-15b1-4d0f-bc87-a9103105ec2d",
   "metadata": {},
   "source": [
    "#### Add positional encodings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a8a6fd-a4ca-46a1-b333-5bda01e2820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the angles for positional embeddings: \n",
    "\n",
    "def get_angles(pos, k, d):\n",
    "    \"\"\"\n",
    "    Get the angles for the positional encoding\n",
    "    \n",
    "    Arguments:\n",
    "        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]\n",
    "        k --   Row vector containing the dimension span [[0, 1, 2, ..., d-1]]\n",
    "        d(integer) -- Encoding size\n",
    "    \n",
    "    Returns:\n",
    "        angles -- (pos, d) numpy array \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get i from dimension span k\n",
    "    i = k//2\n",
    "    # Calculate the angles using pos, i and d\n",
    "    angles = pos/ (10000)**(2*i/d)\n",
    "\n",
    "    \n",
    "    return angles\n",
    "    \n",
    "def pos_emb(len_seq,len_emb): \n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates the positional embeddings for all the words in the sequence based on: \n",
    "    \n",
    "    Input: \n",
    "    len_seq (int) : The length of the sequences inputed into the model. \n",
    "    len_emb (int) : The length of the word embeddings for every word in the sequence. \n",
    "\n",
    "    Note: the size of the positional encoding and the word embeddings must match in order to add them in the next step. \n",
    "\n",
    "    Output: \n",
    "    res (np.array(len_seq, len_emb)) : ith row of this matrix represents the positional encodings for the ith position in the sequence. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    len_i = int(len_emb/2)\n",
    "\n",
    "    # Initialize the matrix to save positional encodings: \n",
    "    res = np.zeros((len_seq,len_emb))\n",
    "    angles = np.zeros((len_seq,len_emb))\n",
    "    \n",
    "    #for each position in the sequence \n",
    "    for pos in range(len_seq): #there are 30 words so position ranges between 0-29\n",
    "        \n",
    "        #calculate the angles: \n",
    "        for i in range(len_i): #ranges between 0 - 24\n",
    "            angles[pos,2*i] = pos/(10000**(2*i/len_emb))\n",
    "            angles[pos, 2*i +1] = pos/(10000**(2*i/len_emb)) \n",
    "        \n",
    "        # Calculate the entries corresponding to each position \n",
    "        #for j in range(len_i): \n",
    "        res[pos, 0::2] = np.sin(angles[pos,0::2])\n",
    "        res[pos,1::2] = np.cos(angles[pos,0::2])\n",
    "            \n",
    "    return(tf.cast(res.reshape(1,len_seq,len_emb), dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9d6798-4d2b-4bbb-b996-d3b6289c69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST/ Add positional encodings to the input of the encoder: \n",
    "pos_encoding_en = pos_emb(27,20)\n",
    "input_encoder = input_encoder + pos_encoding_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "981d728a-2d7b-4a27-8b10-038224a611bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7500, 27, 20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2a2daa7-c1d5-47db-9241-2ed62fbab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST/ Add positional encodings to the input of the decoder: \n",
    "pos_encoding_dec = pos_emb(12,20)\n",
    "input_decoder = input_decoder + pos_encoding_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8be7135b-6ef6-4346-860c-604a6e484435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7500, 12, 20])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_decoder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdc2fd-9f33-4a97-b638-e6d4bf014897",
   "metadata": {},
   "source": [
    "#### Define the masks: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc00b1-db80-42bb-98db-9bdf65067a0f",
   "metadata": {},
   "source": [
    "##### Padding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602baabb-8580-4677-a18f-8245754ce723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(matrix,num_heads):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        seq -- (n, m) matrix\n",
    "    \n",
    "    Returns:\n",
    "        mask -- (n, 1, 1, m) binary tensor\n",
    "    \"\"\"\n",
    "    # Check if each row is all zeros\n",
    "    zero_rows = tf.cast(tf.equal(matrix, 0), dtype=tf.float32)\n",
    "\n",
    "    padded_matrix_1 = tf.repeat(tf.expand_dims(zero_rows, axis=1), repeats=num_heads, axis=1)\n",
    "    final_mask = tf.cast(tf.expand_dims(padded_matrix_1, axis=2),dtype=tf.float32)\n",
    "    # Convert boolean array to integer array (0s and 1s)\n",
    "    #padded_mask = zero_rows.astype(int)\n",
    "    # Expand to make 4D: \n",
    "    #expanded_padding_mask_init = tf.expand_dims(padded_mask, axis=1)\n",
    "    #expanded_padding_mask_final = tf.expand_dims(expanded_padding_mask_init, axis=1)\n",
    "    # Repeat for each head: \n",
    "    #final_mask = tf.cast(tf.tile(expanded_padding_mask_final, [1, num_heads, 1, 1]),tf.float32)  # (batch_size, num_heads, 1, seq_len)\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9820ba-5468-4921-99ba-22ddd2c415e5",
   "metadata": {},
   "source": [
    "#### Example: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05687f-d1c4-4462-a4e5-4c98a04937a0",
   "metadata": {},
   "source": [
    "When we have an input, we want to make sure the zeros get mapped to zero attention. Let us see a sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab0797f9-1fab-4bb9-82ca-d14a956ac8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  1, 14, 28, 29, 22, 24,  1,  6,  4,  4, 10,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainmod[0]# so all the way after the 10th token, we need padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8a864d65-e433-4751-956e-93a20148c422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 1, 27])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = create_padding_mask(X_trainmod[0:1], 2) \n",
    "padding_mask.shape #come back to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7febfa69-db7a-4b4f-a618-344d6b3c4f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 1, 27), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a243c624-3855-45fc-b387-03e9ca1df58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 27, 27])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Query, Key, and Value matrices\n",
    "dense_q = tf.cast(Dense(units = 40)(input_encoder[0:1]), dtype=tf.float32) # shape = (#samples, len_seq, dim_q)\n",
    "dense_k = tf.cast(Dense(units = 40)(input_encoder[0:1]),dtype = tf.float32) # shape = (#samples, len_seq, dim_k) \n",
    "dense_v = tf.cast(Dense(units = 40)(input_encoder[0:1]), dtype = tf.float32) # shape = (#samples, len_seq, dim_v) \n",
    "# Reshape the Query, Key, and Value matrices \n",
    "dense_qre = reshape_tensor(dense_q, 2, pre_attention = True) #shape = (#samples, #heads, dim_q/heads, len_seq)\n",
    "dense_kre = reshape_tensor(dense_k, 2, pre_attention = True) #shape = (#samples, #heads, dim_k/heads, len_seq)\n",
    "dense_vre = reshape_tensor(dense_v, 2, pre_attention = True)\n",
    "# Calculate the attention scores\n",
    "attention_scores, res = self_attention(dense_qre,dense_kre,dense_vre, masking = padding_mask)\n",
    "attention_scores.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5422091e-9222-49a2-9caf-25cdfea020cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27,), dtype=float32, numpy=\n",
       "array([0.06970534, 0.07402434, 0.07621909, 0.07359982, 0.07238382,\n",
       "       0.07415678, 0.07832458, 0.0819699 , 0.08164559, 0.07979792,\n",
       "       0.07662789, 0.07788742, 0.08365756, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[0][0][0] #This is the attention scores for the first sample, first head, first word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c76030-0065-4455-a259-1fc78f1de7d4",
   "metadata": {},
   "source": [
    "### Look-Ahead Mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23b51cb4-3539-447b-afa5-a796360368e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(dim): \n",
    "    \n",
    "    \"\"\"\n",
    "    At each iteration of the decoder making predictions, pass the length of the input (dim) to this function to mask the proceeding words\n",
    "    \n",
    "    \"\"\"\n",
    "    # keeps the main diagonal and all sub-diagonals and sets all super-diagonals to zero: \n",
    "    mask = 1 - linalg.band_part(ones((dim, dim)), -1, 0) \n",
    "    expanded_mask_init = tf.expand_dims(mask, axis = 0) #(1,len_seq, len_seq) \n",
    "    expanded_mask_final = tf.expand_dims(expanded_mask_init, axis = 0)\n",
    " \n",
    "    return expanded_mask_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "32a98b60-6d7a-415e-8f30-0bd99607fd85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 10, 10), dtype=float32, numpy=\n",
       "array([[[[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead_mask = create_look_ahead_mask(10)\n",
    "look_ahead_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a81c28-1b52-4676-bf0b-4696713c4a99",
   "metadata": {},
   "source": [
    "#### Example Look-ahead mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c366dca9-1d7d-469b-8293-a29e118faec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 27, 27])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Q,K,V \n",
    "dense_q = tf.cast(Dense(units = 40)(input_encoder[0:1]), dtype=tf.float32) # shape = (#samples, len_seq, dim_q)\n",
    "dense_k = tf.cast(Dense(units = 40)(input_encoder[0:1]),dtype = tf.float32) # shape = (#samples, len_seq, dim_k) \n",
    "dense_v = tf.cast(Dense(units = 40)(input_encoder[0:1]), dtype = tf.float32) # shape = (#samples, len_seq, dim_v) \n",
    "# Reshape based on the number of heads \n",
    "dense_qre = reshape_tensor(dense_q, 2, pre_attention = True) #shape = (#samples, #heads, dim_q/heads, len_seq)\n",
    "dense_kre = reshape_tensor(dense_k, 2, pre_attention = True) #shape = (#samples, #heads, dim_k/heads, len_seq)\n",
    "dense_vre = reshape_tensor(dense_v, 2, pre_attention = True)\n",
    "attention_scores, res = self_attention(dense_qre, dense_kre,dense_vre, masking = create_look_ahead_mask(dense_q.shape[1]))\n",
    "attention_scores.shape # 1 sample, 2 heads, len_seq = 27 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6d5a5839-b6db-4f9e-8bbc-4fc2ede665a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27,), dtype=float32, numpy=\n",
       "array([0.49960408, 0.50039595, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[0][0][1] #first sample, first head, first word. the amount of attention needed to pay for each. \n",
    "#this shows that the model only pays attention to the first word to make a prediction for the second word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20afc520-362a-4ea3-9ab4-7fced00e5583",
   "metadata": {},
   "source": [
    "#### Define the self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb9e3029-ba8e-4df4-b36a-41942cf50b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(q,k,v,masking):\n",
    "    \"\"\"\n",
    "    This function applied the self-attention mechanism to a given input. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform matrix multiplication on the last two dimensions\n",
    "    dotqk = tf.matmul(q, k, transpose_b = True) #must be of size (batch_size, seq_len, seq_len) \n",
    "\n",
    "    dim_k = tf.cast(40,tf.float32) \n",
    "    normalized_dotqk = dotqk/tf.math.sqrt(dim_k)\n",
    "    \n",
    "    #then add the masking if masking if given\" \n",
    "    if masking is not None: \n",
    "        normalized_dotqk += masking* -1e9\n",
    "    \n",
    "    attention_scores =  tf.nn.softmax(tf.cast(normalized_dotqk, dtype=tf.float32),axis = -1)\n",
    "    res = tf.matmul(attention_scores,v) \n",
    "    \n",
    "    return(attention_scores, res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca9f81-91f7-4433-9ec9-1348d19ef74e",
   "metadata": {},
   "source": [
    "#### Define A feed forward neural network: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24feae77-140c-465a-aec2-12e461fbe037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullFeedForward(n_1, emb_size):#the model must return vectors of the same size as the embeddings of the input so can be combined with decoder\n",
    "    model = Sequential([\n",
    "    Dense(n_1, activation='tanh', name=\"dense1\"), #relu? (#samples, len_seq, n_1)\n",
    "    Dense(emb_size, activation='tanh', name=\"dense2\")# linear? (#samples, len_seq, emb_size)\n",
    "])\n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bb81b3a-d654-4204-82bd-9aae7d12a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reshape_tensor which will be later on used for the Multi-head attention: \n",
    "\n",
    "def reshape_tensor(q_matrix, heads, pre_attention): \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #pre_attention, we'll need to reform into 4d \n",
    "    if pre_attention:\n",
    "\n",
    "        dense_qre = reshape(q_matrix, (shape(q_matrix)[0], shape(q_matrix)[1], heads, -1))\n",
    "        dense_qre = transpose(dense_qre, ([0, 2, 1, 3]))\n",
    "        \n",
    "        \n",
    "    #post_attention, we'll need to revert back to 3d: 1125, 2, 30, 15]\n",
    "    else: \n",
    "        q_matrix_transpose = transpose(q_matrix, ([0,2,1,3]))\n",
    "        dense_qre = reshape(q_matrix_transpose, (shape(q_matrix_transpose)[0], shape(q_matrix_transpose)[1], -1)) \n",
    "        \n",
    "        \n",
    "    return(dense_qre)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1d0f1fe-490d-4f74-b6cd-ffde90fc874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer): \n",
    "\n",
    "    def __init__(self, dim_kv, dim_q, len_emb, heads, **kwargs):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__(**kwargs) \n",
    "        self.heads = heads\n",
    "        self.denseq = Dense(units = dim_q)\n",
    "        self.densek = Dense(units = dim_kv)\n",
    "        self.densev = Dense(units = dim_kv) \n",
    "        self.dense = Dense(units = len_emb)\n",
    "        self.self_attention = self_attention\n",
    "    \n",
    "    def call(self,q,k,v,masking, **kwargs): #by passing self, you passed all the attributes you've defined above. \n",
    "       \n",
    "        # Define the query, key, and value matrices: \n",
    "        #print(f\"dim of q is {q.shape}, dim of k is {k.shape}\")\n",
    "        dense_q = self.denseq(q) # shape = (#samples, len_seq, dim_q)\n",
    "        dense_k = self.densek(k) # shape = (#samples, len_seq, dim_k) \n",
    "        dense_v = self.densev(v) # shape = (#samples, len_seq, dim_v) \n",
    "        \n",
    "        # Reshape: \n",
    "        dense_qre = reshape_tensor(dense_q, self.heads, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_q/heads)\n",
    "        dense_kre = reshape_tensor(dense_k, self.heads, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_k/heads)\n",
    "        dense_vre = reshape_tensor(dense_v, self.heads, pre_attention = True) #shape = (#samples, #heads, len_seq, dim_v/heads)\n",
    "        \n",
    "        # Calculate the attention scores: \n",
    "        attention_scores, res = self.self_attention(dense_qre, dense_kre,dense_vre,masking) #shape = (#samples, #heads, dim_q/heads, len_seq)\n",
    "        # Revert the shape:\n",
    "        attention_with_v = reshape_tensor(res, self.heads, pre_attention = False) #shape = (#samples, len_seq, dim_q)\n",
    "        \n",
    "        return(attention_with_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "195cff87-07cf-4282-ad86-6f01fd3892c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input to the MHA: (7500, 27, 20)\n"
     ]
    }
   ],
   "source": [
    "# Check if it works: \n",
    "dim_kv = 20 #we keep the dimension of k and q the same for the dot product to work. and then the dim of v the same so that mult happens\n",
    "dim_q = 20\n",
    "len_emb = 20\n",
    "heads = 2 \n",
    "masking = None\n",
    "print(f\"shape of input to the MHA: {input_encoder.shape}\")\n",
    "mha = MultiHeadAttention(dim_kv, dim_q, len_emb, heads)\n",
    "mha(input_encoder, input_encoder,input_encoder, masking = None).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bccf2-eb2e-403b-aca6-6017c90100da",
   "metadata": {},
   "source": [
    "### Define the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acc95e45-db07-4917-ac90-05f5242bd9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, dim_kv, dim_q, heads, fnn_neurons, len_emb,len_human_vocab, iter, drop_rate):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        self.heads   = heads\n",
    "        self.iter    = iter\n",
    "        self.len_emb = len_emb\n",
    "\n",
    "        self.enc_emb = Embedding(input_dim=len_human_vocab, output_dim=len_emb, input_length=27)\n",
    "        self.mha     = MultiHeadAttention(dim_kv, dim_q, len_emb, heads)\n",
    "        self.fnn     = FullFeedForward(fnn_neurons, len_emb)\n",
    "        \n",
    "        self.norm1   = LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm2   = LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.drop1    = Dropout(rate = drop_rate)\n",
    "        self.drop2    = Dropout(rate = drop_rate)\n",
    "        self.drop3    = Dropout(rate = drop_rate)\n",
    "        \n",
    "        \n",
    "    def call(self,x, training= False, enc_mask = False): \n",
    "        \"\"\"\n",
    "        This block calculates the Encoder output for number of iterations = iter.\n",
    "        \n",
    "        Input\n",
    "        x        : input of the encoder - provided by the dataset available \n",
    "        training : if training == True, dropout layers will be active. \n",
    "        masking  : Boolean if True then the padding mask will be calculated and applied. \n",
    "\n",
    "        Output \n",
    "        x        : the final x returned will be the output of the encoder after iter loops. \n",
    "        \n",
    "        \"\"\"\n",
    "        # Define the padding mask if True \n",
    "        padding_mask = create_padding_mask(x,self.heads) if enc_mask else None\n",
    "\n",
    "        # Add Embedding Layer \n",
    "        x = self.enc_emb(x)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x += pos_emb(x.shape[1], len_emb)\n",
    "        x *= tf.math.sqrt(tf.cast(self.len_emb,tf.float32))\n",
    "        # Encoder layers\n",
    "        for _ in range(self.iter): \n",
    "\n",
    "            # Add dropout layer: \n",
    "            drop_x = self.drop1(x, training = training) \n",
    "            \n",
    "            # Calculate the attention scores: \n",
    "            mha_scores = self.mha(drop_x, drop_x, drop_x, masking = padding_mask)\n",
    "        \n",
    "            # Add dropout and normalize: \n",
    "            dropout_1 = self.drop2(mha_scores, training = training)\n",
    "            norm_1  = self.norm1(dropout_1 + x )\n",
    "        \n",
    "            #Run through a fully connected neural network: \n",
    "            fnn_output = self.fnn(norm_1) \n",
    "            \n",
    "            # Add dropout: \n",
    "            dropout_2 = self.drop3(fnn_output, training = training)\n",
    "        \n",
    "            # Normalize: \n",
    "            x = self.norm2(dropout_2 + norm_1)\n",
    "            \n",
    "        return x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f38cd3db-8296-4952-aeee-5c815bcb1d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the input given: (7500, 27, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'multi_head_attention_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([7500, 27, 20])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure the Encoder block works: \n",
    "dim_kv, dim_q, len_emb = 20,20,20\n",
    "heads = 2\n",
    "masking = False\n",
    "fnn_neurons = 20\n",
    "drop_rate = 0.1\n",
    "print(f\"shape of the input given: {input_encoder.shape}\")\n",
    "len_human_vocab = len(human_vocab) \n",
    "encoder = Encoder(dim_kv, dim_q, heads, fnn_neurons, len_emb,len_human_vocab, iter = 6, drop_rate = 0.1) \n",
    "enc_output = encoder(X_trainmod, training = True, enc_mask= True) #input_decoder is the embeddings + positional encodings \n",
    "enc_output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae70780e-d655-4a11-89df-e9b9324814a0",
   "metadata": {},
   "source": [
    "### Define the Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43768d2b-6b5f-44c6-a3ca-2b8198834615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer): \n",
    "\n",
    "    def __init__(self, len_emb, dim_kv, dim_q, heads, \n",
    "                dd_model, iter, len_seq_out,  \n",
    "                drop_rate = 0.1, epsilon = 1e-6):  #dd_model is the number of neurons in the last layer of decoder (dense with softmax) \n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.len_emb     = len_emb\n",
    "        self.iter        = iter\n",
    "        self.heads       = heads\n",
    "        self.len_seq_out = len_seq_out\n",
    "\n",
    "        self.emb_layer  = Embedding(input_dim=len_machine_vocab, output_dim=len_emb)\n",
    "        self.mha1       = MultiHeadAttention(dim_kv, dim_q, len_emb, heads)\n",
    "        self.mha2       = MultiHeadAttention(dim_kv, dim_q, len_emb, heads) \n",
    "        self.dense      = FullFeedForward(dd_model, len_emb)\n",
    "        \n",
    "        self.drop1       = Dropout(rate = drop_rate)\n",
    "        self.drop2       = Dropout(rate = drop_rate)\n",
    "        self.drop3       = Dropout(rate = drop_rate)\n",
    "        self.drop4       = Dropout(rate = drop_rate)\n",
    "        \n",
    "        self.layernorm1 = LayerNormalization(epsilon = epsilon)\n",
    "        self.layernorm2 = LayerNormalization(epsilon = epsilon)\n",
    "        self.layernorm3 = LayerNormalization(epsilon = epsilon)\n",
    "       \n",
    "\n",
    "    def call(self, x, enc_output, training= False): #dec_mask = False): \n",
    "        \n",
    "        \"\"\"\n",
    "        if training == True: \n",
    "            - The look-ahead mask will be defined within the model \n",
    "            - The model will make predictions for all time steps at once \n",
    "            - Dropout layers are on \n",
    "            \n",
    "        if training == False: \n",
    "            - The look-ahead mask is None \n",
    "            - The model will make predictions sequentially, \n",
    "            - The model keeps predicting until the end of the sequence is reached, \n",
    "            - Dropout layers are inactive \n",
    "\n",
    "        Input \n",
    "        x    : The input sequence to the decoder \n",
    "        enc_output : The output of the Encoder passed to the Decoder \n",
    "        training   : Boolean value, if True the Dropout layers are active and look-ahead mask is applied \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        len_seq = x.shape[1]\n",
    "\n",
    "        # Define the padding mask if needed\n",
    "        dec_pad_mask = create_padding_mask(x, self.heads) if training else None # this must also be modified if pads are not added. \n",
    "\n",
    "        # Inference mode\n",
    "        look_ahead_mask1 = None if not training else create_look_ahead_mask(len_seq)\n",
    "        \n",
    "       \n",
    "        # Add embeddings: \n",
    "        x = self.emb_layer(x)\n",
    "        \n",
    "        # Add positional encoding \n",
    "        x += pos_emb(len_seq, self.len_emb)\n",
    "        x *= tf.math.sqrt(tf.cast(self.len_emb,tf.float32))\n",
    "       \n",
    "        for _ in range(iter):\n",
    "            # Add a dropout layer: \n",
    "            x = self.drop1(x, training = training) \n",
    "               \n",
    "            # Run through a MHA with the look-forward mask: \n",
    "            attn_mat1 = self.mha1(x, x, x, masking = look_ahead_mask1)\n",
    "                \n",
    "            # Add dropout here during training:  \n",
    "            attn_mat1 = self.drop2(attn_mat1, training = training)\n",
    "                \n",
    "            # Add and Normalize: \n",
    "            attn_mat1_x = self.layernorm1(attn_mat1 + x)\n",
    "                \n",
    "            # Cross Attention\n",
    "            # Define the mask if needed  #####-> made some changes here too for training replaced dec_mask \n",
    "            if training: \n",
    "                cross_mha_mask = np.zeros((x.shape[0], self.heads, attn_mat1_x.shape[1], enc_output.shape[1]))\n",
    "                for i in range(cross_mha_mask.shape[2]): \n",
    "                    cross_mha_mask[:,:,i,:] = tf.repeat(dec_pad_mask[:,:,:,i], repeats=enc_output.shape[1], axis=2)\n",
    "            else: \n",
    "                cross_mha_mask = None \n",
    "            # Run the cross attention \n",
    "            attn_mat2 = self.mha2(attn_mat1_x , enc_output, enc_output, masking = cross_mha_mask)\n",
    "                \n",
    "            # Add dropout during training: \n",
    "            attn_mat2 = self.drop3(attn_mat2, training = training) \n",
    "                \n",
    "            # Add and Normalize: \n",
    "            attn_mat2_x = self.layernorm2(attn_mat2 +  attn_mat1_x) \n",
    "                \n",
    "            # Run through a dense layer: \n",
    "            dense_output = self.dense(attn_mat2_x)\n",
    "                \n",
    "            # Add Dropout: \n",
    "            dense_output = self.drop4(dense_output, training = training)\n",
    "                \n",
    "            # Add and Normalize: \n",
    "            x = self.layernorm3(dense_output + attn_mat2_x) #(#samples, 12,20)-> #(#samples, 12,1) --> (#samples, 1, 12)\n",
    "            \n",
    "        return(x) \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c403b680-22c3-4f14-a600-c4a40096011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7500, 11, 20])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if it works after you've defined your output sequence (decoder input):  \n",
    "dim_kv = 20\n",
    "dim_q = 20\n",
    "len_emb = 20 \n",
    "heads = 2\n",
    "masking = None\n",
    "dd_model = 20\n",
    "drop_rate = 0.1\n",
    "iter = 1\n",
    "len_seq_out = 11\n",
    "\n",
    "func_decoder = Decoder(len_emb, dim_kv, dim_q, heads, \n",
    "                           dd_model, iter,len_seq_out, drop_rate = 0.1, epsilon = 1e-6)\n",
    "decoder_output = func_decoder(y_train_dec_input, enc_output, training = False)\n",
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb4380b8-ae59-4d9b-878e-e4e55825145a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([-0.12847579, -1.1864185 , -1.0001552 ,  1.4832157 ,  0.35379234,\n",
       "        0.69271374, -0.53467846,  0.3083954 , -0.8806666 ,  0.30249602,\n",
       "        0.04884396, -1.3301146 ,  1.2648648 ,  1.0878731 , -0.91357577,\n",
       "        0.17336014, -2.0089796 ,  1.3717271 , -0.4965886 ,  1.3923708 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output[0][0] #logits not probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50bc8a-1ada-490c-a850-77d5830d7cd1",
   "metadata": {},
   "source": [
    "### Modifying the target dataset to feed into the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200595c-59ee-4ba1-97ef-9bc30a045866",
   "metadata": {},
   "source": [
    "Let us print out the y_trainmod: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5d11b377-9bbd-4710-aca6-5044acffa82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  3,  1,  1,  7,  0,  1,  5,  0,  3,  4, 12],\n",
       "       [11,  2, 10,  9,  1,  0,  1,  3,  0,  2,  7, 12],\n",
       "       [11,  2, 10, 10,  8,  0,  2,  3,  0,  1,  9, 12],\n",
       "       [11,  2, 10, 10,  3,  0,  2,  2,  0,  3,  1, 12],\n",
       "       [11,  2, 10,  8, 10,  0,  1,  9,  0,  2,  7, 12],\n",
       "       [11,  2, 10,  9, 10,  0,  2,  3,  0,  3,  1, 12],\n",
       "       [11,  2, 10, 10,  5,  0,  2,  3,  0,  1,  6, 12],\n",
       "       [11,  3,  1,  2,  1,  0,  1,  9,  0,  2,  9, 12],\n",
       "       [11,  2, 10,  8,  3,  0,  1,  3,  0,  1,  9, 12],\n",
       "       [11,  3,  1,  1, 10,  0,  1,  5,  0,  1,  7, 12]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainmod[0:10] #10 samples including the <sos> and <end> tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2ef98-b286-41aa-b09c-9b33761eb4b5",
   "metadata": {},
   "source": [
    "The input of the decoder must start with the start token but the end token must be predicted by the model. Therefore, removing the end tokens from the input of the decoder; We will refer to the input of the decoder as **y_train_dec_input**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "04ca766c-2071-4e09-be07-7bf6f12362b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  3,  1, ...,  0,  3,  4],\n",
       "       [11,  2, 10, ...,  0,  2,  7],\n",
       "       [11,  2, 10, ...,  0,  1,  9],\n",
       "       ...,\n",
       "       [11,  3,  1, ...,  0,  2, 10],\n",
       "       [11,  3,  1, ...,  0,  4,  1],\n",
       "       [11,  3,  1, ...,  0,  3,  5]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dec_input  = y_trainmod[:,:-1] \n",
    "y_train_dec_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7256ec6-f04d-4bcf-97d6-7dbecde86e5d",
   "metadata": {},
   "source": [
    "The expected output of the decoder will be y_trainmod but only shifted one time step forward and no <sos> token; we will refer to the target output as **y_trainmod_dec_output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "87f47938-0c2e-4f0c-a58b-e7a8fff17fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 11)\n",
      "[[ 3  1  1  7  0  1  5  0  3  4 12]\n",
      " [ 2 10  9  1  0  1  3  0  2  7 12]\n",
      " [ 2 10 10  8  0  2  3  0  1  9 12]]\n",
      "this is the desired output to be predicted\n"
     ]
    }
   ],
   "source": [
    "y_trainmod_dec_output = y_trainmod[:,1:]\n",
    "print(y_trainmod_dec_output.shape)\n",
    "print(y_trainmod_dec_output[0:3])\n",
    "print(f\"this is the desired output to be predicted\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1cf11-0c4e-4c48-b60e-5afb398ad9f0",
   "metadata": {},
   "source": [
    "### Some Notes on the Decoder \n",
    "\n",
    "- Training Mode\n",
    "\n",
    "    The training mode uses a method called teacher training in which all parts of the input are fed into the model. The model is designed to make predictions one at a time but during training we will make 12 predictions parallally, meaning that for example the <sos> token is given, then it goes through a layer embeddig creating a vector of 20 indexes. We will then add the positional encodings. The model then goes through the causal MHA in which the attention scores between the input decoder words are calculated. Then, we add the look-ahead mask; this mask makes sure that at each iteration of prediction t the model only sees the t-1 words before the current word. Then the result goes through the cross MHA. The two feed forward neural networks (last one with a softmax activation function) to make predictions.\n",
    "\n",
    "  Note that the teacher training ensures that no matter the prediction of the model, at the next time step, the correct output will be fed into the model. The correct output that is fed to the model during training will be replaced by the output of the decoder during the inference mode. But since we already know what the input of the next step should be during training, we can run 12 calculations parallaly. \n",
    "  \n",
    "- Inference Mode\n",
    "\n",
    "  This is the mode in which the deocder makes predictions iteratively for t = 1:12 time steps (given that the token at t=0 refers to the start token). At each time j, the model predicts the all the words from t = 1:j. We will take only the last prediction (which is the new word), taking the argmax of that vector of probabilities gives us the next token predicted. This token is then concatenated with the original input of the model and the decoder runs again to make predictions for the 1:j+1 words at time j+1.\n",
    "\n",
    "How would the training and gradients work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a089705c-fd66-43bf-ace0-25a7e8f7691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_decoder(shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a function to initialize the inputs of the decoder during the inference mode \n",
    "    \n",
    "    Input \n",
    "    shape: The number of samples to make a prediction for \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return np.full((shape, 1), 11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e019cd-83bd-4b3b-9063-e97b3e576971",
   "metadata": {},
   "source": [
    "### Define the Custom Learning Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "37ed2140-f68c-4d62-bf95-7ff268637fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  \"\"\"\n",
    "  Custom learning rate schedule that implements the learning rate function\n",
    "  described in the original Transformer paper. The learning rate is increased\n",
    "  linearly for the first `warmup_steps` training steps, and then decreased\n",
    "  proportionally to the inverse square root of the step number.\n",
    "\n",
    "  Args:\n",
    "    d_model (int): the dimensionality of the model.\n",
    "    warmup_steps (int): the number of steps taken to increase the learning rate\n",
    "      linearly. Default is 4000.\n",
    "\n",
    "  Attributes:\n",
    "    d_model (float): the dimensionality of the model as a float.\n",
    "    warmup_steps (int): the number of steps taken to increase the learning rate\n",
    "      linearly.\n",
    "\n",
    "  Methods:\n",
    "    __call__(step): returns the learning rate at the given step.\n",
    "\n",
    "  Returns:\n",
    "    The learning rate at the given step.\n",
    "  \"\"\"\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    \"\"\"\n",
    "    Returns the learning rate at the given step.\n",
    "\n",
    "    Args:\n",
    "      step (int): the current training step.\n",
    "\n",
    "    Returns:\n",
    "      The learning rate at the given step as a float32 tensor.\n",
    "    \"\"\"\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b072d55-f237-4da8-a416-c9727d5c03c8",
   "metadata": {},
   "source": [
    "### Define the Transformer Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7789f01c-5f7e-47eb-8b45-5f0eb097f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model): \n",
    "\n",
    "    def __init__(self, len_emb, dim_kv, dim_q, heads, d_model,\n",
    "                dd_model, iterEnc, iterDec, df_model, len_seq_out,\n",
    "                drop_rate = 0.1, epsilon = 1e-6):\n",
    "        \n",
    "        super(Transformer, self).__init__()\n",
    "        self.len_emb = len_emb\n",
    "        self.len_seq_out = len_seq_out\n",
    "        \n",
    "        self.encoder = Encoder(dim_kv, dim_q, heads, d_model, len_emb, len_human_vocab, iterEnc, drop_rate = 0.1) #shape = (#samples, enc_len_seq, len_emb) \n",
    "        self.decoder = Decoder(len_emb, dim_kv, dim_q, heads, dd_model, iterDec, len_seq_out, drop_rate = 0.1, epsilon = 1e-6) #(#samples, dec_len_seq, len_emb) \n",
    "        \n",
    "        self.dense = Dense(units = len_machine_vocab, activation = 'softmax')\n",
    "        self.learning_rate = CustomSchedule(d_model)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "        \n",
    "    def call (self, input_enc, input_dec, enc_pad_mask = True, training = True): \n",
    "        \n",
    "        \"\"\"\n",
    "        this is the forward pass of the model \n",
    "        \"\"\"\n",
    "        \n",
    "        num_samples = input_enc.shape[0]\n",
    "\n",
    "        # Run through the Encoder\n",
    "        enc_output = self.encoder(input_enc, training = training, enc_mask = enc_pad_mask)\n",
    "        # Run through the Decoder \n",
    "        dec_outputs = self.decoder(input_dec, enc_output, training = training) #shape = (#samples,len_seq_out, len_emb]\n",
    "        dec_outputs = self.dense(dec_outputs)  # shape = (#samples, len_seq_out , len_machine_vocab)\n",
    "        return(dec_outputs)\n",
    "\n",
    "    def predict(self,input_enc, enc_pad_mask = True, training = False): \n",
    "        \n",
    "        # Initialize the input of the decoder \n",
    "        input_dec = init_decoder(input_enc.shape[0])\n",
    "        \n",
    "        for i in range(self.len_seq_out): \n",
    "            #print(f\"iteration {i}\")\n",
    "            dec_output = self.call(input_enc, input_dec, training = False)\n",
    "            #print(f\"this is the shape of decoder output before slicing: {dec_output.shape}\")\n",
    "                \n",
    "            # picking only the corresponding prediction for ith letter\n",
    "            dec_output = dec_output[:,-1,:] \n",
    "            arg = tf.cast((tf.argmax(dec_output,axis = -1)),dtype = tf.float32)\n",
    "                \n",
    "            # Update the decoder output \n",
    "            input_dec = tf.concat([input_dec, arg[:, np.newaxis]], axis = -1)\n",
    "            #print(f\"input_dec after {i}th iteration : {input_dec}\")\n",
    "        \n",
    "        return(input_dec)\n",
    "        \n",
    "    def evaluate(self, input_enc, expected_output): \n",
    "        predictions = self.predict(input_enc, enc_pad_mask = True, training = False)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, expected_output), tf.float32)) # finds the mean accuracy. \n",
    "        return(accuracy) \n",
    "        \n",
    "    \n",
    "    def train_step(self, input_enc, input_dec, y_trainmod, training=True, enc_pad_mask = True):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions = self.call(input_enc, input_dec, enc_pad_mask = True, training=True)\n",
    "            # Compute the loss\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_trainmod, predictions, from_logits=True)\n",
    "            # Take average across all samples in the batch \n",
    "            loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # Apply gradients to update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        predicted_classes = tf.argmax(predictions, axis=-1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_classes, y_trainmod), tf.float32)) # finds the mean accuracy. \n",
    "        return loss, accuracy\n",
    "\n",
    "        \n",
    "    def fit_model(self, input_enc, input_dec, y_trainmod, epochs=10, batch_size=200):\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            total_accuracy = 0\n",
    "            num_batches = len(input_enc) // batch_size\n",
    "            \n",
    "            for i in range(0, len(input_enc), batch_size):\n",
    "                batch_input_enc = input_enc[i:i+batch_size]\n",
    "                batch_input_dec = input_dec[i:i+batch_size]\n",
    "                batch_y_trainmod = y_trainmod[i:i+batch_size]\n",
    "    \n",
    "                loss, accuracy = self.train_step(batch_input_enc, batch_input_dec, batch_y_trainmod)\n",
    "                total_loss += loss\n",
    "                total_accuracy += accuracy\n",
    "        \n",
    "            avg_loss = total_loss / num_batches\n",
    "            avg_accuracy = total_accuracy / num_batches\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss.numpy()}, Accuracy: {avg_accuracy.numpy()}\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bdb75b7d-da40-4f9b-9bbd-4cbb4510c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_emb= 30 \n",
    "dim_kv= 30\n",
    "dim_q= 30\n",
    "heads= 3\n",
    "d_model=30\n",
    "dd_model= 30\n",
    "iterEnc= 6 \n",
    "iterDec= 6\n",
    "df_model= 30\n",
    "len_seq_out= 11\n",
    "drop_rate = 0.1\n",
    "epsilon = 1e-6\n",
    "num_samples = X_trainmod.shape[0]\n",
    "model = Transformer(len_emb, dim_kv, dim_q, heads, d_model,\n",
    "                dd_model, iterEnc, iterDec, df_model, len_seq_out,\n",
    "                drop_rate = 0.1, epsilon = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e90910-c5b0-4464-80e4-01ca23693ece",
   "metadata": {},
   "source": [
    "This is the first block of code. if training ==True: Note that the model returns values for all time steps except for the <sos> token (T=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a2cad92c-328f-4172-9974-c7b293656cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7500, 11, 13])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Call the transformer \n",
    "res = model(X_trainmod, y_train_dec_input, training = True, enc_pad_mask= False) \n",
    "res.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9fb1f21c-43f1-4de0-9964-8f47a68ea864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 12), dtype=float32, numpy=\n",
       "array([[11.,  9.,  9.,  9.,  9.,  9.,  1.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  1.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  1.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  1.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  6.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  1.,  6.,  6.,  6.,  6.,  6.],\n",
       "       [11.,  9.,  9.,  9.,  9.,  9.,  1.,  6.,  6.,  6.,  6.,  6.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_trainmod[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37674d-84c1-4dd0-9115-9c9f69861839",
   "metadata": {},
   "source": [
    "Also note that the model doesn't make 12 predictions but 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b98497f-9443-4061-a93d-a7399949474a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1761823147535324, Accuracy: 0.9657984375953674\n",
      "Epoch 2/10, Loss: 0.17642322182655334, Accuracy: 0.9660934209823608\n",
      "Epoch 3/10, Loss: 0.1827087700366974, Accuracy: 0.9630221724510193\n",
      "Epoch 4/10, Loss: 0.15859493613243103, Accuracy: 0.9724570512771606\n",
      "Epoch 5/10, Loss: 0.1602710336446762, Accuracy: 0.9702333807945251\n",
      "Epoch 6/10, Loss: 0.15363916754722595, Accuracy: 0.9731572270393372\n",
      "Epoch 7/10, Loss: 0.16199634969234467, Accuracy: 0.9702948331832886\n",
      "Epoch 8/10, Loss: 0.16432568430900574, Accuracy: 0.9698035717010498\n",
      "Epoch 9/10, Loss: 0.1478009819984436, Accuracy: 0.9749385714530945\n",
      "Epoch 10/10, Loss: 0.16093496978282928, Accuracy: 0.9705649614334106\n"
     ]
    }
   ],
   "source": [
    "model.fit_model(X_trainmod, y_train_dec_input, y_trainmod_dec_output, epochs = 10) # around 170 iterations 130 already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "766d4d23-b55d-4518-9596-7a284ea08887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.,  3.,  1.,  1.,  8.,  0.,  1.,  4.,  0.,  1.,  8., 12.],\n",
       "       [11.,  2., 10., 10., 10.,  0.,  1., 10.,  0.,  1.,  7., 12.],\n",
       "       [11.,  2., 10., 10., 10.,  0.,  2.,  1.,  0.,  1.,  6., 12.],\n",
       "       [11.,  2., 10.,  8.,  1.,  0.,  2.,  3.,  0.,  1.,  7., 12.],\n",
       "       [11.,  3.,  1.,  1.,  3.,  0.,  1.,  3.,  0.,  1.,  8., 12.],\n",
       "       [11.,  2., 10.,  8.,  1.,  0.,  1.,  9.,  0.,  1.,  8., 12.],\n",
       "       [11.,  2., 10.,  9.,  7.,  0.,  2.,  1.,  0.,  4.,  2., 12.],\n",
       "       [11.,  3.,  1.,  1.,  6.,  0.,  2.,  3.,  0.,  4.,  1., 12.],\n",
       "       [11.,  2., 10.,  8.,  4.,  0.,  2.,  1.,  0.,  1.,  3., 12.],\n",
       "       [11.,  2., 10.,  8.,  8.,  0.,  2.,  3.,  0.,  3.,  7., 12.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_testmod[0:10], init_decoder(10), training = False).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "369f590e-1d78-4627-8e1c-e6dd8cc6bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: <sos>2007-03-07<end>,\n",
      " Expected output 7 mar 2007\n",
      "\n",
      "predictions: <sos>1999-09-06<end>,\n",
      " Expected output 06.03.99\n",
      "\n",
      "predictions: <sos>1999-10-05<end>,\n",
      " Expected output tuesday october 5 1999\n",
      "\n",
      "predictions: <sos>1970-12-06<end>,\n",
      " Expected output 6 december 1970\n",
      "\n",
      "predictions: <sos>2002-02-07<end>,\n",
      " Expected output 07 feb 2020\n",
      "\n",
      "predictions: <sos>1970-08-07<end>,\n",
      " Expected output friday august 7 1970\n",
      "\n",
      "predictions: <sos>1986-10-31<end>,\n",
      " Expected output friday october 31 1986\n",
      "\n",
      "predictions: <sos>2005-12-30<end>,\n",
      " Expected output 30 december 2005\n",
      "\n",
      "predictions: <sos>1973-10-02<end>,\n",
      " Expected output tuesday october 2 1973\n",
      "\n",
      "predictions: <sos>1977-12-26<end>,\n",
      " Expected output 26 dec 1977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions = predictions.numpy()\n",
    "for j in range(10):#predictions.shape[0]):\n",
    "    x = []\n",
    "    for i in range(12): \n",
    "        x = x + reverse_lookup([predictions[j][i]])\n",
    "        result = ''.join(x)\n",
    "    print(f\"predictions: {result},\\n Expected output {X_test[j]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "86a51fec-a198-4453-988f-fb0e570c5237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.95683336>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_testmod,y_testmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b72e3-936b-4776-81c8-cf28e45a2eac",
   "metadata": {},
   "source": [
    "#### Some intuition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698dfc1f-23dd-45b9-a2e5-da9dae24dce1",
   "metadata": {},
   "source": [
    "Here is the situation we are dealing with: \n",
    "the call method does predict both the testing and training datasets accurately but this is only when the y_trainmod or testmod is given to it. if we give it the y_input that is just the start token, the loss seems to be infinitiy. but generally speaking, during the training process, we must be able to give the y_trainmod to it and this should make no difference in the output prediction . \n",
    "\n",
    "so check if the look-ahead y_trianmod \n",
    "\n",
    "transform the training loop such that it'll replace the tensor with the predicted value. but in the testing we have a loop and in each loop we might have to actually pick the last prediction because the transfomer creates a 12,13 predictions and you'd pick the last one to predict. but why? if the transformer model predicts the words for all and you only need say the second word, then you take only the second word and run it again. let it make predictions for all but you only need the corresponding prediction. but what you are doing in the decoder tensting section is that the model still makes predictions for all of the len_seq_out (12) but you then run it all through another dense layer to collapse it. if the transformer's model is created correctly, it must make predictions for all of the time sequences (12). but remind me again, why do we take only the last prediction? because technically this must be the end sequence to be predicted why do we take the last prediction? \n",
    "the transformer should only make predictions for the next word not all the sentences. in that case you only take the last time-step predcition and this referes to the lastest word predicted. \n",
    "\n",
    "I know one approach. that we remove the layer that collapses all the 12 time -step predictions into 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817a4a2-5d48-43cf-bd39-dcd88c32a6f4",
   "metadata": {},
   "source": [
    "so our model does well both for the testing and training datasets in the training mode. when it is predicting all the words at the same time. are we predicting all the words at the same time? yes. but in order to make the accurate predictions oh the look-ahead mask. the look ahead mask what does it say? not to look at the words that are considered not given. right. but your input is a set of integers. these ingegers are then given to the model. so the look-ahead mask must know which algorithms to hide? no each integer in the vector integer input will be mapped to a row. so then the model needs to know which rows to completely ignore. so essentailly the input of the decoder is say 12,20: \n",
    "in the sake of training, the input of the decoder is vector (12,) containing the correct output. then this vector is mapped to (12,20); so to each integer index is mapped to a row of integers. now the model looks at all of them with respect to another to learn if there are any intera dependencies between them. but the input has all the correct values. to produce the correct output the model simultanously predicts all the words. but to predict the first word, the model must not see what the correct input is for the first word. so for the first prediction, the model will only see the start token. which is 11. then 11 must be padded to a vector of [11, 0*11]; then this vector is mapped to an embedding so now we have a matrix of 12x20 notice that the model must only pay attention to the first row and no attention to the rest of the words. in the attention mechanism, the attention scores will be of dimension 12x12 implying how much attention must be given to every word in the sequence. so in the first time step prediction, the model must not pay attention to any letters except the first one. so we'll need an attention mask such that when added to the model, it will not pay any attention to any index larger than 0 index. so the attention mask that must be given to the model is \n",
    "\n",
    "\n",
    "but if the decoder is making predictions for all of the time steps simultanously, then for the first time step we only take the start token then int 11 will be mapped to (12,20). my question is how would you parallely make predictions for all time steps? \n",
    "we have created a look-ahead mask that for each row, it'll say what words to focus on. but wouldn't each time step has its own attention matrix? yes. ok then the first attention matrix will be added to a mask of [0 ,1 ,1 ,1,...1] which forces all rows of the attention scores to only pay attention to the first word. but the problem is that all those words are being mapped. so we literally have a 12, complete vector given as the input of the decoder. so then we calculate the attention scores which implies how much attention must be given to each word. so we're saying when predicting the first word, only pay attentino to the start token and nothing else. but when it comes to the second row, meaning second time-step, only pay attention to the first two tokens. but the thing is that each one of them is an embedding no? no they will all be attention scores. so the second row would entail the attention scores for the rest of tokens to become 0. \n",
    "\n",
    "then moving to the next attention mechanism, the first row will be mapped to the prediction based on the enc output and the starting token right? yes. so then it'll be one row of len_emb this is the output of the attention 1. and then this will be mapped to a query which means that only the columns will differ. but the number of rows will be the same only 1. then the key is produced from the enc_output and has dim (27,20) say you map to 20 columns so then a 1x20 is multiplied by a 20x27 we would get a 1x27 row of attention scores we then want to multiply this with its corresponding row 1x20 dimensions won't match. now the thing is that we will make prediction for all of the time steps. doesn't make sense. \n",
    "\n",
    "\n",
    "\n",
    "let's start again; \n",
    "we have the start token fed into the decoder; then the decoder input will run through an embedding layer which is (1,512). then into the MHA1 where it is mapped to query, key and value matrices. the query and key both have dimension 1x20 so when multiplying, we will get a scalar and then once run through the softmax it'll give us the attention score of 1 with dim 1x1 which is then multipleid to the value dim 1x20 to give us 1x20 vector. since we only have one token, the attention score simply represents how similar the start token is to itself.\n",
    "\n",
    "Note that if we gave the model 2 words instead of 1, then those 2 words must be mapped to 2x512 embeddings layer. then the query and key then dot produdct the attention scores will be of dimension 2x2. if 3 words given then attention scores are 3x3. \n",
    "\n",
    "\n",
    "note that the dimension is different from what you are training the model to have. in our model you pad the sequence to be equal in length to the complete input. \n",
    "\n",
    "\n",
    "also note that the look-ahead mask is only given when the model is in training phase. that is when all the words are simultanously processes but in truth we must run it row by row. \n",
    "\n",
    "once into the MHA 2, we have a row vector of 512 dimensions. and this will be mapped to a query 1x512. then we have the enc_output that has 3x512 in it. the dot produce will give us a 1x3 vector saying how similar the start token is to each row of the enc_output. \n",
    "\n",
    "if we have 2 words in the input-dec, then we would have 2x512 as the query and the key would be a 3x512. then result of the dot product will be a matrix of 2x3. each row will show the attention scores or the measurement of the dependencies of that word with each word in the encoder. \n",
    "\n",
    "so taking our 1x3 attention scores, we multiply it with the value which is 3x512. we end up with a 1x512 vector. this vector is then used to make predictions. how to make predictions and with this one given row how could we make predictions on all of the time steps? we don't. we only produce of row of probabilities predicting the next word. \n",
    "\n",
    "what if program the transformer such that the last prediction is the for the last time step along the 12 steps? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8790f7d-ffc7-43ed-b408-67b2fb45897d",
   "metadata": {},
   "source": [
    "in the cross-attention, imagine we have the y_input as [11,0,0,...,0]; in that case, when we are calculating the dependencies of this input sentence with the encoder output, we want to only make attention scores for the first word and all the encoder output i.e. we want the first word attention scores with all 27 other words. but that's it. no other attention must be made. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a105e-2d49-4e7a-8e6f-3c3f350c6736",
   "metadata": {},
   "source": [
    "you can modify your code such that if the input given is none, then the model generates it's own values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94628a4-958c-4867-99e6-2a18ba9a9bb5",
   "metadata": {},
   "source": [
    "analyze how the input of the decoder with its dimensions merges with the input coming from the encoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbe750-51a5-40d8-a0a0-c56a6b63cf3e",
   "metadata": {},
   "source": [
    "Come back to the imported libraries and clean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de8f17-ce87-4caf-bf7a-e964f470f9d9",
   "metadata": {},
   "source": [
    "one thought is that the model learns to predict the start token when the start token is given to it. so then the start token is appended to the result and once the start token is given the model again predicts the start token. so what if we give it another input? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

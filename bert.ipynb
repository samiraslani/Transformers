{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ed5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec697d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "seq_len = 20\n",
    "dropout = 0.5\n",
    "num_epochs = 10\n",
    "label_col = \"Product\"\n",
    "tokens_path = \"Output/tokens.pkl\"\n",
    "labels_path = \"Output/labels.pkl\"\n",
    "data_path = \"/Users/Downloads/modelstatedict\"\n",
    "text_col_name = \"Consumer complaint narrative\"\n",
    "label_encoder_path = \"Output/label_encoder.pkl\"\n",
    "product_map = {'Vehicle loan or lease': 'vehicle_loan',\n",
    "               'Credit reporting, credit repair services, or other personal consumer reports': 'credit_report',\n",
    "               'Credit card or prepaid card': 'card',\n",
    "               'Money transfer, virtual currency, or money service': 'money_transfer',\n",
    "               'virtual currency': 'money_transfer',\n",
    "               'Mortgage': 'mortgage',\n",
    "               'Payday loan, title loan, or personal loan': 'loan',\n",
    "               'Debt collection': 'debt_collection',\n",
    "               'Checking or savings account': 'savings_account',\n",
    "               'Credit card': 'card',\n",
    "               'Bank account or service': 'savings_account',\n",
    "               'Credit reporting': 'credit_report',\n",
    "               'Prepaid card': 'card',\n",
    "               'Payday loan': 'loan',\n",
    "               'Other financial service': 'others',\n",
    "               'Virtual currency': 'money_transfer',\n",
    "               'Student loan': 'loan',\n",
    "               'Consumer Loan': 'loan',\n",
    "               'Money transfers': 'money_transfer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da2b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(name, obj):\n",
    "    \"\"\"\n",
    "    Function to save an object as pickle file\n",
    "    \"\"\"\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load_file(name):\n",
    "    \"\"\"\n",
    "    Function to load a pickle object\n",
    "    \"\"\"\n",
    "    return pickle.load(open(name, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64246157",
   "metadata": {},
   "source": [
    "## Process text data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccad4958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
       "      <td>PA</td>\n",
       "      <td>186XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3274605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "      <td>Loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>Denied request to lower payments</td>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ALLY FINANCIAL INC.</td>\n",
       "      <td>NJ</td>\n",
       "      <td>088XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>PA</td>\n",
       "      <td>19067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3198225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Was not notified of investigation status or re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>31707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4863965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Medical debt</td>\n",
       "      <td>Took or threatened to take negative or legal a...</td>\n",
       "      <td>Threatened or suggested your credit would be d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medical Data Systems, Inc.</td>\n",
       "      <td>VA</td>\n",
       "      <td>22033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4866449.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    2019-06-13  Credit reporting, credit repair services, or o...   \n",
       "1    2019-11-01                              Vehicle loan or lease   \n",
       "2    2019-04-01  Credit reporting, credit repair services, or o...   \n",
       "3    2021-11-01  Credit reporting, credit repair services, or o...   \n",
       "4    2021-11-02                                    Debt collection   \n",
       "\n",
       "        Sub-product                                              Issue  \\\n",
       "0  Credit reporting               Incorrect information on your report   \n",
       "1              Loan                        Struggling to pay your loan   \n",
       "2  Credit reporting               Incorrect information on your report   \n",
       "3  Credit reporting  Problem with a credit reporting company's inve...   \n",
       "4      Medical debt  Took or threatened to take negative or legal a...   \n",
       "\n",
       "                                           Sub-issue  \\\n",
       "0                Information belongs to someone else   \n",
       "1                   Denied request to lower payments   \n",
       "2                           Account status incorrect   \n",
       "3  Was not notified of investigation status or re...   \n",
       "4  Threatened or suggested your credit would be d...   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0                                                NaN   \n",
       "1  I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2  Company has responded to the consumer and the ...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  Company State ZIP code Tags  \\\n",
       "0       CAPITAL ONE FINANCIAL CORPORATION    PA    186XX  NaN   \n",
       "1                     ALLY FINANCIAL INC.    NJ    088XX  NaN   \n",
       "2  TRANSUNION INTERMEDIATE HOLDINGS, INC.    PA    19067  NaN   \n",
       "3  TRANSUNION INTERMEDIATE HOLDINGS, INC.    GA    31707  NaN   \n",
       "4              Medical Data Systems, Inc.    VA    22033  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0       Consent not provided           Web           2019-06-13   \n",
       "1           Consent provided           Web           2019-11-01   \n",
       "2       Consent not provided           Web           2019-04-01   \n",
       "3                        NaN           Web           2021-11-01   \n",
       "4                        NaN           Web           2021-11-02   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                NaN   \n",
       "1      Closed with explanation              Yes                NaN   \n",
       "2      Closed with explanation              Yes                NaN   \n",
       "3                  In progress              Yes                NaN   \n",
       "4                  In progress              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0     3274605.0  \n",
       "1     3425257.0  \n",
       "2     3198225.0  \n",
       "3     4863965.0  \n",
       "4     4866449.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"complaints.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e6a0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "      <td>Loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>Denied request to lower payments</td>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ALLY FINANCIAL INC.</td>\n",
       "      <td>NJ</td>\n",
       "      <td>088XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Their investigation did not fix an error on yo...</td>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>NY</td>\n",
       "      <td>109XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3299394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit inquiries on your report that you don't...</td>\n",
       "      <td>I am a victim of Identity Theft &amp; currently ha...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>MT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3692762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>Two accounts are still on my credit history af...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>FL</td>\n",
       "      <td>328XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3294745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Other personal consumer report</td>\n",
       "      <td>Identity theft protection or other monitoring ...</td>\n",
       "      <td>Received unwanted marketing or advertising</td>\n",
       "      <td>Receiving daily telephone call ( s ) from XXXX...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>NRA Group, LLC</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3186954.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date received                                            Product  \\\n",
       "1     2019-11-01                              Vehicle loan or lease   \n",
       "7     2019-07-08  Credit reporting, credit repair services, or o...   \n",
       "8     2020-06-10  Credit reporting, credit repair services, or o...   \n",
       "10    2019-07-03  Credit reporting, credit repair services, or o...   \n",
       "13    2019-03-21  Credit reporting, credit repair services, or o...   \n",
       "\n",
       "                       Sub-product  \\\n",
       "1                             Loan   \n",
       "7                 Credit reporting   \n",
       "8                 Credit reporting   \n",
       "10                Credit reporting   \n",
       "13  Other personal consumer report   \n",
       "\n",
       "                                                Issue  \\\n",
       "1                         Struggling to pay your loan   \n",
       "7   Problem with a credit reporting company's inve...   \n",
       "8                         Improper use of your report   \n",
       "10               Incorrect information on your report   \n",
       "13  Identity theft protection or other monitoring ...   \n",
       "\n",
       "                                            Sub-issue  \\\n",
       "1                    Denied request to lower payments   \n",
       "7   Their investigation did not fix an error on yo...   \n",
       "8   Credit inquiries on your report that you don't...   \n",
       "10                      Account information incorrect   \n",
       "13         Received unwanted marketing or advertising   \n",
       "\n",
       "                         Consumer complaint narrative  \\\n",
       "1   I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "7   Hello This complaint is against the three cred...   \n",
       "8   I am a victim of Identity Theft & currently ha...   \n",
       "10  Two accounts are still on my credit history af...   \n",
       "13  Receiving daily telephone call ( s ) from XXXX...   \n",
       "\n",
       "                              Company public response  \\\n",
       "1   Company has responded to the consumer and the ...   \n",
       "7   Company has responded to the consumer and the ...   \n",
       "8   Company has responded to the consumer and the ...   \n",
       "10  Company has responded to the consumer and the ...   \n",
       "13  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                   Company State ZIP code           Tags  \\\n",
       "1                      ALLY FINANCIAL INC.    NJ    088XX            NaN   \n",
       "7   TRANSUNION INTERMEDIATE HOLDINGS, INC.    NY    109XX            NaN   \n",
       "8      Experian Information Solutions Inc.    MT      NaN  Servicemember   \n",
       "10     Experian Information Solutions Inc.    FL    328XX            NaN   \n",
       "13                          NRA Group, LLC    MA      NaN            NaN   \n",
       "\n",
       "   Consumer consent provided? Submitted via Date sent to company  \\\n",
       "1            Consent provided           Web           2019-11-01   \n",
       "7            Consent provided           Web           2019-07-08   \n",
       "8            Consent provided           Web           2020-06-10   \n",
       "10           Consent provided           Web           2019-07-03   \n",
       "13           Consent provided           Web           2019-03-27   \n",
       "\n",
       "       Company response to consumer Timely response? Consumer disputed?  \\\n",
       "1           Closed with explanation              Yes                NaN   \n",
       "7           Closed with explanation              Yes                NaN   \n",
       "8           Closed with explanation              Yes                NaN   \n",
       "10  Closed with non-monetary relief              Yes                NaN   \n",
       "13          Closed with explanation              Yes                NaN   \n",
       "\n",
       "    Complaint ID  \n",
       "1      3425257.0  \n",
       "7      3299394.0  \n",
       "8      3692762.0  \n",
       "10     3294745.0  \n",
       "13     3186954.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=[\"Consumer complaint narrative\"], inplace=True) #inplace = True changes the original dataset instead of defining a new one\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e14a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>vehicle_loan</td>\n",
       "      <td>Loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>Denied request to lower payments</td>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ALLY FINANCIAL INC.</td>\n",
       "      <td>NJ</td>\n",
       "      <td>088XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Their investigation did not fix an error on yo...</td>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>NY</td>\n",
       "      <td>109XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3299394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit inquiries on your report that you don't...</td>\n",
       "      <td>I am a victim of Identity Theft &amp; currently ha...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>MT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3692762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>Two accounts are still on my credit history af...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>FL</td>\n",
       "      <td>328XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3294745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>Other personal consumer report</td>\n",
       "      <td>Identity theft protection or other monitoring ...</td>\n",
       "      <td>Received unwanted marketing or advertising</td>\n",
       "      <td>Receiving daily telephone call ( s ) from XXXX...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>NRA Group, LLC</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3186954.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date received        Product                     Sub-product  \\\n",
       "1     2019-11-01   vehicle_loan                            Loan   \n",
       "7     2019-07-08  credit_report                Credit reporting   \n",
       "8     2020-06-10  credit_report                Credit reporting   \n",
       "10    2019-07-03  credit_report                Credit reporting   \n",
       "13    2019-03-21  credit_report  Other personal consumer report   \n",
       "\n",
       "                                                Issue  \\\n",
       "1                         Struggling to pay your loan   \n",
       "7   Problem with a credit reporting company's inve...   \n",
       "8                         Improper use of your report   \n",
       "10               Incorrect information on your report   \n",
       "13  Identity theft protection or other monitoring ...   \n",
       "\n",
       "                                            Sub-issue  \\\n",
       "1                    Denied request to lower payments   \n",
       "7   Their investigation did not fix an error on yo...   \n",
       "8   Credit inquiries on your report that you don't...   \n",
       "10                      Account information incorrect   \n",
       "13         Received unwanted marketing or advertising   \n",
       "\n",
       "                         Consumer complaint narrative  \\\n",
       "1   I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "7   Hello This complaint is against the three cred...   \n",
       "8   I am a victim of Identity Theft & currently ha...   \n",
       "10  Two accounts are still on my credit history af...   \n",
       "13  Receiving daily telephone call ( s ) from XXXX...   \n",
       "\n",
       "                              Company public response  \\\n",
       "1   Company has responded to the consumer and the ...   \n",
       "7   Company has responded to the consumer and the ...   \n",
       "8   Company has responded to the consumer and the ...   \n",
       "10  Company has responded to the consumer and the ...   \n",
       "13  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                   Company State ZIP code           Tags  \\\n",
       "1                      ALLY FINANCIAL INC.    NJ    088XX            NaN   \n",
       "7   TRANSUNION INTERMEDIATE HOLDINGS, INC.    NY    109XX            NaN   \n",
       "8      Experian Information Solutions Inc.    MT      NaN  Servicemember   \n",
       "10     Experian Information Solutions Inc.    FL    328XX            NaN   \n",
       "13                          NRA Group, LLC    MA      NaN            NaN   \n",
       "\n",
       "   Consumer consent provided? Submitted via Date sent to company  \\\n",
       "1            Consent provided           Web           2019-11-01   \n",
       "7            Consent provided           Web           2019-07-08   \n",
       "8            Consent provided           Web           2020-06-10   \n",
       "10           Consent provided           Web           2019-07-03   \n",
       "13           Consent provided           Web           2019-03-27   \n",
       "\n",
       "       Company response to consumer Timely response? Consumer disputed?  \\\n",
       "1           Closed with explanation              Yes                NaN   \n",
       "7           Closed with explanation              Yes                NaN   \n",
       "8           Closed with explanation              Yes                NaN   \n",
       "10  Closed with non-monetary relief              Yes                NaN   \n",
       "13          Closed with explanation              Yes                NaN   \n",
       "\n",
       "    Complaint ID  \n",
       "1      3425257.0  \n",
       "7      3299394.0  \n",
       "8      3692762.0  \n",
       "10     3294745.0  \n",
       "13     3186954.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace({\"Product\": product_map}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207cee2",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49752a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 1, ..., 1, 2, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data[\"Product\"]) #looks through the column 'Product' and assigns a factor to each category. \n",
    "\n",
    "labels = label_encoder.transform(data[label_col]) #replace the categories with their corresponding integers assigned. \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82807cb2-5fe3-4fa1-b9a0-a7b0edaf9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e405c",
   "metadata": {},
   "source": [
    "### Process the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b148d6b-0e40-4965-ace2-705f425d7495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     I contacted Ally on Friday XX/XX/XXXX after fa...\n",
      "7     Hello This complaint is against the three cred...\n",
      "8     I am a victim of Identity Theft & currently ha...\n",
      "10    Two accounts are still on my credit history af...\n",
      "13    Receiving daily telephone call ( s ) from XXXX...\n",
      "Name: Consumer complaint narrative, dtype: object\n",
      "\n",
      "Number of samples: 162985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['Consumer complaint narrative']\n",
    "print(x.head())\n",
    "print(f\"\\nNumber of samples: {len(x)}\")\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34ffaab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I contacted Ally on Friday XX/XX/XXXX after falling behind on payments due to being out of work for a short period of time due to an illness. I chated with a representative after logging into my account regarding my opitions to ensure I protect my credit and bring my account current. \\n\\nShe advised me that before an extenstion could be done, I had to make a payment in the amount of {$270.00}. I reviewed my finances, as I am playing catch up on all my bills and made this payment on Monday XX/XX/XXXX. This rep advised me, once this payment posts to my account to contact Ally back for an extention or to have a payment deffered to the end of my loan. \\n\\nWith this in mind, I contacted Ally again today and chatted with XXXX. I explained all of the above and the information I was provided when I chatted with the rep last week. She asked several questions and advised me that a one or two month  extension/deffered payment could be done however partial payment is needed! WHAT? She advised me {$230.00} or there abouts would be due within 10 days from me accepting the agreement and then the remaining bal of {$150.00} or there abouts would be due in XX/XX/XXXX. In XX/XX/XXXX, my payments of {$380.00} per month would resume. \\n\\nIf this was the case, I SHOULD HAVE JUST BEEN OFFERED THIS WHEN I JUST MADE MY PAYMENT so that I could catch up on my bills. \\n\\nThis company was working with XXXX in New Jersey which has since closed most likely due to illegal practices, they changed my loan company to this company after I had signed paperwork for another, kill you with interest rates and has NEVER once considered refiancing my vechile for a lower interest rate ( due to the age of the vechile other companies will not take it ) and THEY DO NOT WORK WITH YOU!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the input to a list: \n",
    "input_text = list(x)\n",
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54c337b3-c590-44b1-b780-27a59ed83ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_text(x,m): \n",
    "    \"\"\"\n",
    "    Input \n",
    "    \n",
    "    X       : The input sentences into the model. Note that X must be in the format of a list. \n",
    "    m       : The fixed length of the sequences. \n",
    "\n",
    "    Output\n",
    "    \n",
    "    Tokens : This is a list of dictionaries. Each dictionary corresponds to a sampel sequence. \n",
    "             The dictionary contains a vector of integers correponding to the words in the sequence \n",
    "             and an attention mask. \n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the text into lower case: \n",
    "    input_text = [i.lower() for i in x]\n",
    "    \n",
    "    # Remove the punctuations: \n",
    "    input_text = [re.sub(r\"[^\\w\\d'\\s]+\", \" \", i) for i in input_text]\n",
    "    \n",
    "    # Remove digits from the text: \n",
    "    input_text = [re.sub(\"\\d+\", \"\", i) for i in input_text]\n",
    "\n",
    "    # Once digits are removed, there will be double spaces between the words. Remove them: \n",
    "    input_text = [re.sub(' +', ' ', i) for i in input_text]\n",
    "    \n",
    "    # Remove more than one instance of 'x': \n",
    "    input_text = [re.sub(r'[x]{2,}', \"\", i) for i in input_text]\n",
    "    \n",
    "    seq_len = 20 #limiting the length of the sequence. \n",
    "    tokens = [tokenizer(i, padding=\"max_length\", max_length=seq_len, \n",
    "                    truncation=True, return_tensors=\"pt\")  for i in tqdm(input_text)]\n",
    "    \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f330626-3537-44b1-8423-0cc5da8cebe1",
   "metadata": {},
   "source": [
    "The BertTokenizer splits the words and mapps them to a Bert Dictionary containing 30,000 tokens. Notice that the starting and ending integer tokens are the same for all the sample complaints; this is because the first and last indices refer to the $<SOS>$ and $<EOS>$ tokens. Furthermore, the unknown tokens are split into the most known subwords or characters. This allows the model to handle out-of-vocabulary words gracefully. In addition to mapping the words to a vector of integers, Tokenizer can also pad or truncate the sequences and define an attention mask along with the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db3432f7-baaf-4f1f-b97a-f6264c3abd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer to use: \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10a6b5d5-7f71-44cd-a6d7-c886d57b6d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I contacted Ally on Friday XX/XX/XXXX after falling behind on payments due to being out of work for a short period of time due to an illness. I chated with a representative after logging into my account regarding my opitions to ensure I protect my credit and bring my account current. \\n\\nShe advised me that before an extenstion could be done, I had to make a payment in the amount of {$270.00}. I reviewed my finances, as I am playing catch up on all my bills and made this payment on Monday XX/XX/XXXX. This rep advised me, once this payment posts to my account to contact Ally back for an extention or to have a payment deffered to the end of my loan. \\n\\nWith this in mind, I contacted Ally again today and chatted with XXXX. I explained all of the above and the information I was provided when I chatted with the rep last week. She asked several questions and advised me that a one or two month  extension/deffered payment could be done however partial payment is needed! WHAT? She advised me {$230.00} or there abouts would be due within 10 days from me accepting the agreement and then the remaining bal of {$150.00} or there abouts would be due in XX/XX/XXXX. In XX/XX/XXXX, my payments of {$380.00} per month would resume. \\n\\nIf this was the case, I SHOULD HAVE JUST BEEN OFFERED THIS WHEN I JUST MADE MY PAYMENT so that I could catch up on my bills. \\n\\nThis company was working with XXXX in New Jersey which has since closed most likely due to illegal practices, they changed my loan company to this company after I had signed paperwork for another, kill you with interest rates and has NEVER once considered refiancing my vechile for a lower interest rate ( due to the age of the vechile other companies will not take it ) and THEY DO NOT WORK WITH YOU!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce7cbd72-23f2-43d6-bd9a-fa73789ccc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 209.93it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens_samples = edit_text(input_text[0:2],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "916af74c-08cb-48b5-b505-735e1b4e3f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   178, 12017, 11989,  1113,   175, 22977,  1183,  1170,  4058,\n",
      "          1481,  1113, 10772,  1496,  1106,  1217,  1149,  1104,  1250,   102]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokens_samples[0].input_ids)\n",
    "tokens_samples[0].attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a0da5009-6c77-47f0-b992-c83fac15a7db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 19082,  1142, 12522,  1110,  1222,  1103,  1210,  4755,  7516,\n",
      "          2557, 14715,  3779,  1105,   178,  3535,  1199,  6187,  1874,   102]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokens_samples[1].input_ids)\n",
    "tokens_samples[1].attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d9959a-e67b-4dac-92b3-8de72e51eb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 1001.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Edit and Tokenize all samples: \n",
    "tokens = edit_text(input_text[:100],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebd5c0-d697-4d8d-9123-320fc0d77e71",
   "metadata": {},
   "source": [
    "Note that the input tokens cannot be used directly within tokens we must first extract it from the dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32327e",
   "metadata": {},
   "source": [
    "## Create PyTorch Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2969357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    \n",
    "    tokens: This is a list of dictionaries including the word bags and their corresponding attention_mask. \n",
    "    labels: This is a list of labels ranging from 0 - 8 corresponding to the product the complaint is against. \n",
    "\n",
    "    Output \n",
    "    \n",
    "    Python obj self with two attributes: Tokens and labels. \n",
    "    __len__() outputs the number of samples. \n",
    "    __getitem__ will output a specific sample's tokens and its label. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tokens, labels):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx], self.tokens[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619263d",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ad77a-668f-4414-96cd-cfbe59c1ecb5",
   "metadata": {},
   "source": [
    "The dataset is first split between the training (80%) and testing sets (20%). The training set is then split further into training (75% of 80%) and validation sets (25% of 80%). The model first takes the training set and learns the patterns by updating its parameters. We then take the validation dataset to update the hyperparameters. First the model is exposed to the training dataset and makes a prediction then by using back propagation, the model updates the parameters. once the parameters are updated we make a prediction on the validation set where we find out how the model performs on unseen data. Using the results the model produces with the validatino dataset, we can tune the hyperparameters. The model then goes through anther iteration of back propagation. Finally, when the loss is small enoguh or when the max-iteration number is reached, the model will run a prediction on the testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18287f5-d691-4db7-8bcb-2165f20c05e0",
   "metadata": {},
   "source": [
    "#### Come back to the explanation above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6178ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tokens, labels,\n",
    "                                                   test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, \n",
    "                                                      y_train,\n",
    "                                                     test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2202470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train, y_train)\n",
    "valid_dataset = TextDataset(X_valid, y_valid)\n",
    "test_dataset = TextDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe26e0d2-60a0-4f7f-8fba-48e3f679ddbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TextDataset at 0x2a616fc50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2acddb1a-4175-4d0c-af17-ee150694734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 8, 1, 1, 1, 7, 3, 7, 1, 1, 3, 2, 2, 1, 1, 1, 0, 1, 8, 1,\n",
       "       5, 0, 2, 1, 2, 5, 2, 5, 1, 5, 4, 3, 1, 2, 0, 2, 1, 7, 2, 1, 1, 5,\n",
       "       1, 0, 0, 7, 5, 1, 1, 0, 5, 1, 2, 4, 1, 1, 5, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels[0:100] # the labels corresponding to the first 100 training samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40d49f84-2e08-4bdb-a2de-3cecb9442710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  178,  112,  182, 1770, 1106, 1129, 1107, 1103, 2319, 1106, 4779,\n",
       "          170, 1313, 1114, 1115, 1217, 1163,  178,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tokens[0] # The bag of words and its corresponding attentino mask for the first training sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59c9b6de-ed72-428a-8aa5-e706e29989a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97791"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae231973-295f-4dea-8430-550b795c54cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " {'input_ids': tensor([[ 101,  178,  112,  182, 1770, 1106, 1129, 1107, 1103, 2319, 1106, 4779,\n",
       "           170, 1313, 1114, 1115, 1217, 1163,  178,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0) #first the label and then the tokens are returned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f26184-bbf5-4ed2-97cc-e892864e947a",
   "metadata": {},
   "source": [
    "Note that the tokens in each dataset must be further processed to be extracted from the dictionary tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf1488-d48c-4f17-837d-15264d7f6fa9",
   "metadata": {},
   "source": [
    "## torch.utils.data.DataLoader: \n",
    "Instead of feeding all the training dataset at once, we use a stochastic approach by feeding into the model one batch at a time. To create the batches we use **'torch.utils.data.DataLoader'** which does the following: \n",
    "\n",
    "- Batch Processing:\n",
    "\n",
    "DataLoader allows you to load data in batches, which is crucial for training models efficiently. Instead of loading the entire dataset into memory at once, it loads data in smaller chunks (batches).\n",
    "- Shuffling:\n",
    "\n",
    "It can shuffle the data at the beginning of each epoch to ensure that the model does not learn the order of the data, which helps in improving the generalization of the model.\n",
    "- Parallel Data Loading:\n",
    "\n",
    "DataLoader supports multi-threaded data loading, which means it can use multiple worker processes to load data in parallel. This can significantly speed up the data loading process.\n",
    "\n",
    "- drop_last: \n",
    "\n",
    "A boolean flag that indicates whether to drop the last incomplete batch if the dataset size is not divisible by the batch size. If True, the last batch will be dropped if it is smaller than batch_size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d03cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                         batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323823d5",
   "metadata": {},
   "source": [
    "## Create Bert model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de6f4d-f94c-48bb-b649-2ae46c01bc70",
   "metadata": {},
   "source": [
    "The objective here is to create a Bert classifier class in which we input the sequences and the pre-trained Bert model will attend to the sentences. The output is then run through an activation then a dropout layer is added and finally the output is mapped to another linear layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6b443-ba3c-4a1a-bbe5-92fcc7b0a3b9",
   "metadata": {},
   "source": [
    "### Rewrite: shorten: Understanding pooler_output in BERT Models\n",
    "BERT Model Overview\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based model used for a variety of natural language processing (NLP) tasks. It processes input sequences and generates embeddings for each token in the sequence.\n",
    "\n",
    "The [CLS] Token\n",
    "Special Token: [CLS] stands for \"classification\" and is a special token added at the beginning of the input sequence.\n",
    "Purpose: This token is used to aggregate information from the entire sequence. During training, its embedding is often utilized for sequence-level classification tasks.\n",
    "How BERT Processes the [CLS] Token\n",
    "Token Embeddings:\n",
    "\n",
    "Each token in the input sequence, including [CLS], is converted into an embedding by the model's embedding layer.\n",
    "Transformer Layers:\n",
    "\n",
    "These embeddings are processed through multiple transformer layers, refining the embeddings based on both left and right context due to bidirectional attention.\n",
    "Pooling:\n",
    "\n",
    "After the sequence has been processed through the transformer layers, the [CLS] token's embedding is pooled or extracted. This pooling typically involves a simple linear transformation to produce a fixed-size vector.\n",
    "The pooler_output\n",
    "Definition: pooler_output refers to the embedding of the [CLS] token after pooling.\n",
    "\n",
    "Pooling Process: After processing through the final transformer layer, the [CLS] token's embedding is passed through a pooling layer to obtain a vector of size hidden_size.\n",
    "Shape: [batch_size, hidden_size]\n",
    "\n",
    "batch_size: The number of sequences processed in one forward pass.\n",
    "hidden_size: The size of the hidden layer in the BERT model, typically 768 for BERT base models.\n",
    "Usage in Classification Tasks\n",
    "Feature Representation: The embedding of the [CLS] token acts as a summary representation of the entire input sequence.\n",
    "Classification Layer: This embedding is fed into a classification head (usually a fully connected layer) to produce class scores.\n",
    "Example Workflow\n",
    "Input Sequence:\n",
    "\n",
    "Tokenize the sequence and add [CLS] at the start.\n",
    "Forward Pass:\n",
    "\n",
    "Pass the sequence through BERT to generate embeddings for each token, including [CLS].\n",
    "Pooling:\n",
    "\n",
    "Extract the [CLS] token’s embedding from the final hidden states, which is the pooler_output.\n",
    "Classification:\n",
    "\n",
    "Use the pooler_output in a classification head to predict class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "70f16178-9caa-4846-a40f-3c1797343a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module): #nn.Module specifies that we are building the neural network in pytorch and it should inherit all properties of nn in pytorch. \n",
    "    \n",
    "    def __init__(self, dropout, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        #Make sure not all parameters during training will be used: \n",
    "        for param in self.bert.parameters(): #iterating through all the parameters of the model\n",
    "            param.required_grad = False #this parameter will not require gradient updates. \n",
    "        #self.dropout1 = nn.Dropout(dropout_rate) #this is no longer tenserflow so dropout must be nn from torch. \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #Define the linear layer \n",
    "        self.linear = nn.Linear(768, num_classes) # no use of units here anymore. first arg input size and second arg is output shape. \n",
    "        self.activation = nn.ReLU() \n",
    "        # Add LayerNorms \n",
    "        self.layernorm1 = nn.LayerNorm(normalized_shape=768)\n",
    "    \n",
    "\n",
    "    def forward(self,input_seqs, attention_mask): #in context of Pytorch use forward instead of call command. \n",
    "\n",
    "        \"\"\"\n",
    "        Inputs \n",
    "        \n",
    "        input_seqs     (batch_size, len_seq) : An integer vector corresponding to the index of words used in the dictionary. \n",
    "        attention_mask (batch_size,len_seq)  : A binary vector indicating the padding mask\n",
    "\n",
    "        Output\n",
    "        final_output:  (batch_size, num_classes): a list of logits, each representing the score of the sequence belonging to a class.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        #First you get the input run it through a dropout layer: \n",
    "        #x_dropped = self.dropout1(input_seqs)\n",
    "        \n",
    "        \n",
    "        # Run through the Bert Model: \n",
    "        _, output_bert = self.bert(input_ids = input_seqs, \n",
    "                                   attention_mask = attention_mask, \n",
    "                                   return_dict = False) # Shape: (batch_size, len_seq, num_hidden_neurons = 768) \n",
    "        \n",
    "        dropout_bert = self.layernorm1(self.dropout(output_bert))\n",
    "      \n",
    "        final_output = self.linear(dropout_bert)\n",
    "        return final_output \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e4543e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        for param in self.bert.parameters():\n",
    "            param.required_grad = False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, bert_output = self.bert(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  return_dict=False)\n",
    "        dropout_output = self.activation(self.dropout(bert_output))\n",
    "        final_output = self.linear(dropout_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea069cc-69af-4905-8403-978b2044aa19",
   "metadata": {},
   "source": [
    "## Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c7e8e56-493a-4a7f-a6e1-4fc4d3724cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 722.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 1, 1, 1, 2, 1, 2, 3, 7, 1, 7, 1, 1, 7, 5])\n",
      "tensor([5, 0, 7, 5, 5, 0, 2, 1, 3, 4, 2, 1, 1, 2, 8, 1])\n",
      "tensor([5, 5, 2, 2, 4, 0, 1, 2, 7, 1, 1, 1, 1, 0, 5, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_labels, batch_data in tqdm(train_loader): \n",
    "    input_ids = batch_data[\"input_ids\"] #extract the embeddings \n",
    "    attention_mask = batch_data[\"attention_mask\"] #extract the attention_masks \n",
    "    print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7aa3c79-05f8-42f0-8807-de7581020d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 20])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "be894cbe-258e-435f-bf3f-172a2a86b772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 20])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33fbfe56-d210-45dd-8920-46c3d1201208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.squeeze(input_ids, 1)\n",
    "input_ids.shape #this is the expected input size to the BertClassifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c745ce35-6ca8-4331-9b6a-0da5d5739308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9036, -0.6614, -0.5998,  0.9039, -0.7093,  1.8036,  0.2790,\n",
       "          -0.2847, -0.7064, -0.8898,  2.3714,  0.7420, -0.7087,  0.6164,\n",
       "          -0.7078, -0.7082,  1.7924, -0.4410, -0.2847, -0.9034]],\n",
       "\n",
       "        [[-1.0095,  0.0187, -0.9693,  1.6986,  0.4400,  0.2456, -0.4206,\n",
       "          -0.4212, -0.9647, -0.4061, -0.3985, -0.0884, -0.1012, -0.4247,\n",
       "           2.9753, -0.4055,  1.6986, -0.4160, -0.0424, -1.0089]],\n",
       "\n",
       "        [[-0.5410, -0.5273, -0.3471, -0.5287,  0.2925, -0.3592, -0.3610,\n",
       "          -0.5287,  2.1348, -0.3607, -0.5273, -0.0405, -0.3605, -0.3584,\n",
       "           0.0962,  0.0279, -0.3619,  3.5519, -0.3603, -0.5408]],\n",
       "\n",
       "        [[-0.5991, -0.5722, -0.1255, -0.5750,  0.0070, -0.2436, -0.5722,\n",
       "          -0.5694,  0.1439, -0.2485, -0.2495, -0.2286, -0.5750,  1.6988,\n",
       "           3.6834, -0.2471, -0.2419,  0.6854, -0.5722, -0.5987]],\n",
       "\n",
       "        [[-0.4106, -0.3971,  0.1519, -0.2287, -0.1982, -0.2343, -0.3971,\n",
       "          -0.2288, -0.2311, -0.1268, -0.2297, -0.2278,  4.3241, -0.2327,\n",
       "          -0.2022, -0.2329, -0.2252, -0.2287, -0.0336, -0.4104]],\n",
       "\n",
       "        [[-0.6331, -0.6198,  1.4132,  1.4084, -0.4593, -0.6203,  3.2952,\n",
       "          -0.4473, -0.4495,  0.0464, -0.3961, -0.4593,  1.1994, -0.3935,\n",
       "          -0.4605, -0.4414, -0.4531, -0.4608, -0.4357, -0.6329]],\n",
       "\n",
       "        [[-0.7282, -0.6955,  0.3777, -0.2937, -0.6989,  1.2469,  0.7656,\n",
       "          -0.2983, -0.2996, -0.2771,  0.0683, -0.2614, -0.6955, -0.2219,\n",
       "          -0.2877,  3.8004, -0.2987, -0.1714, -0.3030, -0.7278]],\n",
       "\n",
       "        [[-0.7167, -0.7036, -0.5397,  1.3175, -0.5453,  1.7781,  2.6287,\n",
       "          -0.2274, -0.4692, -0.5137, -0.7036, -0.5397, -0.4722,  1.4051,\n",
       "          -0.5453, -0.5373, -0.5397, -0.5400,  1.1804, -0.7165]],\n",
       "\n",
       "        [[-1.0442, -0.9998, -0.4459, -0.4534, -0.4661,  0.6082, -0.4655,\n",
       "          -0.2053,  3.0608, -0.4557,  1.3507,  0.8390, -0.0576, -0.4557,\n",
       "          -0.4644, -0.1361, -0.3611, -0.4453,  1.6409, -1.0436]],\n",
       "\n",
       "        [[-1.3910, -1.3176,  0.0272, -0.4274, -1.3252,  1.0079, -0.4284,\n",
       "          -1.3252,  1.1480,  0.5895,  1.3567, -0.4360,  1.1480,  0.5895,\n",
       "           1.3567,  1.3815, -0.3979, -0.4141,  0.2483, -1.3900]],\n",
       "\n",
       "        [[-0.7159, -0.4683, -0.6970,  0.0681, -0.6990,  2.7061, -0.4664,\n",
       "          -0.6970,  0.2628, -0.4700,  1.1785, -0.4708, -0.2739, -0.4664,\n",
       "          -0.4373, -0.3935, -0.3137,  2.6308,  0.4385, -0.7156]],\n",
       "\n",
       "        [[-0.8087,  3.0105,  1.4932,  0.9091, -0.2815, -0.6038, -0.6317,\n",
       "          -0.4238,  1.7006, -0.6262, -0.6308,  0.2801, -0.5428, -0.7965,\n",
       "           0.0135, -0.1868, -0.6299,  0.1904, -0.6262, -0.8086]],\n",
       "\n",
       "        [[-0.6475, -0.2337, -0.6115,  3.6409,  1.8438, -0.6160, -0.0918,\n",
       "          -0.6193, -0.6107, -0.1548, -0.2304, -0.6160, -0.0313, -0.2378,\n",
       "           0.0635, -0.2370,  0.5011, -0.2333, -0.2309, -0.6471]],\n",
       "\n",
       "        [[-0.6345,  1.6531,  2.4331, -0.4773, -0.4731,  2.7316,  0.5262,\n",
       "          -0.4741, -0.1338, -0.4758, -0.4766, -0.4725, -0.2876, -0.6224,\n",
       "          -0.4722, -0.3873, -0.4705, -0.4777, -0.3743, -0.6343]],\n",
       "\n",
       "        [[-0.7804, -0.7558, -0.2306, -0.7584,  1.2363, -0.4598,  0.5276,\n",
       "           3.7533, -0.4601, -0.2153, -0.0631, -0.1507, -0.4502,  0.0475,\n",
       "          -0.4569, -0.4486,  0.7073,  0.0158, -0.2776, -0.7801]],\n",
       "\n",
       "        [[-0.6783, -0.6525, -0.3412, -0.6552,  3.0374,  0.0334,  0.0368,\n",
       "          -0.2324, -0.1135,  0.8744, -0.3422, -0.3415, -0.6525, -0.2849,\n",
       "          -0.6552, -0.2427, -0.3402,  2.5670, -0.3388, -0.6780]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = input_ids.to(torch.float32)\n",
    "layernorm = nn.LayerNorm(normalized_shape=20)\n",
    "layernorm(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca219fb-38e6-40aa-9161-692c86e78517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d7d75e72-9c9e-4a82-8a82-16f08d1a00a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.squeeze(attention_mask, 1)\n",
    "attention_mask.shape #This is the expected shape for the attention_mask in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065568d-ff48-4a6b-b67e-7c976b4b4c9f",
   "metadata": {},
   "source": [
    "#### Try the BERT model on its own: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "026e5e7e-888f-4f30-8176-4ff53831bdd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-cased')\n",
    "output_bert  = bert(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6bce39c-75e4-4270-94a4-b816365d80ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_bert.last_hidden_state.shape #this is the output of the last hidden state "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aad9c0-4cd0-4f38-9f6e-62c6db5f4961",
   "metadata": {},
   "source": [
    "**Pooler_output**:\n",
    "\n",
    "The hidden state representation of the [CLS] token after pooling (typically used for classification tasks).\n",
    "Shape: (batch_size, hidden_size = 768)\n",
    "Use: This tensor is used as the representation for the entire sequence. It can be used for classification or other downstream tasks where a single vector representation of the input is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83a4408d-6f7a-412d-b52d-140e5c2779bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_bert.pooler_output.shape   #this is the pooler output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfac346-8d9e-48eb-80d9-55e28b45afa3",
   "metadata": {},
   "source": [
    "#### Try BertClassifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "704bf0f0-4b36-475d-b4a7-31df10e99a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(0.1, 9)\n",
    "output = model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9a389c99-d634-4bc5-afbe-9b9cd63d1adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 9])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #outputting a logit for every possible category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cffdec61-52b4-4a74-b21b-13772a683263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1679, -0.3284, -0.0554,  0.2516, -0.1639,  0.0882, -0.1001, -0.0939,\n",
       "         0.1223], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0] #scores corresponding how likely it is for the first sample in the batch to belong to each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5a83039-c18b-42f2-bbb8-cbfb13cbe33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0974, 0.0829, 0.1090, 0.1481, 0.0977, 0.1258, 0.1042, 0.1048, 0.1301],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(output, dim = -1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c882cf2",
   "metadata": {},
   "source": [
    "### Create model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e1c92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                     else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecf048",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07124b-8732-48a0-8f7a-d61a6e9e4cb9",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid red;\">Come back to this; I don't understand why the log function applied to the probability can be a good measurement of the loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8621022-ef3b-46f5-9f91-beea58cd4f21",
   "metadata": {},
   "source": [
    "When you have a batch of logits and corresponding labels for a classification task, and you apply the Cross Entropy Loss function in PyTorch, the process is as follows:\n",
    "\n",
    "#### Scenario\n",
    "\n",
    "- **`batch_output`**: This tensor represents the logits for a batch of sequences. For a batch of size 16 with 9 classes, it has a shape of `(16, 9)`.\n",
    "- **`labels`**: This tensor contains the correct class labels for each sequence in the batch. For a batch of size 16, it has a shape of `(16,)`.\n",
    "\n",
    "#### Cross Entropy Loss Calculation\n",
    "\n",
    "1. **Apply Softmax Internally**:\n",
    "\n",
    "   The `CrossEntropyLoss` function applies the Softmax function to the logits (raw scores) to convert them into probabilities. This operation is done internally by the function.\n",
    "\n",
    "   For a given sequence \\( i \\), the probability for class \\( j \\) is computed as:\n",
    "\n",
    "   $$\n",
    "   p_{i,j} = \\frac{\\exp(\\text{logit}_{i,j})}{\\sum_{k} \\exp(\\text{logit}_{i,k})}\n",
    "   $$\n",
    "\n",
    "   where $( \\text{logit}_{i,j} )$ is the score for class \\( j \\) for sequence \\( i \\), and \\( \\sum_{k} \\exp(\\text{logit}_{i,k}) \\) is the sum of exponentials of logits for all classes for sequence \\( i \\).\n",
    "\n",
    "2. **Compute Log Probabilities**:\n",
    "\n",
    "   The function then extracts the probability for the correct class for each sequence. If the correct class for sequence \\( i \\) is \\( c_i \\), it calculates the log probability:\n",
    "\n",
    "   $$\n",
    "   \\log(p_{i,c_i})\n",
    "   $$\n",
    "\n",
    "3. **Calculate the Negative Log Probability**:\n",
    "\n",
    "   The loss for each sequence is computed as the negative log of the probability of the correct class:\n",
    "\n",
    "   $$\n",
    "   \\text{Loss}_i = -\\log(p_{i,c_i})\n",
    "   $$\n",
    "\n",
    "4. **Compute the Mean Loss**:\n",
    "\n",
    "   Finally, the loss function averages the individual losses over all sequences in the batch to obtain the final loss:\n",
    "\n",
    "   $$\n",
    "   \\text{Loss} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Loss}_i\n",
    "   $$\n",
    "\n",
    "   where \\( N \\) is the batch size (16 in this case).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794e3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c9ced7cc-0be2-4b8e-bca1-1039ecd19d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(output, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "95f67e46-ed0a-4d7c-be92-4d1fbb6a69ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2441, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2903b89e-dc62-4d56-a230-4d5ccc4cb439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1807,  0.7302,  1.1485,  0.4753, -0.5546,  0.0336,  1.1944, -0.2405,\n",
       "        -0.0737], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4ea78a7-ca46-4869-9de1-a7ae6c33e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b422adf3-988e-4470-9edf-d833ebdd4850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.253777265548706"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665a786",
   "metadata": {},
   "source": [
    "### Move the model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19c0dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d480d-bf3c-469e-a8c9-6d8c359fd7f5",
   "metadata": {},
   "source": [
    "## Validation and Training Modes of a Model\n",
    "\n",
    "In machine learning, particularly in frameworks like PyTorch, models can operate in different modes depending on the phase of the workflow. The two primary modes are **Training** and **Validation**\n",
    "\n",
    "### Training Mode (`model.train()`)\n",
    "\n",
    "In machine learning frameworks like PyTorch, models operate in two primary modes: **Training** and **Validation (Evaluation)**. **Training Mode** (`model.train()`) is used during the model training process where dropout layers are active to prevent overfitting, batch normalization uses the current batch statistics and updates running statistics, and gradients are computed for backpropagation. In contrast, **Validation Mode** (`model.eval()`) is used for evaluating the model's performance. During this mode, dropout layers are turned off, batch normalization uses accumulated running statistics, and gradient calculations are disabled to ensure consistent and efficient evaluation of the model’s performance.\n",
    "\n",
    "\n",
    "In machine learning, particularly in frameworks like PyTorch, models can operate in different modes depending on the phase of the workflow. The two primary modes are **Training** and **Validation (Evaluation)**.\n",
    "\n",
    "### Training Mode (`model.train()`)\n",
    "\n",
    "In **Validation Mode** (`model.eval()`), the model is set for evaluation, which includes both validation and testing phases. The primary purpose of this mode is to assess the model's performance on unseen data. During validation mode, dropout layers are inactive; this means that dropout is turned off, ensuring that all units are used and no randomness is introduced during the forward pass. Additionally, batch normalization layers use the running statistics (mean and variance) that were accumulated during training for normalization purposes, and these statistics are not updated during evaluation. Furthermore, gradient calculations are disabled, which makes the evaluation process faster and more memory-efficient. This mode ensures that the model's performance is measured consistently and accurately without the interference of training-specific behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782fe93-f482-4900-b9f9-9843c19d5dc7",
   "metadata": {},
   "source": [
    "Note: PyTorch accumulates gradients by default. This means that each time backward() is called, the gradients are added to the existing gradients for each parameter. This is useful for scenarios where you might want to accumulate gradients over multiple iterations (e.g., in cases of gradient accumulation across mini-batches) but you also need to make sure they are initialized to zero when training for a new batch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4d195c29-5d18-474d-b2e4-40da3e09c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, num_iter, model, criterion,optimizer):\n",
    "    \"\"\"\n",
    "    This function will run predictions and then trains the model\n",
    "    \n",
    "    Input \n",
    "    \n",
    "    train_loader: Contains the training dataset split into batches. \n",
    "    valid_loader: Contains the validation dataset split into batches. \n",
    "    model       : BertClassifier model \n",
    "    criterion   : Loss function\n",
    "    optimizer   : Optimizer usually Adam is used. \n",
    "    num_iter    : Number of bachpropagation iterations \n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    #Set an initial loss: \n",
    "    best_loss = 1e8 \n",
    "    \n",
    "    train_loss, valid_loss = [] , []\n",
    "    # Run through the iterations: \n",
    "    for i in range(num_iter): \n",
    "        print(f\"Epoch {i+1} of {num_iter}\")\n",
    "        # Set the model into training mode \n",
    "        model.train() \n",
    "        \n",
    "        # Iterate through each training batch\n",
    "        for batch_labels, batch_tokens in train_loader: \n",
    "            \n",
    "            # Extract the integer vectors input_ids in each batch_token\n",
    "            input_seqs = batch_tokens[\"input_ids\"] \n",
    "            # Extract the attention_masks for the current batch\n",
    "            attention_mask = batch_tokens[\"attention_mask\"]\n",
    "            # Save their respective labels\n",
    "            labels = batch_labels \n",
    "    \n",
    "            # Reshape the input_seqs and attention_mask\n",
    "            input_seqs = torch.squeeze(input_seqs, 1) # shape = (batch_size, len_seq)\n",
    "            attention_mask = torch.squeeze(attention_mask,1) # shape = (batch_size, len_seq) \n",
    "            \n",
    "            # Make a prediction using the BertClassifier\n",
    "            output_bert = model(input_seqs, attention_mask)\n",
    "            \n",
    "            # Calculate the loss and save it \n",
    "            loss = criterion(output_bert, labels)\n",
    "            train_loss.append(loss.item()) #this will be a list of all training losses \n",
    "            \n",
    "            # Initialize the gradients as 0, crucial when training each batch \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Start the backpropagation \n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters \n",
    "            optimizer.step() \n",
    "    \n",
    "       \n",
    "        # Set the model for evaluation\n",
    "        model.eval() \n",
    "        for batch_labels, batch_tokens in valid_loader: \n",
    "            # Extract the integer tokens \n",
    "            input_seqs = batch_tokens[\"input_ids\"]\n",
    "            #Extract the attention_masks\n",
    "            attention_mask = batch_tokens[\"attention_mask\"]\n",
    "            # Save the labels \n",
    "            labels = batch_labels \n",
    "            # Reshape the input_seqs and attention_masks \n",
    "            input_seqs = torch.squeeze(input_seqs, 1) #remove a dim of size 1 \n",
    "            attention_mask = torch.squeeze(attention_mask,1) \n",
    "            # Make a prediction \n",
    "            bert_output = model(input_seqs, attention_mask) \n",
    "            # Calculate the loss \n",
    "            loss = criterion(bert_output,labels)\n",
    "            # Save the loss \n",
    "            valid_loss.append(loss.item())\n",
    "    \n",
    "        # Take the mean of all losses in the training set and validation set: \n",
    "        loss_tmean = np.mean(train_loss)\n",
    "        loss_vmean = np.mean(valid_loss)\n",
    "        # Print the result \n",
    "        print(f\"Mean train Loss: {loss_tmean}, Mean validation Loss: {loss_vmean}\")\n",
    "        # If the model performs well across all validation batches\n",
    "        if loss_vmean < best_loss: \n",
    "            best_loss = loss_vmean\n",
    "            # Save the model \n",
    "            #torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Best Validation Loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0e5809a5-b60e-4a83-b730-f354d16b52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n",
      "Mean train Loss: 2.0757266680399575, Mean validation Loss: 2.130387544631958\n",
      "Best Validation Loss: 2.130387544631958\n",
      "Epoch 2 of 10\n",
      "Mean train Loss: 2.03116238117218, Mean validation Loss: 2.130387544631958\n",
      "Epoch 3 of 10\n",
      "Mean train Loss: 2.0559387074576483, Mean validation Loss: 2.130387544631958\n",
      "Epoch 4 of 10\n",
      "Mean train Loss: 2.082428882519404, Mean validation Loss: 2.130387544631958\n",
      "Epoch 5 of 10\n",
      "Mean train Loss: 2.0759719451268515, Mean validation Loss: 2.130387544631958\n",
      "Epoch 6 of 10\n",
      "Mean train Loss: 2.0681277778413563, Mean validation Loss: 2.130387544631958\n",
      "Epoch 7 of 10\n",
      "Mean train Loss: 2.0751718225933256, Mean validation Loss: 2.130387544631958\n",
      "Epoch 8 of 10\n",
      "Mean train Loss: 2.073319981495539, Mean validation Loss: 2.130387544631958\n",
      "Epoch 9 of 10\n",
      "Mean train Loss: 2.0702677170435586, Mean validation Loss: 2.130387544631958\n",
      "Epoch 10 of 10\n",
      "Mean train Loss: 2.0746772567431133, Mean validation Loss: 2.130387544631958\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.1\n",
    "model = BertClassifier(dropout_rate ,9)\n",
    "num_iter = 10\n",
    "train(train_loader, valid_loader, num_iter, model, criterion,optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581eb54-54b7-410c-8e92-20c820a911ec",
   "metadata": {},
   "source": [
    "Note that the parameters of the model are internally updating. Now once the model is finished, with the training process, let's save the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5a7229f3-a528-4f41-87ba-c7e8d9c55ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/apple/Documents/GitHub/Transformers/model.statedict'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7a1943c1-15f1-4086-872c-77b6a34eb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion ): \n",
    "    \"\"\"\n",
    "    Function to test the model \n",
    "    Input: \n",
    "    test_loader : to load the testing data in  batches \n",
    "    model       : the BertClassifier model \n",
    "    criterion   : the loss function (usually Cross Entropy Loss function) \n",
    "    \n",
    "    \"\"\"\n",
    "    # Set the model into evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = [] \n",
    "    test_acc = []\n",
    "    \n",
    "    # Iterate through each batch\n",
    "    for batch_labels, batch_tokens in test_loader: \n",
    "        \n",
    "        # Extract the input_ids and the attention masks \n",
    "        input_ids = batch_tokens[\"input_ids\"] \n",
    "        attention_mask = batch_tokens[\"attention_mask\"]\n",
    "        \n",
    "        # Squeeze the last dimension\n",
    "        input_ids = torch.squeeze(input_ids, 1)\n",
    "        attention_mask =  torch.squeeze(attention_mask, 1) \n",
    "        # Make a prediction using the model \n",
    "        bert_output = model(input_ids, attention_mask)\n",
    "\n",
    "        # Calculate and save the loss \n",
    "        loss = criterion(bert_output, batch_labels) \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        # Find the predicted class and compute the accuracy \n",
    "        model_preds = torch.argmax(bert_output, axis = 1)\n",
    "        # Compute accuracy\n",
    "        test_acc.append(accuracy_score(batch_labels.detach().\n",
    "                                        numpy(),\n",
    "                                        model_preds.detach().\n",
    "                                        numpy()))\n",
    "    \n",
    "    # Take the mean loss across all batches \n",
    "    mean_loss = np.mean(test_loss)\n",
    "    mean_acc = np.mean(test_acc) * 100\n",
    "    print(f\"Mean Test Loss: {mean_loss}, Mean Test Accuracy: {mean_acc}\")\n",
    "    return(mean_loss,mean_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "155be6a0-bb26-483f-b3c6-1f8ec3d36d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss: 1.876768946647644, Mean Test Accuracy: 53.125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.876768946647644, 53.125)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb7a07",
   "metadata": {},
   "source": [
    "## Predict on new text\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c5e7b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''I am a victim of Identity Theft & currently have an Experian account that \n",
    "I can view my Experian Credit Report and getting notified when there is activity on \n",
    "my Experian Credit Report. For the past 3 days I've spent a total of approximately 9 \n",
    "hours on the phone with Experian. Every time I call I get transferred repeatedly and \n",
    "then my last transfer and automated message states to press 1 and leave a message and \n",
    "someone would call me. Every time I press 1 I get an automatic message stating than you \n",
    "before I even leave a message and get disconnected. I call Experian again, explain what \n",
    "is happening and the process begins again with the same end result. I was trying to have \n",
    "this issue attended and resolved informally but I give up after 9 hours. There are hard \n",
    "hit inquiries on my Experian Credit Report that are fraud, I didn't authorize, or recall \n",
    "and I respectfully request that Experian remove the hard hit inquiries immediately just \n",
    "like they've done in the past when I was able to speak to a live Experian representative \n",
    "in the United States. The following are the hard hit inquiries : BK OF XXXX XX/XX/XXXX \n",
    "XXXX XXXX XXXX  XX/XX/XXXX XXXX  XXXX XXXX  XX/XX/XXXX XXXX  XX/XX/XXXX XXXX  XXXX \n",
    "XX/XX/XXXX'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a65bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_text.lower()\n",
    "input_text = re.sub(r\"[^\\w\\d'\\s]+\", \" \", input_text)\n",
    "input_text = re.sub(\"\\d+\", \"\", input_text)\n",
    "input_text = re.sub(r'[x]{2,}', \"\", input_text)\n",
    "input_text = re.sub(' +', ' ', input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5e724e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "868f2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_text, padding=\"max_length\",\n",
    "                 max_length=seq_len, truncation=True,\n",
    "                 return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "62b0bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens[\"input_ids\"]\n",
    "attention_mask = tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "565f8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                     else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d1b7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "82fb78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.squeeze(input_ids, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9721e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: vehicle_loan\n"
     ]
    }
   ],
   "source": [
    "# Create model object\n",
    "model = BertClassifier(dropout, 9)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "# Forward pass\n",
    "out = torch.squeeze(model(input_ids, attention_mask))\n",
    "\n",
    "# Find predicted class\n",
    "prediction = label_encoder.classes_[torch.argmax(out)]\n",
    "print(f\"Predicted Class: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
